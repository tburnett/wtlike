---

title: Log Likelihood tools


keywords: fastai
sidebar: home_sidebar

summary: "Evaluate the Kerr likelihood, fits using poisson, gaussian"
description: "Evaluate the Kerr likelihood, fits using poisson, gaussian"
nb_path: "nbs/07_loglike.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/07_loglike.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Kerr-likelihood-formula">The Kerr likelihood formula<a class="anchor-link" href="#The-Kerr-likelihood-formula"> </a></h3><p>For each cell with a set of photons with weights $w$, the log likelihood as a function of $\alpha$  and $\beta$ is</p>
<p>{% raw %}
$$ \displaystyle\log\mathcal{L}(\alpha,\beta\ |\ w)\ = \sum_{w}  \log \big( 1 + \alpha\ w + \beta\ (1-w) \big) - (\alpha\ S + \beta\ B) $$
{% endraw %}</p>
<p>where  $\alpha$ and $\beta$ are the excess signal and background fractions and $S$ and $B$ are
the expected numbers of signal and background counts for the cell, determined from the full data set and relative exposure for the cell.</p>
<p>Usually, we assume $\beta=0$, that the background is not varying, and look for signal variation.</p>
<p>In the special case where all $w$ values are 1, this reduces to Poisson likelihood, with solution $\alpha = (1-n/S)$,
where $n$ is the number of photons.</p>
<p>This module uses this functional evaluation of the likelihood for a cell to define the poisson-like
3-parameter function to approximate this likelihood.</p>
<p>The case of a known variable background is not equivalent to allowing $\beta$ to vary, although detecting that would be a reason to be concerned.
That is because the rest of the background would not be varying. This case could be dealt with by allowing for two sources.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Special-case:-expand-the-log">Special case: expand the log<a class="anchor-link" href="#Special-case:-expand-the-log"> </a></h3><p>The case where the variation of the signal is small, and background dominated, deserves attention. Suppose $\max(|\alpha w|) &lt;&lt;1$ and $\beta$ is also small.</p>
<p>Then we only need the sums $\sum w$ and $\sum w^2$. Denoting them as $W$ and $U$, 
the solution is</p>
<p>{% raw %}
$$ \alpha = (W-S)\ /U\  \pm 1/ \sqrt U $$
{% endraw %}</p>
<p>However, for a source that is mostly quiescent, with brief flares, we have $\alpha=-1+\epsilon$, with $0 &lt; \epsilon$ &lt;&lt;1$.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LogLike" class="doc_header"><code>class</code> <code>LogLike</code><a href="https://github.com/tburnett/wtlike/tree/master/wtlike/loglike.py#L18" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LogLike</code>(<strong><code>cell</code></strong>)</p>
</blockquote>
<p>implement Kerr Eqn 2 for a single interval, or cell</p>
<ul>
<li>cell -- a dict with  w, n, S, B <br></li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3><p>Create a cell for further tests. Plot the likelihood for a cell with 100 weights</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># def fitit(loglike, pars):</span>
<span class="c1">#     pars=np.atleast_1d(pars)</span>
<span class="c1">#     fun = lambda p:  -loglike(p)</span>
<span class="c1">#     grad = lambda p: np.atleast_1d(loglike.gradient(p))</span>
<span class="c1">#     print(f&#39;Estimate: {pars.round(4)},  function: {fun(pars):.3f}, gradient: {(np.array(grad(pars))).round(4)}&#39;)</span>
<span class="c1">#     fi = optimize.fmin_l_bfgs_b(fun, pars, fprime=grad)</span>
<span class="c1">#     fit_pars = np.array(fi[0])</span>
<span class="c1">#     print(f&#39;Fit:      {fit_pars.round(4)}, function {fi[1]:.3f}, gradient: {(fi[2][&quot;grad&quot;].round(4))}&#39; )</span>
<span class="c1">#     return fi[2]</span>

<span class="c1"># loglike = ll</span>
<span class="c1"># fun = lambda p:  -loglike(p)</span>
<span class="c1"># grad = lambda p: -np.atleast_1d(loglike.gradient(p))</span>
<span class="c1"># def check(pars):</span>
<span class="c1">#     pars = np.atleast_1d(pars)</span>
<span class="c1">#     print(f&#39;pars: {pars.round(4)},  function: {fun(pars):.3f}, gradient: {(np.array(grad(pars))).round(4)}&#39;)</span>
    
<span class="c1"># check([1,0]), check([1.01,0]), check([0.99,0]);</span>

<span class="c1"># fitit(ll, [1.,0])</span>

<span class="c1"># fitit(ll, [0.99, 0])</span>

<span class="c1"># pars=[1,0.1]</span>
<span class="c1"># ll.gradient(pars)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GaussianRep" class="doc_header"><code>class</code> <code>GaussianRep</code><a href="https://github.com/tburnett/wtlike/tree/master/wtlike/loglike.py#L249" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GaussianRep</code>(<strong><code>loglike</code></strong>, <strong><code>fix_beta</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>Manage fits to the loglike object</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-1-D-gaussian-fit-parameters">The 1-D gaussian fit parameters<a class="anchor-link" href="#The-1-D-gaussian-fit-parameters"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the rate is significant, more than 5 $\sigma$, the resulting poisson-like parameters are
straight-forward to fit.</p>
<p>If $s$ and $v$ are the signal rate and its  variance, determined by the 1-d Gaussian fit for $n$ measurements,
so $s &gt; 5\sqrt{v} $, then we determine the poisson-like parameters as follows.</p>
<p>We use the properties of the Poisson distribution 
$f(n;\lambda) = \exp(n \log\lambda - \lambda + \mathrm{const})$, 
where the parameter $\lambda$ is equal to the expected value of number of occurrences $n$ and 
to its variance, and that the function we want is shifted by the background $b$ and scaled by a factor
$k$ so we use $f(k(s-b); \lambda)$ This implies that for the expected value of $s$, $\lambda = n$,
and $ k(s-b)= k^2 v = n$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>from which we obtain $k=\sqrt{n}/v$ and $b=s-k/n$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2-D-Gaussian-fit">2-D Gaussian fit<a class="anchor-link" href="#2-D-Gaussian-fit"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Gaussian2dRep" class="doc_header"><code>class</code> <code>Gaussian2dRep</code><a href="https://github.com/tburnett/wtlike/tree/master/wtlike/loglike.py#L269" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Gaussian2dRep</code>(<strong><code>ll</code></strong>) :: <a href="/wtlikeloglike.html#GaussianRep"><code>GaussianRep</code></a></p>
</blockquote>
<p>Manage fits to the loglike object</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">s</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">s</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">b</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)])</span>
<span class="n">cell</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">S</span><span class="o">=</span><span class="n">n</span><span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="n">n</span><span class="o">*</span><span class="n">b</span><span class="p">)</span>

<span class="n">ll2</span> <span class="o">=</span> <span class="n">LogLike</span><span class="p">(</span><span class="n">cell</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="n">Gaussian2dRep</span><span class="p">(</span><span class="n">ll2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Gaussian2dRep: 1,100 counts
	flux: 1.000 +/- 0.038 
	beta: 0.000 +/- 0.050
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="PoissonRep" class="doc_header"><code>class</code> <code>PoissonRep</code><a href="https://github.com/tburnett/wtlike/tree/master/wtlike/loglike.py#L275" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>PoissonRep</code>(<strong><code>loglike</code></strong>, <strong><code>tol</code></strong>=<em><code>0.2</code></em>, <strong><code>ts_min</code></strong>=<em><code>25</code></em>)</p>
</blockquote>
<p>Manage the representation of the log likelihood of a cell by a <a href="/wtlikepoisson.html#Poisson"><code>Poisson</code></a>.</p>
<ul>
<li>loglike: a LogLike object</li>
<li>ts_min : tolerance for if use fitter</li>
<li>thresh: sigma threshold to assume no Bayesian restriction</li>
</ul>
<p>Constructor takes a <a href="/wtlikeloglike.html#LogLike"><code>LogLike</code></a> object, fits it to the poisson-like function (see <a href="/wtlikepoisson.html#Poisson"><code>Poisson</code></a>), and
defines a function to evaluate that.</p>
<p>Note that beta is set to zero.</p>
<p>If the rate is significant, more than 5 $\sigma$, so that the likelihood is not truncated by the
Bayesian requirement, the resulting poisson-like parameters are   straightforward to determine.</p>
<p>If $s$ and $v$ are the signal rate and its  variance, determined by the 1-d Gaussian fit for $n$ measurements,
so $s &gt; 5\sqrt{v} $, then we determine the poisson-like parameters as follows.</p>
<p>We use the properties of the Poisson distribution
$f(n;\lambda) = \exp(n \log\lambda - \lambda + \mathrm{const})$,
where the parameter $\lambda$ is equal to the expected value of number of occurrences $n$ and
to its variance, and that the function we want is shifted by the background $b$ and scaled by a factor
$k$ so we use $f(k(s-b); \lambda)$ This implies that for the expected value of $s$, $\lambda = n$,
and $ k(s-b)= k^2 v = n$.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="/wtlikeloglike.html"><code>loglike</code></a></strong></td>
<td></td>
<td></td>
<td><em>No Content</em></td>
</tr>
<tr>
<td><strong><code>tol</code></strong></td>
<td><code>float</code></td>
<td><code>2</code></td>
<td>note global</td>
</tr>
<tr>
<td><strong><code>ts_min</code></strong></td>
<td><code>int</code></td>
<td><code>25</code></td>
<td><em>No Content</em></td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># plt.plot(x,y);</span>

<span class="c1"># pr = PoissonRep(fail, tol=0.4);</span>
<span class="c1"># plt.plot(x, [pr(t) for t in x]);</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#     pars = np.atleast_1d(pars)</span>
<span class="c1">#     if len(pars)&gt;1:      alpha, beta = pars - np.array([1,0])</span>
<span class="c1">#     else:                alpha, beta = max(-1, pars[0]-1), 0</span>
<span class="c1">#     tmp =  1 + alpha*self.w + beta*(1-self.w)</span>
<span class="c1">#     # limit alpha</span>
<span class="c1">#     tmp[tmp&lt;=1e-6]=1e-6</span>

<span class="c1">#     return np.sum( np.log(tmp)) - alpha*self.S - beta*self.B</span>
<span class="c1"># test(ll, 1), test(ll, [1,0.5])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Poisson-representation-development">Poisson representation development<a class="anchor-link" href="#Poisson-representation-development"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># info = ll.fit_info()</span>
<span class="c1"># print(f&#39;LogLike fit info:{info}&#39;)</span>
<span class="c1"># pr = PoissonRep(ll, ts_min=15)</span>
<span class="c1"># print(f&#39;PoissonRep: {pr}, poiss: {pr.poiss}&#39;)</span>
<span class="c1"># pars = np.array(pr.poiss.p).round(3)</span>
<span class="c1"># print(f&#39;poisson pars: {pars}&#39;)</span>
<span class="c1"># print(f&#39;poisson info:\n{pr.info()} &#39;)</span>

<span class="c1"># n, m, sig = np.array(list(info.values())).round(3)</span>
<span class="c1"># print(f&#39;Get poisson parmeters from n={int(n)}, m={m}, sig={sig}&#39;)</span>
<span class="c1"># mu, beta = n, n-np.sqrt(n)/sig</span>
<span class="c1"># e = m*(mu-beta)</span>
<span class="c1"># b = beta/e</span>
<span class="c1"># pois = Poisson([m, e , b])</span>
<span class="c1"># print(pois, pois.p)</span>
<span class="c1"># pr.comparison_plots(xlim=(0.4, 1.6), ylabel=&#39;log likelihood&#39; ,</span>
<span class="c1">#                     title=&#39;Likelihood Functional representations&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="PoissonRepTable" class="doc_header"><code>class</code> <code>PoissonRepTable</code><a href="https://github.com/tburnett/wtlike/tree/master/wtlike/loglike.py#L415" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>PoissonRepTable</code>(<strong><code>loglike</code></strong>) :: <a href="/wtlikeloglike.html#PoissonRep"><code>PoissonRep</code></a></p>
</blockquote>
<p>Create a table, then interpolate it</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

