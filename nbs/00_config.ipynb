{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp config\n",
    "\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements:\n",
    "\n",
    "- Cache\n",
    "- Config\n",
    "- MJD\n",
    "- UTC, UTCnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "# from astropy.coordinates import SkyCoord, Angle\n",
    "import astropy.units as u\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object <br> This is the folder where the index and data files are saved.\n",
    "    - `clear` -- set True to clear the cache on initialization\n",
    "\n",
    "    This uses pickle to save objects, associated with a hashable key, which is used to index the\n",
    "    filename in a file `index.pkl` in the same folder.\n",
    "\n",
    "    The `__call__` function is a convenient way to use it, so one call may either store a new entry or retrieve an existing one.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if not self.path: return\n",
    "        if not self.path.exists() :\n",
    "            raise Exception(f'cache Path {self.path} does not exist ')\n",
    "\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():\n",
    "            if clear:\n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists():\n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "\n",
    "    def add(self, key, object, exist_ok=False):\n",
    "        if not self.path: return\n",
    "        assert type(key)==str, f'Expect key to be a string, got {key}'\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index()\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        if not filename.exists():\n",
    "            # perhaps deleted by another instance?\n",
    "            print(f'File for Cache key {key} not found, removing entry', file='sys.stderr')\n",
    "            selt.pop(key)\n",
    "            return None\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "\n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file:\n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "\n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        try:\n",
    "            filename.unlink()\n",
    "        except:\n",
    "            print(f'Failed to unlink file {filename}')\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "\n",
    "\n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "\n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If None, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "        - `overwrite` -- if set, overwrite previous entry if exists\n",
    "\n",
    "        Example:\n",
    "        <pre>\n",
    "        mycache = Cache('/tmp/thecache', clear=True)\n",
    "\n",
    "        def myfun(x):\n",
    "            return x\n",
    "\n",
    "        result = mycache('mykey', myfun, x=99,  description='My data')\n",
    "\n",
    "        </pre>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if key is None:\n",
    "            return func(*pars, **kwargs)\n",
    "\n",
    "        ret = self.get(key)\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self or overwrite else \"Restoring from\"} cache', end='')\n",
    "            print('' if key == description else f' with key \"{key}\"')\n",
    "\n",
    "        if ret is None or overwrite:\n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret, exist_ok=overwrite)\n",
    "        return ret\n",
    "\n",
    "    def show(self, starts_with=''):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        title = 'Cache contents' if not starts_with else f'Cache entries starting with {starts_with}'\n",
    "        s = f'{title}\\n {\"key\":30}   {\"size\":>10}  {\"time\":20} {\"name\"}, in folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None or not name.startswith(starts_with) : continue\n",
    "            try:\n",
    "                stat = value.stat()\n",
    "                size = stat.st_size\n",
    "                mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "                s += f'  {name:30s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "            except Exception as msg:\n",
    "                s += f'{name} -- file not found'\n",
    "        return s\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L97\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If None, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "- `overwrite` -- if set, overwrite previous entry if exists\n",
       "\n",
       "Example:\n",
       "<pre>\n",
       "mycache = Cache('/tmp/thecache', clear=True)\n",
       "\n",
       "def myfun(x):\n",
       "    return x\n",
       "\n",
       "result = mycache('mykey', myfun, x=99,  description='My data')\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cache.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "Test: Saving to cache with key \"four\"\n",
      "Test: Restoring from cache with key \"four\"\n",
      "Before remove:\n",
      "Cache contents\n",
      " key                                    size  time                 name, in folder /tmp/cache_test\n",
      "  one                                     18  2021-08-01 15:20     cache_file_d7a97129dbf65.pkl\n",
      "  two                                     18  2021-08-01 15:20     cache_file_10d19c6307109a27.pkl\n",
      "  four                                    23  2021-08-01 15:20     cache_file_41d038288807144b.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for key \"two\" exists\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "    c.clear()\n",
    "\n",
    "test_path = Path('/tmp/cache_test')\n",
    "test_path.mkdir(exist_ok=True)\n",
    "cache_test(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Config():\n",
    "    defaults=\\\n",
    "    \"\"\"\n",
    "        verbose         : 1\n",
    "            \n",
    "        datapath        : None # where to find data--must be set\n",
    "        cachepath       : None # cache location -- will be /tmp/wtlike_cache if not set\n",
    "\n",
    "        # data cuts, processing\n",
    "        radius          : 4\n",
    "        cos_theta_max   : 0.4\n",
    "        z_max           : 100\n",
    "        offset_size     : 2.e-06  # scale factor used for event time\n",
    "\n",
    "        # binning\n",
    "        energy_edge_pars : [2,6,17] # pars for np.logspace\n",
    "        etypes          : [0, 1] # front, back\n",
    "        nside           : 1024  \n",
    "        nest            : True\n",
    "\n",
    "        # data selection for cell creation\n",
    "        week_range      : []\n",
    "        time_bins       : [0, 0, 7]\n",
    "        exp_min         : 5\n",
    "\n",
    "        # cell fitting\n",
    "        use_kerr        : False\n",
    "        likelihood_rep  : poisson\n",
    "        poisson_tolerance : 0.2\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        import yaml\n",
    "        from yaml import SafeLoader\n",
    "        \n",
    "        # parameters: first defaults, then from ~/.config/wtlike/config.yaml, then kwars\n",
    "        pars = yaml.load(self.defaults, Loader=SafeLoader)\n",
    "        dp = Path('~/.config/wtlike/config.yaml').expanduser()\n",
    "        if dp.is_file():\n",
    "            userpars = yaml.load(open(dp,'r'), Loader=SafeLoader)\n",
    "            pars.update(userpars)\n",
    "            #print(f'update from user file {dp}: {userpars}')\n",
    "        pars.update(kwargs)\n",
    "        \n",
    "        self.__dict__.update(pars)\n",
    "        \n",
    "        self.energy_edges = ee=np.logspace(*self.energy_edge_pars)\n",
    "        self.energy_bins = np.sqrt(ee[1:] * ee[:-1])\n",
    "        if not self.week_range:\n",
    "            self.week_range = (None, None)\n",
    "        \n",
    "       # set up, check files paths\n",
    "        self.error_msg=''\n",
    "        if self.datapath is None:\n",
    "            self.error_msg+='\\ndatapath must be a folder with wtlike data'\n",
    "        self.datapath = df = Path(self.datapath).expanduser()\n",
    "        if not (self.datapath.is_dir() or  self.datapath.is_symlink()):\n",
    "            self.error_msg+=f'\\ndata_folder \"{df}\" is not a directory or symlink'\n",
    "        subs = 'aeff_files weight_files data_files'.split()\n",
    "        for sub in subs:\n",
    "            if not ( (df/sub).is_dir() or  (df/sub).is_symlink()) :\n",
    "                self.error_msg+=f'\\n{df/sub} is not a directory or symlink'\n",
    "\n",
    "        if self.cachepath is None:\n",
    "            self.cachepath = Path('/tmp/wtlike_cache')\n",
    "            os.makedirs(self.cachepath, exist_ok=True)\n",
    "        else:\n",
    "            self.cachepath =  Path(self.cachepath).expanduser()\n",
    "        if not self.cachepath.is_dir():\n",
    "            self.error_msg +=f'cachepath {self.cachepath} is not a folder.'\n",
    "    \n",
    "    @property\n",
    "    def cache(self):\n",
    "        if not hasattr(self, '_cache'):\n",
    "            self._cache = Cache(self.cachepath, clear=False)\n",
    "        return self._cache\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        if len(self.error_msg)==0: return True\n",
    "        print(f'wtlike configuration is invalid:\\n{self.error_msg}',file=sys.stderr)\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files' or name.startswith('_'): continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)\n",
    "    def get(self, *pars): return self.__dict__.get(*pars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Config\" class=\"doc_header\"><code>class</code> <code>Config</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Config</code>(**\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### config.Config -- parameters are from three sources:\n",
       "- defaults\n",
       "- the file `~/.config/wtlike/config.yaml` if it exists\n",
       "- keyword args in Config constructor. For example, to suppress all printout:\n",
       "    ```\n",
       "config = Config(verbose=0)\n",
       "```\n",
       "\n",
       "##### Config defaults\n",
       "This is yaml-format, corresponding to `config.yaml`.\n",
       "\n",
       "        verbose         : 1\n",
       "            \n",
       "        datapath        : None # where to find data--must be set\n",
       "        cachepath       : None # cache location -- will be /tmp/wtlike_cache if not set\n",
       "\n",
       "        # data cuts, processing\n",
       "        radius          : 4\n",
       "        cos_theta_max   : 0.4\n",
       "        z_max           : 100\n",
       "        offset_size     : 2.e-06  # scale factor used for event time\n",
       "\n",
       "        # binning\n",
       "        energy_edge_pars : [2,6,17] # pars for np.logspace\n",
       "        etypes          : [0, 1] # front, back\n",
       "        nside           : 1024  \n",
       "        nest            : True\n",
       "\n",
       "        # data selection for cell creation\n",
       "        week_range      : []\n",
       "        time_bins       : [0, 0, 7]\n",
       "        exp_min         : 5\n",
       "\n",
       "        # cell fitting\n",
       "        use_kerr        : False\n",
       "        likelihood_rep  : poisson\n",
       "        poisson_tolerance : 0.2\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "#### Config contents as set up here\n",
       "<details  class=\"nbdoc-description\" >  <summary> config parameter list </summary>  <div style=\"margin-left: 5%\"><pre>Configuration parameters <br>  verbose         : 1<br>  datapath        : /home/burnett/wtlike_data<br>  cachepath       : /home/burnett/wtlike_cache<br>  radius          : 4<br>  cos_theta_max   : 0.4<br>  z_max           : 100<br>  offset_size     : 2e-06<br>  energy_edge_pars : [2, 6, 17]<br>  etypes          : [0, 1]<br>  nside           : 1024<br>  nest            : True<br>  week_range      : (None, None)<br>  time_bins       : [0, 0, 7]<br>  exp_min         : 5<br>  use_kerr        : False<br>  likelihood_rep  : poisson<br>  poisson_tolerance : 0.2<br>  energy_edges    : [1.00000000e+02 1.77827941e+02 3.16227766e+02 5.62341325e+02<br> 1.00000000e+03 1.77827941e+03 3.16227766e+03 5.62341325e+03<br> 1.00000000e+04 1.77827941e+04 3.16227766e+04 5.62341325e+04<br> 1.00000000e+05 1.77827941e+05 3.16227766e+05 5.62341325e+05<br> 1.00000000e+06]<br>  energy_bins     : [1.33352143e+02 2.37137371e+02 4.21696503e+02 7.49894209e+02<br> 1.33352143e+03 2.37137371e+03 4.21696503e+03 7.49894209e+03<br> 1.33352143e+04 2.37137371e+04 4.21696503e+04 7.49894209e+04<br> 1.33352143e+05 2.37137371e+05 4.21696503e+05 7.49894209e+05]<br>  error_msg       : <br></pre></div> </details>   \n",
       "\n",
       "\n",
       "\n",
       "##### config.cache -- a file cache\n",
       "The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
       "`/home/burnett/wtlike_cache`\n",
       "\n",
       "<details  class=\"nbdoc-description\" >  <summary> current cache contents </summary>  <div style=\"margin-left: 5%\"><pre>Cache contents<br> key                                    size  time                 name, in folder /home/burnett/wtlike_cache<br>  P88Y3278_data                    128097967  2021-07-30 07:11     cache_file_7cc64c0c03169077.pkl<br>  P88Y3243_data                     96003882  2021-07-31 06:10     cache_file_616b5b35718cbef9.pkl<br>  PSR J0633+1746_data              125596991  2021-07-29 15:49     cache_file_e5a52bc7bf78597.pkl<br>  P88Y4744_data                    155979422  2021-07-06 09:42     cache_file_313ff9a4a61b0dd.pkl<br>  PSR J1747-2958_data              153970472  2021-07-06 10:01     cache_file_67d7112d0fd9cf73.pkl<br>  Geminga_test                     134106948  2021-07-08 06:14     cache_file_110ee4a7bc8f2715.pkl<br>  P88Y3157_data                     94261671  2021-08-01 10:06     cache_file_4c35159676191122.pkl<br>  PSR J0534+2200_data              123229511  2021-07-09 10:41     cache_file_31da097aee4d5d1a.pkl<br>  Geminga_nokerr                   128071691  2021-07-29 14:33     cache_file_2905cf7a9572d1c4.pkl<br></pre></div> </details>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7f8d671498b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "def summary():\n",
    "    \"\"\"\n",
    "    \n",
    "    #### config.Config -- parameters are from three sources:\n",
    "    - defaults\n",
    "    - the file `~/.config/wtlike/config.yaml` if it exists\n",
    "    - keyword args in Config constructor. For example, to suppress all printout:\n",
    "        ```\n",
    "    config = Config(verbose=0)\n",
    "    ```\n",
    "    \n",
    "    ##### Config defaults\n",
    "    This is yaml-format, corresponding to `config.yaml`.\n",
    "    {config_defaults}\n",
    "    \n",
    "    \n",
    "    #### Config contents as set up here\n",
    "    {config_text}   \n",
    "\n",
    "\n",
    "    \n",
    "    ##### config.cache -- a file cache\n",
    "    The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
    "    `{config.cachepath}`\n",
    "    \n",
    "    {cache_text}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    config_defaults = Config.defaults\n",
    "    config_text = monospace(config, summary='config parameter list')\n",
    "\n",
    " \n",
    "    cache_text = monospace(config.cache, 'current cache contents' )\n",
    "\n",
    "\n",
    "    return locals()\n",
    "nbdoc(summary) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time\n",
    "- UTCnow: current ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "#mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "# From a FT2 file header\n",
    "# MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "# MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "mission_start = 51910.00074287037\n",
    "\n",
    "def MJD(arg):\n",
    "\n",
    "    if type(arg)==str:\n",
    "        while len(arg.split('-'))<3:\n",
    "            arg+='-1'\n",
    "        return Time(arg, format='iso').mjd\n",
    "\n",
    "    \"convert MET or UTC to MJD\"\n",
    "    return (mission_start + arg/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value\n",
    "\n",
    "def UTCnow():\n",
    "    from datetime import datetime\n",
    "    t=datetime.utcnow()\n",
    "    return f'UTC {t.year}-{t.month:02d}-{t.day} {t.hour:02d}:{t.minute:02d}'\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2001-01-01 00:01', '2008-08-05 00:00', 'UTC 2021-08-1 21:33')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UTC(MJD(0)), UTC(first_data), UTCnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'\n",
    "assert MJD('2008')==54466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bin_size_name(bins):\n",
    "    \"\"\"Provide a nice name, e.g., 'day' for a time interval\n",
    "    \"\"\"\n",
    "    if np.isscalar(bins) :\n",
    "        binsize = bins\n",
    "    else:\n",
    "        binsize = np.mean(bins)\n",
    "\n",
    "    def check_unit(x):\n",
    "        unit_table = dict(week=1/7, day=1, hour=24, min=24*60, s=24*3600)\n",
    "        for name, unit in unit_table.items():\n",
    "            t = x*unit\n",
    "            r = np.mod(t+1e-9,1)\n",
    "            if r<1e-6 or t>1:\n",
    "                return t, name\n",
    "        return x, 'day'\n",
    "    n, unit =  check_unit(binsize)\n",
    "    nt = f'{n:.0f}' if np.mod(n,1)<1e-2 else f'{n:.0f}'\n",
    "    return f'{nt}-{unit}'# if n>1 else f'{unit}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decorate_with(other_func):\n",
    "    def decorator(func):\n",
    "        func.__doc__ += other_func.__doc__\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 03_sources.ipynb.\n",
      "Converted 04_load_data.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_main.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sun Aug  1 14:33:10 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
