{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp config\n",
    "%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n",
    "from wtlike.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### config.Config -- parameters\n",
       "\n",
       "for now, but could be obtained from an editable yaml file.\n",
       "\n",
       "<details  class=\"nbdoc-description\" >  <summary> config parameter list </summary>  <div style=\"margin-left: 5%\"><pre>Configuration parameters <br>  verbose         : 3<br>  mjd_range       : None<br>  radius          : 5<br>  cos_theta_max   : 0.4<br>  z_max           : 100<br>  time_interval   : 1<br>  use_uint8       : False<br>  nside           : 1024<br>  nest            : True<br>  bins_per_decade : 4<br>  base_spectrum   : lambda E: (E/1000)**-2.1<br>  energy_range    : (100.0, 1000000.0)<br>  likelihood_rep  : poisson<br></pre></div> </details>\n",
       "\n",
       "##### config.Files -- default file paths\n",
       "<details  class=\"nbdoc-description\" >  <summary> file list </summary>  <div style=\"margin-left: 5%\"><pre>File paths for light curves<br>  data       : /home/burnett/data<br>  ft2        : /home/burnett/work/lat-data/ft2<br>  gti        : /home/burnett/work/lat-data/binned<br>  aeff       : /home/burnett/work/lat-data/aeff<br>  weights    : /home/burnett/onedrive/fermi/weight_files<br>  cachepath  : /tmp/lc_cache<br></pre></div> </details>\n",
       "\n",
       "These are dataclass classes, and can be initialized with\n",
       "parameters. For example, to suppress printout \n",
       "    \n",
       "```\n",
       "config = Config(verbose=0)\n",
       "```\n",
       "\n",
       "##### config.cache -- a file cache\n",
       "The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
       "`config.files.cachepath`\n",
       "\n",
       "<details  class=\"nbdoc-description\" >  <summary> cache contents </summary>  <div style=\"margin-left: 5%\"><pre>Cache contents<br> key                          size  time                 name, in folder /tmp/lc_cache<br>  gti                      1018319  2020-12-26 12:35     cache_file_4500f0b6c67283da.pkl<br>  photons_Geminga         22334705  2020-12-26 12:36     cache_file_41e661309838f76b.pkl<br>  exposure_Geminga        86263776  2020-12-26 12:46     cache_file_7e30467ce5583755.pkl<br>  binned_exposure_Geminga       64448  2020-12-26 12:46     cache_file_4c1fe764cb82290a.pkl<br>  cells_Geminga            4746224  2020-12-26 12:46     cache_file_725fd436c9def390.pkl<br>  lightfcurve_Geminga      6887313  2020-12-26 12:46     cache_file_a35e0970a832156.pkl<br>  photons_3C 279           3659049  2020-12-26 12:46     cache_file_495c0998a1cea57.pkl<br></pre></div> </details>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7f085ccfdc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "def summary():\n",
    "    \"\"\"\n",
    "    \n",
    "    ##### config.Config -- parameters\n",
    "\n",
    "    for now, but could be obtained from an editable yaml file.\n",
    "    \n",
    "    {config_text}\n",
    "    \n",
    "    ##### config.Files -- default file paths\n",
    "    {files_text}\n",
    " \n",
    "    These are dataclass classes, and can be initialized with\n",
    "    parameters. For example, to suppress printout \n",
    "        \n",
    "    ```\n",
    "    config = Config(verbose=0)\n",
    "    ```\n",
    "    \n",
    "    ##### config.cache -- a file cache\n",
    "    The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
    "    `config.files.cachepath`\n",
    "    \n",
    "    {cache_text}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    config_text = monospace(config, summary='config parameter list')\n",
    "    files_text = monospace(Files(), summary='file list')\n",
    "    files = Files()\n",
    " \n",
    "    cache_text = monospace(config.cache, 'cache contents' )\n",
    "    assert files.valid\n",
    "    return locals()\n",
    "if Files().valid:\n",
    "    nbdoc(summary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object <br> This is the folder where the index and data files are saved.\n",
    "    - `clear` -- set True to clear the cache on initialization\n",
    "    \n",
    "    This uses pickle to save objects, associated with a hashable key, which is used to index the\n",
    "    filename in a file `index.pkl` in the same folder. \n",
    "    \n",
    "    The `__call__` function is a convenient way to use it, so one call may either store a new entry or retrieve an existing one.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if not self.path: return\n",
    "        self.path.mkdir(exist_ok=True)\n",
    "        assert self.path.exists()\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():  \n",
    "            if clear: \n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "        else:\n",
    "            self.path.mkdir(exist_ok=True)        \n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        \n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists(): \n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "        \n",
    "    def add(self, key, object, exist_ok=False):\n",
    "        if not self.path: return\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index() \n",
    " \n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "        \n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        if not filename.exists():\n",
    "            # perhaps deleted by another instance?\n",
    "            print(f'File for Cache key {key} not found, removing entry', file='sys.stderr')\n",
    "            selt.pop(key)\n",
    "            return None\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "    \n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file: \n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "        \n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        filename.unlink()\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "        \n",
    "                \n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "        \n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If none, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "\n",
    "        Example:\n",
    "        <pre>\n",
    "        mycache = Cache('/tmp/thecache', clear=True)\n",
    "        \n",
    "        def myfun(x):\n",
    "            return x\n",
    "\n",
    "        result = mycache('mykey', myfun, x=99,  description='My data')\n",
    "\n",
    "        </pre>\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if key is None:\n",
    "            return func(*pars, **kwargs)\n",
    "        \n",
    "        ret = self.get(key)\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self else \"Restoring from\"} cache with key \"{key}\"')\n",
    "\n",
    "        if ret is None or overwrite: \n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret)\n",
    "        return ret\n",
    "             \n",
    "    def __str__(self):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        s = f'Cache contents\\n {\"key\":20}   {\"size\":>10}  {\"time\":20} {\"name\"}, in folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None: continue\n",
    "            stat = value.stat()\n",
    "            size = stat.st_size\n",
    "            mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "            s += f'  {name:20s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L94\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If none, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "\n",
       "Example:\n",
       "<pre>\n",
       "mycache = Cache('/tmp/thecache', clear=True)\n",
       "\n",
       "def myfun(x):\n",
       "    return x\n",
       "\n",
       "result = mycache('mykey', myfun, x=99,  description='My data')\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cache.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "Test: Saving to cache with key \"four\"\n",
      "Test: Restoring from cache with key \"four\"\n",
      "Before remove:\n",
      "Cache contents\n",
      " key                          size  time                 name, in folder /tmp/test_cache\n",
      "  one                           13  2020-12-26 14:31     cache_file_2073333e680c59.pkl\n",
      "  two                           13  2020-12-26 14:31     cache_file_317b139909ee2564.pkl\n",
      "  four                          18  2020-12-26 14:31     cache_file_870c73b22257801.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for key \"two\" exists\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "   \n",
    "    \n",
    "    c.clear()\n",
    "cache_test('/tmp/test_cache')\n",
    "# disabled should ignore\n",
    "#cache_test(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration data classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Files:\n",
    "    \"\"\" paths to the various files that we need\"\"\"\n",
    "\n",
    "    data:str = '$HOME/data'\n",
    "    ft2: str = '$HOME/work/lat-data/ft2'\n",
    "    gti: str = '$HOME/work/lat-data/binned/'\n",
    "    aeff:str = '$HOME/work/lat-data/aeff'\n",
    "    weights: str = '$HOME/onedrive/fermi/weight_files'\n",
    "    cachepath: str = '/tmp/lc_cache'\n",
    "\n",
    "    # expand -- not implemented in Path\n",
    "    def __post_init__(self):\n",
    "        d = self.__dict__\n",
    "        for name, value in d.items():\n",
    "            d[name] = Path(os.path.expandvars(value))\n",
    "#         self.cachepath.mkdir(exist_ok=True)\n",
    "#         self.cache = Cache(self.cachepath, clear=False)\n",
    "        \n",
    "    @property\n",
    "    def valid(self):\n",
    "        \"\"\"assume all files ok if aeff\"\"\"\n",
    "        return self.aeff.exists()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'File paths for light curves\\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            s += f'  {name:10s} : {value}\\n'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File paths for light curves\n",
       "  data       : /home/burnett/data\n",
       "  ft2        : /home/burnett/work/lat-data/ft2\n",
       "  gti        : /home/burnett/work/lat-data/binned\n",
       "  aeff       : /home/burnett/work/lat-data/aeff\n",
       "  weights    : /home/burnett/onedrive/fermi/weight_files\n",
       "  cachepath  : /tmp/lc_cache"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Default light curve configuration parameters\"\"\"\n",
    "    verbose : int = 3\n",
    "    files :'' =  None\n",
    "\n",
    "    # photon selection\n",
    "    mjd_range : Tuple=None\n",
    "    radius: float = 5\n",
    "    cos_theta_max:float=0.4\n",
    "    z_max : float=100\n",
    "\n",
    "    # binning\n",
    "    energy_edges = np.logspace(2,6,17)\n",
    "    time_interval: int = 1\n",
    "    use_uint8: bool=False  # for weights \n",
    "\n",
    "    # healpix data representation used by data\n",
    "    nside : int=1024\n",
    "    nest: bool=True\n",
    "\n",
    "    # exposure calculation\n",
    "    bins_per_decade: int=4\n",
    "    base_spectrum: str='lambda E: (E/1000)**-2.1'\n",
    "    energy_range: Tuple = (100.,1e6)\n",
    "        \n",
    "    # analysis\n",
    "    likelihood_rep: str='poisson'\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        if self.files is None: self.files=Files()\n",
    "#         try:\n",
    "#             chpath = self.files.cachepath\n",
    "#             chpath.mkdir(exist_ok=True)\n",
    "#             self.cache = Cache(chpath, clear=False)\n",
    "#         except Exception as e:\n",
    "#             print(f'Could not create cache, {e}', file=sys.stderr)\n",
    "#             raise\n",
    "#             self.cache = None\n",
    "    @property\n",
    "    def cache(self):\n",
    "        if not hasattr(self, '_cache'):\n",
    "            self._cache = Cache(self.files.cachepath, clear=False)\n",
    "        return self._cache\n",
    "        \n",
    "    @property\n",
    "    def valid(self):\n",
    "        return self.files.valid \n",
    "    \n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files' or name.startswith('_'): continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration parameters \n",
      "  verbose         : 3\n",
      "  mjd_range       : None\n",
      "  radius          : 5\n",
      "  cos_theta_max   : 0.4\n",
      "  z_max           : 100\n",
      "  time_interval   : 1\n",
      "  use_uint8       : False\n",
      "  nside           : 1024\n",
      "  nest            : True\n",
      "  bins_per_decade : 4\n",
      "  base_spectrum   : lambda E: (E/1000)**-2.1\n",
      "  energy_range    : (100.0, 1000000.0)\n",
      "  likelihood_rep  : poisson\n",
      " File paths for light curves\n",
      "  data       : /home/burnett/data\n",
      "  ft2        : /home/burnett/work/lat-data/ft2\n",
      "  gti        : /home/burnett/work/lat-data/binned\n",
      "  aeff       : /home/burnett/work/lat-data/aeff\n",
      "  weights    : /home/burnett/onedrive/fermi/weight_files\n",
      "  cachepath  : /tmp/lc_cache\n",
      " Cache contents\n",
      " key                          size  time                 name, in folder /tmp/lc_cache\n",
      "  gti                      1018319  2020-12-26 12:35     cache_file_4500f0b6c67283da.pkl\n",
      "  photons_Geminga         22334705  2020-12-26 12:36     cache_file_41e661309838f76b.pkl\n",
      "  exposure_Geminga        86263776  2020-12-26 12:46     cache_file_7e30467ce5583755.pkl\n",
      "  binned_exposure_Geminga       64448  2020-12-26 12:46     cache_file_4c1fe764cb82290a.pkl\n",
      "  cells_Geminga            4746224  2020-12-26 12:46     cache_file_725fd436c9def390.pkl\n",
      "  lightfcurve_Geminga      6887313  2020-12-26 12:46     cache_file_a35e0970a832156.pkl\n",
      "  photons_3C 279           3659049  2020-12-26 12:46     cache_file_495c0998a1cea57.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print (config, config.files, config.cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "\n",
    "def MJD(met):\n",
    "    \"convert MET to MJD\"\n",
    "    #mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "    # From a FT2 file header\n",
    "    # MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "    # MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "    mission_start = 51910.00074287037\n",
    "    return (mission_start + met/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "class PointSource():\n",
    "    \"\"\"Manage the position and name of a point source\n",
    "    \"\"\"\n",
    "    def __init__(self, name, position=None):\n",
    "        \"\"\"position: (l,b) tuple or None. if None, expect to be found by lookup\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        if position is None:\n",
    "            skycoord = SkyCoord.from_name(name)\n",
    "            gal = skycoord.galactic\n",
    "            self.l,self.b = (gal.l.value, gal.b.value)\n",
    "        else:\n",
    "            self.l,self.b = position\n",
    "            skycoord = SkyCoord(self.l,self.b, unit='deg', frame='galactic')\n",
    "        self.skycoord = skycoord\n",
    "    def __str__(self):\n",
    "        return f'Source \"{self.name}\" at: (l,b)=({self.l:.3f},{self.b:.3f})'\n",
    "    def __repr__(self): return str(self)\n",
    "\n",
    "    @property\n",
    "    def ra(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.ra.value\n",
    "    @property\n",
    "    def dec(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.dec.value\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        \"\"\"Modified name for file system\"\"\"\n",
    "        return self.name.replace(' ', '_').replace('+','p')\n",
    "\n",
    "    @classmethod\n",
    "    def fk5(cls, name, position):\n",
    "        \"\"\"position: (ra,dec) tuple \"\"\"\n",
    "        ra,dec = position\n",
    "        sk = SkyCoord(ra, dec, unit='deg',  frame='fk5').transform_to('galactic')\n",
    "        return cls(name, (sk.l.value, sk.b.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"PointSource.fk5\" class=\"doc_header\"><code>PointSource.fk5</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PointSource.fk5</code>(**`name`**, **`position`**)\n",
       "\n",
       "position: (ra,dec) tuple "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PointSource.fk5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, expect in [( PointSource('Geminga'),             'Source \"Geminga\" at: (l,b)=(195.134,4.266)'),\n",
    "                  ( PointSource('gal_source', (0,0)),   'Source \"gal_source\" at: (l,b)=(0.000,0.000)', ),\n",
    "                  ( PointSource.fk5('fk5_source',(0,0)),'Source \"fk5_source\" at: (l,b)=(96.337,-60.189)',)\n",
    "                   ]:    \n",
    "    assert str(s)==expect, f'expected {expect}, got {str(s)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Sat Dec 26 14:31:23 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
