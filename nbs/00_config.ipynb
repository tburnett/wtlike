{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp config\n",
    "\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements:\n",
    "\n",
    "- Cache\n",
    "- Config\n",
    "- MJD\n",
    "- UTC, UTCnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "# from astropy.coordinates import SkyCoord, Angle\n",
    "import astropy.units as u\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "   \n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object <br> This is the folder where the index and data files are saved.\n",
    "    - `clear` -- set True to clear the cache on initialization\n",
    "\n",
    "    This uses pickle to save objects, associated with a hashable key, which is used to index the\n",
    "    filename in a file `index.pkl` in the same folder.\n",
    "\n",
    "    The `__call__` function is a convenient way to use it, so one call may either store a new entry or retrieve an existing one.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if self.path is None: return\n",
    "        if not self.path.exists() :\n",
    "            print(f'Warning: cache Path {self.path} does not exist, cache disabled ',file=sys.stderr)\n",
    "            self.path=None\n",
    "            return\n",
    "\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():\n",
    "            if clear:\n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists():\n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "\n",
    "    def add(self, key, object,  exist_ok=False):\n",
    "        if not self.path: return\n",
    "        assert type(key)==str, f'Expect key to be a string, got {key}'\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index()\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        if not filename.exists():\n",
    "            # perhaps deleted by another instance?\n",
    "            print(f'File for Cache key {key} not found, removing entry', file='sys.stderr')\n",
    "            selt.pop(key)\n",
    "            return None\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "\n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file:\n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "\n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        try:\n",
    "            filename.unlink()\n",
    "        except:\n",
    "            print(f'Failed to unlink file {filename}')\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "\n",
    "\n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "\n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If None, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "        - `overwrite` -- if set, overwrite previous entry if exists\n",
    "\n",
    "        Example:\n",
    "        <pre>\n",
    "        mycache = Cache('/tmp/thecache', clear=True)\n",
    "\n",
    "        def myfun(x):\n",
    "            return x\n",
    "\n",
    "        result = mycache('mykey', myfun, x=99,  description='My data')\n",
    "\n",
    "        </pre>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if key is None or self.path is None:\n",
    "            return func(*pars, **kwargs)\n",
    "\n",
    "\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self or overwrite else \"Restoring from\"} cache', end='')\n",
    "            print('' if key == description else f' with key \"{key}\"')\n",
    "        ret = self.get(key)\n",
    "        if ret is None or overwrite:\n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret, exist_ok=overwrite)\n",
    "        return ret\n",
    "\n",
    "    def show(self, starts_with=''):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        if len(self.items())==0: return f'Cache at {self.path} is empty\\n'\n",
    "        title = 'Cache contents' if not starts_with else f'Cache entries starting with {starts_with}'\n",
    "        s = f'{title}\\n {\"key\":30}   {\"size\":>10}  {\"time\":20} {\"name\"}, folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None or not name.startswith(starts_with) : continue\n",
    "            try:\n",
    "                stat = value.stat()\n",
    "                size = stat.st_size\n",
    "                mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "                s += f'  {name:30s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "            except Exception as msg:\n",
    "                s += f'{name} -- file not found\\n'\n",
    "        return s\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L99\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If None, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "- `overwrite` -- if set, overwrite previous entry if exists\n",
       "\n",
       "Example:\n",
       "<pre>\n",
       "mycache = Cache('/tmp/thecache', clear=True)\n",
       "\n",
       "def myfun(x):\n",
       "    return x\n",
       "\n",
       "result = mycache('mykey', myfun, x=99,  description='My data')\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cache.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "Test: Saving to cache with key \"four\"\n",
      "Test: Restoring from cache with key \"four\"\n",
      "Before remove:\n",
      "Cache contents\n",
      " key                                    size  time                 name, folder /tmp/cache_test\n",
      "  one                                     18  2021-08-14 08:56     cache_file_0af188f7828c3d7.pkl\n",
      "  two                                     18  2021-08-14 08:56     cache_file_5e46270bc1351613.pkl\n",
      "  four                                    23  2021-08-14 08:56     cache_file_90ab8da73281313.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for key \"two\" exists\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "    c.clear()\n",
    "\n",
    "test_path = Path('/tmp/cache_test')\n",
    "test_path.mkdir(exist_ok=True)\n",
    "cache_test(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Config():\n",
    "    defaults=\\\n",
    "    \"\"\"\n",
    "        verbose         : 1 # set to zero for no output\n",
    "        usermode        : true # default suppress warnings \n",
    "            \n",
    "        datapath        : None # where to find data--must be set\n",
    "        cachepath       : ~/.cache/wtlike # \n",
    "        \n",
    "        # Expect 4FGL FITS file, e.g.,  gll_psc_v28.fit\n",
    "        catalog_file    : \n",
    "\n",
    "        # data cuts, processing\n",
    "        radius          : 4\n",
    "        cos_theta_max   : 0.4\n",
    "        z_max           : 100\n",
    "        offset_size     : 2.e-06  # scale factor used for event time\n",
    "\n",
    "        # binning -- actually determined by weight run\n",
    "        energy_edge_pars : [2,6,17] # pars for np.logspace\n",
    "        etypes          : [0, 1] # front, back\n",
    "        nside           : 1024  \n",
    "        nest            : True\n",
    "\n",
    "        # data selection for cell creation\n",
    "        week_range      : []  # default all weeks found\n",
    "        time_bins       : [0, 0, 7] # full MJD range, 7-day cells\n",
    "        exp_min         : 5    # threshold for exposure per cell, in cm^2 Ms units.\n",
    "\n",
    "        # cell fitting\n",
    "        use_kerr        : False\n",
    "        likelihood_rep  : poisson\n",
    "        poisson_tolerance : 0.2\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        import yaml\n",
    "        from yaml import SafeLoader\n",
    "        \n",
    "        # parameters: first defaults, then from ~/.config/wtlike/config.yaml, then kwars\n",
    "        pars = yaml.load(self.defaults, Loader=SafeLoader)\n",
    "        dp = Path('~/.config/wtlike/config.yaml').expanduser()\n",
    "        if dp.is_file():\n",
    "            userpars = yaml.load(open(dp,'r'), Loader=SafeLoader)\n",
    "            pars.update(userpars)\n",
    "            #print(f'update from user file {dp}: {userpars}')\n",
    "        pars.update(kwargs)\n",
    "        \n",
    "        self.__dict__.update(pars)\n",
    "        \n",
    "        # suppress warnings unless testing or in usermode\n",
    "        if self.usermode:\n",
    "            if not sys.warnoptions:\n",
    "                import warnings\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        self.energy_edges = ee=np.logspace(*self.energy_edge_pars)\n",
    "        self.energy_bins = np.sqrt(ee[1:] * ee[:-1])\n",
    "        if not self.week_range:\n",
    "            self.week_range = (None, None)\n",
    "        \n",
    "       # set up, check files paths\n",
    "        self.error_msg=''\n",
    "        if self.datapath is None:\n",
    "            self.error_msg+='\\ndatapath must be a folder with wtlike data'\n",
    "        else:    \n",
    "            self.datapath = df = Path(self.datapath).expanduser()\n",
    "            if not (self.datapath.is_dir() or  self.datapath.is_symlink()):\n",
    "                self.error_msg+=f'\\ndata_folder \"{df}\" is not a directory or symlink'\n",
    "            subs = 'aeff_files weight_files data_files'.split()\n",
    "            for sub in subs:\n",
    "                if not ( (df/sub).is_dir() or  (df/sub).is_symlink()) :\n",
    "                    self.error_msg+=f'\\n{df/sub} is not a directory or symlink'\n",
    "\n",
    "        self.cachepath =  Path(self.cachepath).expanduser()\n",
    "        os.makedirs(self.cachepath, exist_ok=True)\n",
    "        if not self.cachepath.is_dir():\n",
    "            self.error_msg +=f'cachepath {self.cachepath} is not a folder.'\n",
    "            \n",
    "    @property\n",
    "    def cache(self):\n",
    "        if not hasattr(self, '_cache'):\n",
    "            self._cache = Cache(self.cachepath, clear=False)\n",
    "        return self._cache\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        if len(self.error_msg)==0: return True\n",
    "        print(f'wtlike configuration is invalid:\\n{self.error_msg}',file=sys.stderr)\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files' or name.startswith('_'): continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)\n",
    "    def get(self, *pars): return self.__dict__.get(*pars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Config\" class=\"doc_header\"><code>class</code> <code>Config</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Config</code>(**\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### config.Config -- parameters are from three sources:\n",
       "- defaults\n",
       "- the file `~/.config/wtlike/config.yaml` if it exists\n",
       "- keyword args in Config constructor. For example, to suppress all printout:\n",
       "    ```\n",
       "config = Config(verbose=0)\n",
       "```\n",
       "\n",
       "##### Config defaults\n",
       "This is yaml-format, corresponding to `config.yaml`.\n",
       "\n",
       "        verbose         : 1 # set to zero for no output\n",
       "        usermode        : true # default suppress warnings \n",
       "            \n",
       "        datapath        : None # where to find data--must be set\n",
       "        cachepath       : ~/.cache/wtlike # \n",
       "        \n",
       "        # Expect 4FGL FITS file, e.g.,  gll_psc_v28.fit\n",
       "        catalog_file    : \n",
       "\n",
       "        # data cuts, processing\n",
       "        radius          : 4\n",
       "        cos_theta_max   : 0.4\n",
       "        z_max           : 100\n",
       "        offset_size     : 2.e-06  # scale factor used for event time\n",
       "\n",
       "        # binning -- actually determined by weight run\n",
       "        energy_edge_pars : [2,6,17] # pars for np.logspace\n",
       "        etypes          : [0, 1] # front, back\n",
       "        nside           : 1024  \n",
       "        nest            : True\n",
       "\n",
       "        # data selection for cell creation\n",
       "        week_range      : []  # default all weeks found\n",
       "        time_bins       : [0, 0, 7] # full MJD range, 7-day cells\n",
       "        exp_min         : 5    # threshold for exposure per cell, in cm^2 Ms units.\n",
       "\n",
       "        # cell fitting\n",
       "        use_kerr        : False\n",
       "        likelihood_rep  : poisson\n",
       "        poisson_tolerance : 0.2\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "#### Config contents as set up here\n",
       "<details  class=\"nbdoc-description\" >  <summary> config parameter list </summary>  <div style=\"margin-left: 5%\"><pre>Configuration parameters <br>  verbose         : 1<br>  usermode        : False<br>  datapath        : /home/burnett/wtlike_data<br>  cachepath       : /home/burnett/.cache/wtlike<br>  catalog_file    : ~/onedrive/fermi/catalog/gll_psc_v28.fit<br>  radius          : 4<br>  cos_theta_max   : 0.4<br>  z_max           : 100<br>  offset_size     : 2e-06<br>  energy_edge_pars : [2, 6, 17]<br>  etypes          : [0, 1]<br>  nside           : 1024<br>  nest            : True<br>  week_range      : (None, None)<br>  time_bins       : [0, 0, 7]<br>  exp_min         : 5<br>  use_kerr        : False<br>  likelihood_rep  : poisson<br>  poisson_tolerance : 0.2<br>  energy_edges    : [1.00000000e+02 1.77827941e+02 3.16227766e+02 5.62341325e+02<br> 1.00000000e+03 1.77827941e+03 3.16227766e+03 5.62341325e+03<br> 1.00000000e+04 1.77827941e+04 3.16227766e+04 5.62341325e+04<br> 1.00000000e+05 1.77827941e+05 3.16227766e+05 5.62341325e+05<br> 1.00000000e+06]<br>  energy_bins     : [1.33352143e+02 2.37137371e+02 4.21696503e+02 7.49894209e+02<br> 1.33352143e+03 2.37137371e+03 4.21696503e+03 7.49894209e+03<br> 1.33352143e+04 2.37137371e+04 4.21696503e+04 7.49894209e+04<br> 1.33352143e+05 2.37137371e+05 4.21696503e+05 7.49894209e+05]<br>  error_msg       : <br></pre></div> </details>   \n",
       "\n",
       "\n",
       "\n",
       "##### config.cache -- a file cache\n",
       "The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
       "`/home/burnett/.cache/wtlike`\n",
       "\n",
       "<details  class=\"nbdoc-description\" >  <summary> current cache contents </summary>  <div style=\"margin-left: 5%\"><pre>Cache at /home/burnett/.cache/wtlike is empty<br></pre></div> </details>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fe4e6f68a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "def summary():\n",
    "    \"\"\"\n",
    "    \n",
    "    #### config.Config -- parameters are from three sources:\n",
    "    - defaults\n",
    "    - the file `~/.config/wtlike/config.yaml` if it exists\n",
    "    - keyword args in Config constructor. For example, to suppress all printout:\n",
    "        ```\n",
    "    config = Config(verbose=0)\n",
    "    ```\n",
    "    \n",
    "    ##### Config defaults\n",
    "    This is yaml-format, corresponding to `config.yaml`.\n",
    "    {config_defaults}\n",
    "    \n",
    "    \n",
    "    #### Config contents as set up here\n",
    "    {config_text}   \n",
    "\n",
    "\n",
    "    \n",
    "    ##### config.cache -- a file cache\n",
    "    The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
    "    `{config.cachepath}`\n",
    "    \n",
    "    {cache_text}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    config_defaults = Config.defaults\n",
    "    config_text = monospace(config, summary='config parameter list')\n",
    "\n",
    "    try:\n",
    "        cache_text = monospace(config.cache, 'current cache contents' )\n",
    "    except Exception as msg:\n",
    "        cache_text = f'(Failed: {msg})'\n",
    "\n",
    "\n",
    "    return locals()\n",
    "nbdoc(summary) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time\n",
    "- UTCnow: current ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "#mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "# From a FT2 file header\n",
    "# MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "# MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "mission_start = 51910.00074287037\n",
    "\n",
    "def MJD(arg):\n",
    "\n",
    "    if type(arg)==str:\n",
    "        while len(arg.split('-'))<3:\n",
    "            arg+='-1'\n",
    "        return Time(arg, format='iso').mjd\n",
    "\n",
    "    \"convert MET or UTC to MJD\"\n",
    "    return (mission_start + arg/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value\n",
    "\n",
    "def UTCnow():\n",
    "    from datetime import datetime\n",
    "    t=datetime.utcnow()\n",
    "    return f'UTC {t.year}-{t.month:02d}-{t.day} {t.hour:02d}:{t.minute:02d}'\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2001-01-01 00:01', '2008-08-05 00:00', 'UTC 2021-08-14 15:56')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UTC(MJD(0)), UTC(first_data), UTCnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'\n",
    "assert MJD('2008')==54466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bin_size_name(bins):\n",
    "    \"\"\"Provide a nice name, e.g., 'day' for a time interval\n",
    "    \"\"\"\n",
    "    if np.isscalar(bins) :\n",
    "        binsize = bins\n",
    "    else:\n",
    "        binsize = np.mean(bins)\n",
    "\n",
    "    def check_unit(x):\n",
    "        unit_table = dict(week=1/7, day=1, hour=24, min=24*60, s=24*3600)\n",
    "        for name, unit in unit_table.items():\n",
    "            t = x*unit\n",
    "            r = np.mod(t+1e-9,1)\n",
    "            if r<1e-6 or t>1:\n",
    "                return t, name\n",
    "        return x, 'day'\n",
    "    n, unit =  check_unit(binsize)\n",
    "    nt = f'{n:.0f}' if np.mod(n,1)<1e-2 else f'{n:.0f}'\n",
    "    return f'{nt}-{unit}'# if n>1 else f'{unit}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def decorate_with(other_func):\n",
    "    def decorator(func):\n",
    "        func.__doc__ += other_func.__doc__\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def df_4fgl():\n",
    "    \"\"\"Return a DataFrame with a summary of the 4FGL-DR3 catalog\n",
    "    \"\"\"\n",
    "    \n",
    "    from pathlib import Path\n",
    "    from astropy.io import fits\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    import pandas as pd\n",
    "    \n",
    "    catfile = Path(Config().catalog_file).expanduser()\n",
    "    if not catfile.exists(): return\n",
    "    \n",
    "    with fits.open(catfile) as hdu:\n",
    "        cat = hdu[1].data\n",
    "    \n",
    "    # return columns: strip the names, convert floats to little endian\n",
    "    cname = lambda n : [s.strip() for s in cat[n]]\n",
    "    cvar = lambda a: cat[a].astype(float)\n",
    "    # use this to get (ra,dec) and (l,b) pairs\n",
    "    skycoord = SkyCoord(cvar('RAJ2000'), cvar('DEJ2000'), unit='deg', frame='fk5')\n",
    "\n",
    "    catdf = pd.DataFrame(dict(\n",
    "\n",
    "        fk5 = zip( (skycoord.ra.deg).round(3),\n",
    "                   (skycoord.dec.deg).round(3)),\n",
    "        gal = zip( (skycoord.galactic.l.deg).round(3), \n",
    "                   (skycoord.galactic.b.deg).round(3)),\n",
    "        significance = cvar('Signif_Avg'),\n",
    "        variability = cvar('Variability_Index'),\n",
    "        assoc_prob = cvar('ASSOC_PROB_BAY'),\n",
    "        assoc_name = cname('ASSOC1'),\n",
    "        \n",
    "        ))\n",
    "    catdf.index = cname('Source_Name')\n",
    "    catdf.index.name='name'\n",
    "    return catdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk5</th>\n",
       "      <th>gal</th>\n",
       "      <th>significance</th>\n",
       "      <th>variability</th>\n",
       "      <th>assoc_prob</th>\n",
       "      <th>assoc_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4FGL J0000.3-7355</th>\n",
       "      <td>(0.098, -73.922)</td>\n",
       "      <td>(307.709, -42.73)</td>\n",
       "      <td>7.46</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4FGL J0000.5+0743</th>\n",
       "      <td>(0.138, 7.727)</td>\n",
       "      <td>(101.656, -53.029)</td>\n",
       "      <td>5.27</td>\n",
       "      <td>25.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4FGL J0000.7+2530</th>\n",
       "      <td>(0.188, 25.515)</td>\n",
       "      <td>(108.775, -35.959)</td>\n",
       "      <td>4.18</td>\n",
       "      <td>13.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4FGL J0001.2+4741</th>\n",
       "      <td>(0.313, 47.686)</td>\n",
       "      <td>(114.25, -14.338)</td>\n",
       "      <td>4.69</td>\n",
       "      <td>25.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B3 2358+474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4FGL J0001.2-0747</th>\n",
       "      <td>(0.315, -7.797)</td>\n",
       "      <td>(89.033, -67.305)</td>\n",
       "      <td>23.78</td>\n",
       "      <td>46.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PMN J0001-0746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fk5                 gal  significance  \\\n",
       "name                                                                    \n",
       "4FGL J0000.3-7355  (0.098, -73.922)   (307.709, -42.73)          7.46   \n",
       "4FGL J0000.5+0743    (0.138, 7.727)  (101.656, -53.029)          5.27   \n",
       "4FGL J0000.7+2530   (0.188, 25.515)  (108.775, -35.959)          4.18   \n",
       "4FGL J0001.2+4741   (0.313, 47.686)   (114.25, -14.338)          4.69   \n",
       "4FGL J0001.2-0747   (0.315, -7.797)   (89.033, -67.305)         23.78   \n",
       "\n",
       "                   variability  assoc_prob      assoc_name  \n",
       "name                                                        \n",
       "4FGL J0000.3-7355        14.60         0.0                  \n",
       "4FGL J0000.5+0743        25.40         0.0                  \n",
       "4FGL J0000.7+2530        13.65         0.0                  \n",
       "4FGL J0001.2+4741        25.31         1.0     B3 2358+474  \n",
       "4FGL J0001.2-0747        46.78         1.0  PMN J0001-0746  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "catdf = df_4fgl()\n",
    "None if catdf is None else catdf.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 03_sources.ipynb.\n",
      "Converted 04_load_data.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_main.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sat Aug 14 08:57:38 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
