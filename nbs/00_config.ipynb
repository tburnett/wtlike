{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp config\n",
    "#%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def summary():\n",
    "    \"\"\"\n",
    "    \n",
    "    ##### config.Config -- parameters\n",
    "\n",
    "    for now, but could be obtained from an editable yaml file.\n",
    "    \n",
    "    {config_text}\n",
    "    \n",
    "\n",
    "    These are dataclass classes, and can be initialized with\n",
    "    parameters. For example, to suppress printout \n",
    "        \n",
    "    ```\n",
    "    config = Config(verbose=0)\n",
    "    ```\n",
    "    \n",
    "    ##### config.cache -- a file cache\n",
    "    The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
    "    `config.files.cachepath`\n",
    "    \n",
    "    {cache_text}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    config_text = monospace(config, summary='config parameter list')\n",
    "\n",
    " \n",
    "    cache_text = monospace(config.cache, 'cache contents' )\n",
    "    assert files.valid\n",
    "    return locals()\n",
    "#nbdoc(summary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object <br> This is the folder where the index and data files are saved.\n",
    "    - `clear` -- set True to clear the cache on initialization\n",
    "\n",
    "    This uses pickle to save objects, associated with a hashable key, which is used to index the\n",
    "    filename in a file `index.pkl` in the same folder.\n",
    "\n",
    "    The `__call__` function is a convenient way to use it, so one call may either store a new entry or retrieve an existing one.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if not self.path: return\n",
    "        if not self.path.exists() :\n",
    "            raise Exception(f'cache Path {self.path} does not exist ')\n",
    "\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():\n",
    "            if clear:\n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists():\n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "\n",
    "    def add(self, key, object, exist_ok=False):\n",
    "        if not self.path: return\n",
    "        assert type(key)==str, f'Expect key to be a string, got {key}'\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index()\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        if not filename.exists():\n",
    "            # perhaps deleted by another instance?\n",
    "            print(f'File for Cache key {key} not found, removing entry', file='sys.stderr')\n",
    "            selt.pop(key)\n",
    "            return None\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "\n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file:\n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "\n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        try:\n",
    "            filename.unlink()\n",
    "        except:\n",
    "            print(f'Failed to unlink file {filename}')\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "\n",
    "\n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "\n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If None, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "        - `overwrite` -- if set, overwrite previous entry if exists\n",
    "\n",
    "        Example:\n",
    "        <pre>\n",
    "        mycache = Cache('/tmp/thecache', clear=True)\n",
    "\n",
    "        def myfun(x):\n",
    "            return x\n",
    "\n",
    "        result = mycache('mykey', myfun, x=99,  description='My data')\n",
    "\n",
    "        </pre>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if key is None:\n",
    "            return func(*pars, **kwargs)\n",
    "\n",
    "        ret = self.get(key)\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self or overwrite else \"Restoring from\"} cache', end='')\n",
    "            print('' if key == description else f' with key \"{key}\"')\n",
    "\n",
    "        if ret is None or overwrite:\n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret, exist_ok=overwrite)\n",
    "        return ret\n",
    "\n",
    "    def show(self, starts_with=''):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        title = 'Cache contents' if not starts_with else f'Cache entries starting with {starts_with}'\n",
    "        s = f'{title}\\n {\"key\":30}   {\"size\":>10}  {\"time\":20} {\"name\"}, in folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None or not name.startswith(starts_with) : continue\n",
    "            try:\n",
    "                stat = value.stat()\n",
    "                size = stat.st_size\n",
    "                mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "                s += f'  {name:30s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "            except Exception as msg:\n",
    "                s += f'{name} -- file not found'\n",
    "        return s\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m511\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Create a new directory at this given path.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.7/pathlib.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = Path('/tmp/cache')\n",
    "p.mkdir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L96\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If None, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "- `overwrite` -- if set, overwrite previous entry if exists\n",
       "\n",
       "Example:\n",
       "<pre>\n",
       "mycache = Cache('/tmp/thecache', clear=True)\n",
       "\n",
       "def myfun(x):\n",
       "    return x\n",
       "\n",
       "result = mycache('mykey', myfun, x=99,  description='My data')\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cache.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse_hide\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "   \n",
    "    \n",
    "    c.clear()\n",
    "\n",
    "test_path = Path('/tmp/cache_test').mkdir(exist_ok=True)\n",
    "#??cache_test(test_path)\n",
    "# disabled should ignore\n",
    "#cache_test(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Default light curve configuration parameters\"\"\"\n",
    "    verbose : int = 1\n",
    "\n",
    "    # data source: if set, expect all data files here\n",
    "    wtlike_data:  str = '~/wtlike_data' # wired in for convenience\n",
    "\n",
    "    # cache\n",
    "    cachepath: str = '~/wtlike_cache'\n",
    "\n",
    "    radius: float = 4\n",
    "    cos_theta_max:float=0.4\n",
    "    z_max : float=100\n",
    "\n",
    "    # binning\n",
    "    energy_edges = np.logspace(2,6,17)\n",
    "    etypes = (0,1)\n",
    "\n",
    "    week_range: Tuple=(None,None)\n",
    "\n",
    "    time_bins: Tuple=(0,0,7)\n",
    "\n",
    "    use_uint8: bool=False  # for weights\n",
    "\n",
    "    # healpix data representation used by data\n",
    "    nside : int=1024\n",
    "    nest: bool=True\n",
    "\n",
    "    # exposure calculation\n",
    "    bins_per_decade: int=5\n",
    "    base_spectrum: str='lambda E: (E/1000)**-2.1'\n",
    "    energy_range: Tuple = (100.,1e6)\n",
    "\n",
    "    # analysis\n",
    "    likelihood_rep: str='poisson'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # set up data\n",
    "        self.errors=[]\n",
    "        if self.wtlike_data is None:\n",
    "            self.errors.append('wtlike_data must be set')\n",
    "        if self.cachepath is None:\n",
    "            self.errors.appnd('wtlike_cache must be set')\n",
    "        self.wtlike_data = df = Path(self.wtlike_data).expanduser()\n",
    "        self.cachepath =  Path(self.cachepath).expanduser()\n",
    "        if not self.wtlike_data.is_dir() and not self.wtlike_data.is_symlink():\n",
    "            self.errors.append(f'data_folder {df} not a directory or symlink')\n",
    "        subs = 'aeff_files weight_files data_files'.split()\n",
    "        for sub in subs:\n",
    "            if not (df/sub).is_dir() and (df/sub).is_symlink() :\n",
    "                self.errors.append(f'{df/sub} is not a directory or symlink')\n",
    "        if self.verbose>1:\n",
    "            print(self)\n",
    "\n",
    "    @property\n",
    "    def cache(self):\n",
    "        if not hasattr(self, '_cache'):\n",
    "            self._cache = Cache(self.cachepath, clear=False)\n",
    "        return self._cache\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        return len(self.errors)==0\n",
    "\n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files' or name.startswith('_'): continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "\n",
    "def MJD(met):\n",
    "    \"convert MET to MJD\"\n",
    "    #mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "    # From a FT2 file header\n",
    "    # MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "    # MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "    mission_start = 51910.00074287037\n",
    "    return (mission_start + met/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bin_size_name(bins):\n",
    "    \"\"\"Provide a nice name, e.g., 'day' for a time interval\n",
    "    \"\"\"\n",
    "    if np.isscalar(bins) :\n",
    "        binsize = bins\n",
    "    else:\n",
    "        binsize = np.mean(bins)\n",
    "\n",
    "    def check_unit(x):\n",
    "        unit_table = dict(week=1/7, day=1, hour=24, min=24*60, s=24*3600)\n",
    "        for name, unit in unit_table.items():\n",
    "            t = x*unit\n",
    "            r = np.mod(t+1e-9,1)\n",
    "            if r<1e-6 or t>1:\n",
    "                return t, name\n",
    "        return x, 'day'\n",
    "    n, unit =  check_unit(binsize)\n",
    "    nt = f'{n:.0f}' if np.mod(n,1)<1e-2 else f'{n:.0f}'\n",
    "    return f'{nt}-{unit}'# if n>1 else f'{unit}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print([bin_size_name(x) for x in [0.25, 1, 2, 1/24, 2/24, 2.1/24/60, 14]])\n",
    "# bin_size_name(np.linspace(0,10,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "class PointSource():\n",
    "    \"\"\"Manage the position and name of a point source\n",
    "    \"\"\"\n",
    "    def __init__(self, name, position=None):\n",
    "        \"\"\"position: (l,b) tuple or None. if None, expect to be found by lookup\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        if position is None:\n",
    "            try:\n",
    "                skycoord = SkyCoord.from_name(name)\n",
    "            except Exception as e:\n",
    "                print(f'PointSource: a source \"{name}\" was not recognized by SkyCoord: {e}', file=sys.stderr)\n",
    "                raise\n",
    "            gal = skycoord.galactic\n",
    "            self.l,self.b = (gal.l.value, gal.b.value)\n",
    "        else:\n",
    "            self.l,self.b = position\n",
    "            skycoord = SkyCoord(self.l,self.b, unit='deg', frame='galactic')\n",
    "        self.skycoord = skycoord\n",
    "    def __str__(self):\n",
    "        return f'Source \"{self.name}\" at: (l,b)=({self.l:.3f},{self.b:.3f})'\n",
    "    def __repr__(self): return str(self)\n",
    "\n",
    "    @property\n",
    "    def ra(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.ra.value\n",
    "    @property\n",
    "    def dec(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.dec.value\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        \"\"\"Modified name for file system\"\"\"\n",
    "        return self.name.replace(' ', '_').replace('+','p')\n",
    "\n",
    "    @classmethod\n",
    "    def fk5(cls, name, position):\n",
    "        \"\"\"position: (ra,dec) tuple \"\"\"\n",
    "        ra,dec = position\n",
    "        sk = SkyCoord(ra, dec, unit='deg',  frame='fk5').transform_to('galactic')\n",
    "        return cls(name, (sk.l.value, sk.b.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"PointSource.fk5\" class=\"doc_header\"><code>PointSource.fk5</code><a href=\"__main__.py#L39\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PointSource.fk5</code>(**`name`**, **`position`**)\n",
       "\n",
       "position: (ra,dec) tuple "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PointSource.fk5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, expect in [( PointSource('Geminga'),             'Source \"Geminga\" at: (l,b)=(195.134,4.266)'),\n",
    "                  ( PointSource('gal_source', (0,0)),   'Source \"gal_source\" at: (l,b)=(0.000,0.000)', ),\n",
    "                  ( PointSource.fk5('fk5_source',(0,0)),'Source \"fk5_source\" at: (l,b)=(96.337,-60.189)',)\n",
    "                   ]:    \n",
    "    assert str(s)==expect, f'expected {expect}, got {str(s)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decorate_with(other_func):\n",
    "    def decorator(func):\n",
    "        func.__doc__ += other_func.__doc__\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_weights.ipynb.\n",
      "Converted 04_exposure.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_main.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Thu May 20 06:28:04 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache is a mixin for a class ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import pickle\n",
    "# config = Config(cachepath='/tmp/cache')\n",
    "# config.cache\n",
    "\n",
    "# !ls -l /tmp/cache\n",
    "# ! rm -f /tmp/cache/index.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-48aa60fb940a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mCacheMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-48aa60fb940a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mCacheMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'cache'"
     ]
    }
   ],
   "source": [
    "# class CacheMixin(object):\n",
    "#     def __init__(self, cache):\n",
    "#         self.cache = cache\n",
    "\n",
    "# class TestCache(CacheMixin):\n",
    "#     def __init__(self,  config):\n",
    "#         Path('/tmp/cache').mkdir(exist_ok=True)\n",
    "#         CacheMixin.__init__(config.cache)\n",
    "       \n",
    "# tc = TestCache(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
