{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp config\n",
    "\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements:\n",
    "\n",
    "- Cache\n",
    "- Config\n",
    "- MJD\n",
    "- UTC, UTCnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "# from astropy.coordinates import SkyCoord, Angle\n",
    "import astropy.units as u\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object <br> This is the folder where the index and data files are saved.\n",
    "    - `clear` -- set True to clear the cache on initialization\n",
    "\n",
    "    This uses pickle to save objects, associated with a hashable key, which is used to index the\n",
    "    filename in a file `index.pkl` in the same folder.\n",
    "\n",
    "    The `__call__` function is a convenient way to use it, so one call may either store a new entry or retrieve an existing one.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if self.path is None: return\n",
    "        if not self.path.exists() :\n",
    "            print(f'Warning: cache Path {self.path} does not exist, cache disabled ',file=sys.stderr)\n",
    "            self.path=None\n",
    "            return\n",
    "\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():\n",
    "            if clear:\n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists():\n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "\n",
    "    def add(self, key, object,  exist_ok=False):\n",
    "        if not self.path: return\n",
    "        assert type(key)==str, f'Expect key to be a string, got {key}'\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index()\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        if not filename.exists():\n",
    "            # perhaps deleted by another instance?\n",
    "            print(f'File for Cache key {key} not found, removing entry', file='sys.stderr')\n",
    "            selt.pop(key)\n",
    "            return None\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "\n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file:\n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "\n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        try:\n",
    "            filename.unlink()\n",
    "        except:\n",
    "            print(f'Failed to unlink file {filename}')\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "\n",
    "\n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "\n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If None, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "        - `overwrite` -- if set, overwrite previous entry if exists\n",
    "\n",
    "        Example:\n",
    "        <pre>\n",
    "        mycache = Cache('/tmp/thecache', clear=True)\n",
    "\n",
    "        def myfun(x):\n",
    "            return x\n",
    "\n",
    "        result = mycache('mykey', myfun, x=99,  description='My data')\n",
    "\n",
    "        </pre>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if key is None or self.path is None:\n",
    "            return func(*pars, **kwargs)\n",
    "\n",
    "\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self or overwrite else \"Restoring from\"} cache', end='')\n",
    "            print('' if key == description else f' with key \"{key}\"')\n",
    "        ret = self.get(key)\n",
    "        if ret is None or overwrite:\n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret, exist_ok=overwrite)\n",
    "        return ret\n",
    "\n",
    "    def show(self, starts_with=''):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        if len(self.items())==0: return f'Cache at {self.path} is empty\\n'\n",
    "        title = 'Cache contents' if not starts_with else f'Cache entries starting with {starts_with}'\n",
    "        s = f'{title}\\n {\"key\":30}   {\"size\":>10}  {\"time\":20} {\"name\"}, folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None or not name.startswith(starts_with) : continue\n",
    "            try:\n",
    "                stat = value.stat()\n",
    "                size = stat.st_size\n",
    "                mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "                s += f'  {name:30s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "            except Exception as msg:\n",
    "                s += f'{name} -- file not found\\n'\n",
    "        return s\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L99\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If None, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "- `overwrite` -- if set, overwrite previous entry if exists\n",
       "\n",
       "Example:\n",
       "<pre>\n",
       "mycache = Cache('/tmp/thecache', clear=True)\n",
       "\n",
       "def myfun(x):\n",
       "    return x\n",
       "\n",
       "result = mycache('mykey', myfun, x=99,  description='My data')\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cache.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "Test: Saving to cache with key \"four\"\n",
      "Test: Restoring from cache with key \"four\"\n",
      "Before remove:\n",
      "Cache contents\n",
      " key                                    size  time                 name, folder /tmp/cache_test\n",
      "  one                                     18  2022-05-03 04:42     cache_file_6f8be229af54c761.pkl\n",
      "  two                                     18  2022-05-03 04:42     cache_file_39432e3c365956ca.pkl\n",
      "  four                                    23  2022-05-03 04:42     cache_file_5532bc2bc6bf921.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for key \"two\" exists\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "    c.clear()\n",
    "\n",
    "test_path = Path('/tmp/cache_test')\n",
    "test_path.mkdir(exist_ok=True)\n",
    "cache_test(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Config():\n",
    "    defaults=\\\n",
    "    \"\"\"\n",
    "        verbose         : 1 # set to zero for no output\n",
    "        usermode        : true # default suppress warnings\n",
    "\n",
    "        datapath        : None # where to find data--must be set\n",
    "        cachepath       : ~/.cache/wtlike #\n",
    "\n",
    "        # Expect 4FGL FITS file, e.g.,  gll_psc_v28.fit\n",
    "        catalog_file    :\n",
    "\n",
    "        # data cuts, processing\n",
    "        radius          : 4\n",
    "        cos_theta_max   : 0.4\n",
    "        z_max           : 100\n",
    "        offset_size     : 2.e-06  # scale factor used for event time\n",
    "\n",
    "        # binning -- actually determined by weight run\n",
    "        energy_edge_pars : [2,6,17] # pars for np.logspace\n",
    "        etypes          : [0, 1] # front, back\n",
    "        nside           : 1024\n",
    "        nest            : True\n",
    "\n",
    "        # multiprocessing\n",
    "        pool_size       : 1 # number of pool processes to use\n",
    "\n",
    "        # data selection for cell creation\n",
    "        week_range      : []  # default all weeks found\n",
    "        time_bins       : [0, 0, 7] # full MJD range, 7-day cells\n",
    "        exp_min         : 5    # threshold for exposure per day, in cm^2 Ms units.\n",
    "\n",
    "        # cell fitting\n",
    "        use_kerr        : True  # Use the Kerr power-law exposure weighting\n",
    "        likelihood_rep  : poisson\n",
    "        poisson_tolerance : 0.2\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        import yaml\n",
    "        from yaml import SafeLoader\n",
    "\n",
    "        # parameters: first defaults, then from ~/.config/wtlike/config.yaml, then kwars\n",
    "        pars = yaml.load(self.defaults, Loader=SafeLoader)\n",
    "        dp = Path('~/.config/wtlike/config.yaml').expanduser()\n",
    "        if dp.is_file():\n",
    "            userpars = yaml.load(open(dp,'r'), Loader=SafeLoader)\n",
    "            pars.update(userpars)\n",
    "            #print(f'update from user file {dp}: {userpars}')\n",
    "        pars.update(kwargs)\n",
    "\n",
    "        self.__dict__.update(pars)\n",
    "\n",
    "        # suppress warnings unless testing or in usermode\n",
    "        if self.usermode:\n",
    "            if not sys.warnoptions:\n",
    "                import warnings\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        self.energy_edges = ee=np.logspace(*self.energy_edge_pars)\n",
    "        self.energy_bins = np.sqrt(ee[1:] * ee[:-1])\n",
    "        if not self.week_range:\n",
    "            self.week_range = (None, None)\n",
    "\n",
    "       # set up, check files paths\n",
    "        self.error_msg=''\n",
    "        if self.datapath is None:\n",
    "            self.error_msg+='\\ndatapath must be a folder with wtlike data'\n",
    "        else:\n",
    "            self.datapath = df = Path(self.datapath).expanduser()\n",
    "            if not (self.datapath.is_dir() or  self.datapath.is_symlink()):\n",
    "                self.error_msg+=f'\\ndata_folder \"{df}\" is not a directory or symlink'\n",
    "            subs = 'aeff_files weight_files data_files'.split()\n",
    "            for sub in subs:\n",
    "                if not ( (df/sub).is_dir() or  (df/sub).is_symlink()) :\n",
    "                    self.error_msg+=f'\\n{df/sub} is not a directory or symlink'\n",
    "\n",
    "        self.cachepath =  Path(self.cachepath).expanduser()\n",
    "        os.makedirs(self.cachepath, exist_ok=True)\n",
    "        if not self.cachepath.is_dir():\n",
    "            self.error_msg +=f'cachepath {self.cachepath} is not a folder.'\n",
    "\n",
    "    @property\n",
    "    def cache(self):\n",
    "        if not hasattr(self, '_cache'):\n",
    "            self._cache = Cache(self.cachepath, clear=False)\n",
    "        return self._cache\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        if len(self.error_msg)==0: return True\n",
    "        print(f'wtlike configuration is invalid:\\n{self.error_msg}',file=sys.stderr)\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files' or name.startswith('_'): continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)\n",
    "    def get(self, *pars): return self.__dict__.get(*pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Config\" class=\"doc_header\"><code>class</code> <code>Config</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Config</code>(**\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### config.Config -- parameters are from three sources:\n",
       "- defaults\n",
       "- the file `~/.config/wtlike/config.yaml` if it exists\n",
       "- keyword args in Config constructor. For example, to suppress all printout:\n",
       "    ```\n",
       "config = Config(verbose=0)\n",
       "```\n",
       "\n",
       "##### Config defaults\n",
       "This is yaml-format, corresponding to `config.yaml`.\n",
       "\n",
       "        verbose         : 1 # set to zero for no output\n",
       "        usermode        : true # default suppress warnings\n",
       "\n",
       "        datapath        : None # where to find data--must be set\n",
       "        cachepath       : ~/.cache/wtlike #\n",
       "\n",
       "        # Expect 4FGL FITS file, e.g.,  gll_psc_v28.fit\n",
       "        catalog_file    :\n",
       "\n",
       "        # data cuts, processing\n",
       "        radius          : 4\n",
       "        cos_theta_max   : 0.4\n",
       "        z_max           : 100\n",
       "        offset_size     : 2.e-06  # scale factor used for event time\n",
       "\n",
       "        # binning -- actually determined by weight run\n",
       "        energy_edge_pars : [2,6,17] # pars for np.logspace\n",
       "        etypes          : [0, 1] # front, back\n",
       "        nside           : 1024\n",
       "        nest            : True\n",
       "\n",
       "        # multiprocessing\n",
       "        pool_size       : 1 # number of pool processes to use\n",
       "\n",
       "        # data selection for cell creation\n",
       "        week_range      : []  # default all weeks found\n",
       "        time_bins       : [0, 0, 7] # full MJD range, 7-day cells\n",
       "        exp_min         : 5    # threshold for exposure per day, in cm^2 Ms units.\n",
       "\n",
       "        # cell fitting\n",
       "        use_kerr        : True  # Use the Kerr power-law exposure weighting\n",
       "        likelihood_rep  : poisson\n",
       "        poisson_tolerance : 0.2\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "#### Config contents as set up here\n",
       "<details  class=\"nbdoc-description\" >  <summary> config parameter list </summary>  <div style=\"margin-left: 5%;\"><pre>Configuration parameters <br>  verbose         : 1<br>  usermode        : True<br>  datapath        : /home/burnett/fermi/wtlike-data<br>  cachepath       : /home/burnett/.cache/wtlike<br>  catalog_file    : /home/burnett/fermi/catalog/gll_psc_v28.fit<br>  radius          : 4<br>  cos_theta_max   : 0.4<br>  z_max           : 100<br>  offset_size     : 2e-06<br>  energy_edge_pars : [2, 6, 17]<br>  etypes          : [0, 1]<br>  nside           : 1024<br>  nest            : True<br>  pool_size       : 1<br>  week_range      : (None, None)<br>  time_bins       : [0, 0, 7]<br>  exp_min         : 5<br>  use_kerr        : True<br>  likelihood_rep  : poisson<br>  poisson_tolerance : 0.2<br>  energy_edges    : [1.00000000e+02 1.77827941e+02 3.16227766e+02 5.62341325e+02<br> 1.00000000e+03 1.77827941e+03 3.16227766e+03 5.62341325e+03<br> 1.00000000e+04 1.77827941e+04 3.16227766e+04 5.62341325e+04<br> 1.00000000e+05 1.77827941e+05 3.16227766e+05 5.62341325e+05<br> 1.00000000e+06]<br>  energy_bins     : [1.33352143e+02 2.37137371e+02 4.21696503e+02 7.49894209e+02<br> 1.33352143e+03 2.37137371e+03 4.21696503e+03 7.49894209e+03<br> 1.33352143e+04 2.37137371e+04 4.21696503e+04 7.49894209e+04<br> 1.33352143e+05 2.37137371e+05 4.21696503e+05 7.49894209e+05]<br>  error_msg       : <br></pre></div> </details>   \n",
       "\n",
       "\n",
       "\n",
       "##### config.cache -- a file cache\n",
       "The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
       "`/home/burnett/.cache/wtlike`\n",
       "\n",
       "<details  class=\"nbdoc-description\" >  <summary> current cache contents </summary>  <div style=\"margin-left: 5%;\"><pre>Cache contents<br> key                                    size  time                 name, folder /home/burnett/.cache/wtlike<br>  P88Y0839_data                    135087218  2021-12-09 10:24     cache_file_8f49ffbb40f6cf6.pkl<br>  P88Y1621_data                    107292391  2021-12-09 10:35     cache_file_49a44b1cafa987f1.pkl<br>  PSR J1826-1256_data              136536785  2021-12-09 16:23     cache_file_a8ee594ce4a0d23.pkl<br>  P88Y4434_data                    115585160  2021-12-14 12:17     cache_file_ea9875c41d155b8.pkl<br>  PSR J0835-4510_data              163972071  2022-03-24 11:49     cache_file_399d710d5471fbc4.pkl<br>  PSR J0633+1746_data              117364633  2022-03-23 13:30     cache_file_57c899e951e2b4.pkl<br>  P88Y3243_data                     98383177  2021-12-15 08:03     cache_file_1e5998dac531f886.pkl<br>  P88Y4744_data                    142982565  2022-01-10 13:49     cache_file_2f39212c4f1593.pkl<br>  PSR J1709-4429_data              134198524  2022-01-10 13:56     cache_file_9d363406414a4fe.pkl<br>  PSR J0205+6449_data              142684766  2022-01-10 14:04     cache_file_59324d9896384e55.pkl<br>  P88Y5020_data                    133814110  2022-01-10 14:11     cache_file_d1961115fc8ad1a.pkl<br>  PSR J1813-1246_data              130999543  2022-01-10 14:18     cache_file_66c22c86184760b.pkl<br>  P88Y4996_data                    136648585  2022-01-10 14:41     cache_file_390f2ec0123e06a8.pkl<br>  PSR J1836+5925_data              138099988  2022-01-29 09:28     cache_file_4cf2c6ef9e8e4391.pkl<br>  PSR J0007+7303_data              144483213  2022-01-29 09:35     cache_file_9118b9b420eaeac.pkl<br>  PSR J1057-5226_data              111852404  2022-01-29 09:43     cache_file_36f08f8931993de.pkl<br>  PSR J0534+2200_data              120459827  2022-01-29 09:51     cache_file_5c194f3ba9839d.pkl<br>  PSR J0614-3329_data              102991649  2022-01-29 09:58     cache_file_e59455e871b54c2.pkl<br>  PSR J2021+3651_data              139760141  2022-01-29 10:06     cache_file_7edc70eff46418a.pkl<br>  PSR J1231-1411_data               97580750  2022-01-29 10:14     cache_file_48cde18e4ff8d7e.pkl<br>  504F-1187_data                   125944587  2022-01-30 09:30     cache_file_7aa9c4634b9bc359.pkl<br>  PSR J2021+4026_data              144574909  2022-02-10 13:45     cache_file_c6a0ca9d4d493c1.pkl<br>  PSR J1809-2332_data              129902712  2022-02-10 13:53     cache_file_7d0bdab4612d158.pkl<br>  PSR J1907+0602_data              131716816  2022-02-11 07:06     cache_file_2692651f8ebac87.pkl<br>  P88Y2741_data                    120835877  2022-03-15 15:27     cache_file_7ed05b488735d4.pkl<br>  P88Y0643_data                     94996984  2022-03-17 09:48     cache_file_cae40ada2d216cf.pkl<br>  504H-0317_data                   132398851  2022-03-20 03:04     cache_file_294d0d01edc3ec7.pkl<br>  P88Y4842_data                    124862808  2022-05-02 15:01     cache_file_8998e475010a987.pkl<br>  P88Y6076_data                    105662092  2022-05-02 15:21     cache_file_f77ebbb3092935b.pkl<br></pre></div> </details>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7f3c834f1ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "@ipynb_doc\n",
    "def summary():\n",
    "    \"\"\"\n",
    "    \n",
    "    #### config.Config -- parameters are from three sources:\n",
    "    - defaults\n",
    "    - the file `~/.config/wtlike/config.yaml` if it exists\n",
    "    - keyword args in Config constructor. For example, to suppress all printout:\n",
    "        ```\n",
    "    config = Config(verbose=0)\n",
    "    ```\n",
    "    \n",
    "    ##### Config defaults\n",
    "    This is yaml-format, corresponding to `config.yaml`.\n",
    "    {config_defaults}\n",
    "    \n",
    "    \n",
    "    #### Config contents as set up here\n",
    "    {config_text}   \n",
    "\n",
    "\n",
    "    \n",
    "    ##### config.cache -- a file cache\n",
    "    The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
    "    `{config.cachepath}`\n",
    "    \n",
    "    {cache_text}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    config_defaults = Config.defaults\n",
    "    config_text = monospace(config, summary='config parameter list')\n",
    "\n",
    "    try:\n",
    "        cache_text = monospace(config.cache, 'current cache contents' )\n",
    "    except Exception as msg:\n",
    "        cache_text = f'(Failed: {msg})'\n",
    "\n",
    "\n",
    "    return locals()\n",
    "summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time\n",
    "- UTCnow: current ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "#mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "# From a FT2 file header\n",
    "# MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "# MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "mission_start = 51910.00074287037\n",
    "from datetime import datetime\n",
    "\n",
    "def MJD(arg):\n",
    "    \"\"\" convert MET or UTC to MJD\n",
    "    \"\"\"\n",
    "\n",
    "    if type(arg)==str:\n",
    "        if arg=='now':\n",
    "            return Time(datetime.utcnow()).mjd\n",
    "        while len(arg.split('-'))<3:\n",
    "            arg+='-1'\n",
    "        return Time(arg, format='iso').mjd\n",
    "\n",
    "\n",
    "    return (mission_start + arg/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value\n",
    "\n",
    "def UTCnow():\n",
    "    \"\"\" current UTC \"\"\"\n",
    "    t=datetime.utcnow()\n",
    "    return f'UTC {t.year}-{t.month:02d}-{t.day} {t.hour:02d}:{t.minute:02d}'\n",
    "\n",
    "def mission_week(mjd):\n",
    "    \"\"\" return the mission week number for a MJD value\n",
    "    (Note that week #0 starts on UTC Thursday 2008-05-29 00:00, the first data is in week 9, and that week 525 is missing)\n",
    "    \"\"\"\n",
    "    return (mjd-54615)//(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2001-01-01 00:01',\n",
       " '2008-08-05 00:00',\n",
       " 'UTC 2022-05-3 11:44',\n",
       " 59702.48934774685,\n",
       " '2022-05-03 11:44')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UTC(MJD(0)), UTC(first_data), UTCnow(), MJD('now'), UTC(MJD('now'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'\n",
    "assert MJD('2008')==54466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bin_size_name(bins):\n",
    "    \"\"\"Provide a nice name, e.g., 'day' for a time interval\n",
    "    \"\"\"\n",
    "    if np.isscalar(bins) :\n",
    "        binsize = bins\n",
    "    else:\n",
    "        binsize = np.mean(bins)\n",
    "\n",
    "    def check_unit(x):\n",
    "        unit_table = dict(year=1/365.25, week=1/7, day=1, hour=24, min=24*60) #, min=24*60, s=24*3600)\n",
    "        for name, unit in unit_table.items():\n",
    "            t = x*unit\n",
    "            r = np.mod(t+1e-9,1)\n",
    "\n",
    "            if r<1e-6 : #or t>1:\n",
    "                return t, name\n",
    "        return x, 'day'\n",
    "    n, unit =  check_unit(binsize)\n",
    "    nt = f'{n:.0f}' if np.mod(n,1)<1e-3 else f'{n:.1f}'\n",
    "    return f'{nt}-{unit}'# if n>1 else f'{unit}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15-min', '1-day', '2-day', '1-week', '10656-min', '1-year']\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print([bin_size_name(x) for x in (1/96, 1,2,7, 7.4, 365.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def decorate_with(other_func):\n",
    "    def decorator(func):\n",
    "        func.__doc__ += other_func.__doc__\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import time\n",
    "\n",
    "class Timer():\n",
    "    \"\"\"Usage:\n",
    "    ```\n",
    "    with Timer() as t:\n",
    "        time.sleep(5)\n",
    "    print(t)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.t=time.time()\n",
    "        self.exit_time=1e6\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, *pars):\n",
    "        self.exit_time = time.time()-self.t\n",
    "    def __repr__(self):\n",
    "         return  f'elapsed time: {self.elapsed:.1f}s ({self.elapsed/60:.1f} min)'\n",
    "    @property\n",
    "    def elapsed(self):\n",
    "        return min(time.time()-self.t, self.exit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intemediate elapsed time: 2.0s (0.0 min)\n",
      "Final elapsed time: 5.0s (0.1 min)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "with Timer() as t:\n",
    "    time.sleep(2)\n",
    "    print('intemediate',t)\n",
    "    time.sleep(3)\n",
    "print('Final',t)\n",
    "assert(abs(t.elapsed -5)<0.1), f'wrong elapsed time: {t.elapsed}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 03_sources.ipynb.\n",
      "Converted 04_load_data.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10-time_series.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_main.ipynb.\n",
      "Converted 99_presentation.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Wed Mar 23 13:44:42 PDT 2022\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
