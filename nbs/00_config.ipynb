{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp config\n",
    "#%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def summary():\n",
    "    \"\"\"\n",
    "    \n",
    "    ##### config.Config -- parameters\n",
    "\n",
    "    for now, but could be obtained from an editable yaml file.\n",
    "    \n",
    "    {config_text}\n",
    "    \n",
    "\n",
    "    These are dataclass classes, and can be initialized with\n",
    "    parameters. For example, to suppress printout \n",
    "        \n",
    "    ```\n",
    "    config = Config(verbose=0)\n",
    "    ```\n",
    "    \n",
    "    ##### config.cache -- a file cache\n",
    "    The class `Cache`, available from `config.cache` implements a file cache in the folder\n",
    "    `config.files.cachepath`\n",
    "    \n",
    "    {cache_text}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    config_text = monospace(config, summary='config parameter list')\n",
    "\n",
    " \n",
    "    cache_text = monospace(config.cache, 'cache contents' )\n",
    "    assert files.valid\n",
    "    return locals()\n",
    "#nbdoc(summary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object <br> This is the folder where the index and data files are saved.\n",
    "    - `clear` -- set True to clear the cache on initialization\n",
    "\n",
    "    This uses pickle to save objects, associated with a hashable key, which is used to index the\n",
    "    filename in a file `index.pkl` in the same folder.\n",
    "\n",
    "    The `__call__` function is a convenient way to use it, so one call may either store a new entry or retrieve an existing one.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if not self.path: return\n",
    "        if not self.path.exists() :\n",
    "            raise Exception(f'cache Path {self.path} does not exist ')\n",
    "\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():\n",
    "            if clear:\n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists():\n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "\n",
    "    def add(self, key, object, exist_ok=False):\n",
    "        if not self.path: return\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index()\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        if not filename.exists():\n",
    "            # perhaps deleted by another instance?\n",
    "            print(f'File for Cache key {key} not found, removing entry', file='sys.stderr')\n",
    "            selt.pop(key)\n",
    "            return None\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "\n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file:\n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "\n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        try:\n",
    "            filename.unlink()\n",
    "        except:\n",
    "            print(f'Failed to unlink file {filename}')\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "\n",
    "\n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "\n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If None, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "        - `overwrite` -- if set, overwrite previous entry if exists\n",
    "\n",
    "        Example:\n",
    "        <pre>\n",
    "        mycache = Cache('/tmp/thecache', clear=True)\n",
    "\n",
    "        def myfun(x):\n",
    "            return x\n",
    "\n",
    "        result = mycache('mykey', myfun, x=99,  description='My data')\n",
    "\n",
    "        </pre>\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if key is None:\n",
    "            return func(*pars, **kwargs)\n",
    "\n",
    "        ret = self.get(key)\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self or overwrite else \"Restoring from\"} cache', end='')\n",
    "            print('' if key == description else f' with key \"{key}\"')\n",
    "\n",
    "        if ret is None or overwrite:\n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret, exist_ok=overwrite)\n",
    "        return ret\n",
    "\n",
    "    def show(self, starts_with=''):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        title = 'Cache contents' if not starts_with else f'Cache entries starting with {starts_with}'\n",
    "        s = f'{title}\\n {\"key\":30}   {\"size\":>10}  {\"time\":20} {\"name\"}, in folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None or not name.startswith(starts_with) : continue\n",
    "            try:\n",
    "                stat = value.stat()\n",
    "                size = stat.st_size\n",
    "                mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "                s += f'  {name:30s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "            except Exception as msg:\n",
    "                s += f'{name} -- file not found'\n",
    "        return s\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L96\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If None, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "- `overwrite` -- if set, overwrite previous entry if exists\n",
       "\n",
       "Example:\n",
       "<pre>\n",
       "mycache = Cache('/tmp/thecache', clear=True)\n",
       "\n",
       "def myfun(x):\n",
       "    return x\n",
       "\n",
       "result = mycache('mykey', myfun, x=99,  description='My data')\n",
       "\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cache.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "Test: Saving to cache with key \"four\"\n",
      "Test: Restoring from cache with key \"four\"\n",
      "Before remove:\n",
      "Cache contents\n",
      " key                                    size  time                 name, in folder /tmp/test_cache\n",
      "  one                                     13  2021-05-08 17:28     cache_file_173532f865bb3057.pkl\n",
      "  two                                     13  2021-05-08 17:28     cache_file_5a805d8cbd1892a6.pkl\n",
      "  four                                    18  2021-05-08 17:28     cache_file_e27a06170a4baf7.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for key \"two\" exists\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "   \n",
    "    \n",
    "    c.clear()\n",
    "cache_test('/tmp/test_cache')\n",
    "# disabled should ignore\n",
    "#cache_test(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Default light curve configuration parameters\"\"\"\n",
    "    verbose : int = 1\n",
    "\n",
    "    # data source: if set, expect all data files here\n",
    "    wtlike_data:  str = '~/wtlike_data' # wired in for convenience\n",
    "\n",
    "    # cache\n",
    "    cachepath: str = '~/wtlike_cache'\n",
    "\n",
    "    radius: float = 4\n",
    "    cos_theta_max:float=0.4\n",
    "    z_max : float=100\n",
    "\n",
    "    # binning\n",
    "    energy_edges = np.logspace(2,6,17)\n",
    "    etypes = (0,1)\n",
    "\n",
    "    week_range: Tuple=(None,None)\n",
    "\n",
    "    time_bins: Tuple=(0,0,7)\n",
    "\n",
    "    use_uint8: bool=False  # for weights\n",
    "\n",
    "    # healpix data representation used by data\n",
    "    nside : int=1024\n",
    "    nest: bool=True\n",
    "\n",
    "    # exposure calculation\n",
    "    bins_per_decade: int=4\n",
    "    base_spectrum: str='lambda E: (E/1000)**-2.1'\n",
    "    energy_range: Tuple = (100.,1e6)\n",
    "\n",
    "    # analysis\n",
    "    likelihood_rep: str='poisson'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # set up data\n",
    "        self.errors=[]\n",
    "        if self.wtlike_data is None:\n",
    "            self.errors.append('wtlike_data must be set')\n",
    "        if self.cachepath is None:\n",
    "            self.errors.appnd('wtlike_cache must be set')\n",
    "        self.wtlike_data = df = Path(self.wtlike_data).expanduser()\n",
    "        self.cachepath =  Path(self.cachepath).expanduser()\n",
    "        if not self.wtlike_data.is_dir() and not self.wtlike_data.is_symlink():\n",
    "            self.errors.append(f'data_folder {df} not a directory or symlink')\n",
    "        subs = 'aeff_files weight_files data_files'.split()\n",
    "        for sub in subs:\n",
    "            if not (df/sub).is_dir() and (df/sub).is_symlink() :\n",
    "                self.errors.append(f'{df/sub} is not a directory or symlink')\n",
    "        if self.verbose>1:\n",
    "            print(self)\n",
    "\n",
    "    @property\n",
    "    def cache(self):\n",
    "        if not hasattr(self, '_cache'):\n",
    "            self._cache = Cache(self.cachepath, clear=False)\n",
    "        return self._cache\n",
    "\n",
    "    @property\n",
    "    def valid(self):\n",
    "        return len(self.errors)==0\n",
    "\n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files' or name.startswith('_'): continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeff_files  data_files\tweight_files\n"
     ]
    }
   ],
   "source": [
    "!ls ~/wtlike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration parameters \n",
      "  verbose         : 1\n",
      "  wtlike_data     : /home/burnett/wtlike_data\n",
      "  cachepath       : /home/burnett/wtlike_cache\n",
      "  radius          : 4\n",
      "  cos_theta_max   : 0.4\n",
      "  z_max           : 100\n",
      "  week_range      : (None, None)\n",
      "  time_bins       : (0, 0, 7)\n",
      "  use_uint8       : False\n",
      "  nside           : 1024\n",
      "  nest            : True\n",
      "  bins_per_decade : 4\n",
      "  base_spectrum   : lambda E: (E/1000)**-2.1\n",
      "  energy_range    : (100.0, 1000000.0)\n",
      "  likelihood_rep  : poisson\n",
      " Cache contents\n",
      " key                                    size  time                 name, in folder /home/burnett/wtlike_cache\n",
      "  3C 279_data                       84793416  2021-05-08 15:09     cache_file_e80d1c899f32358.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print (config, config.cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "\n",
    "def MJD(met):\n",
    "    \"convert MET to MJD\"\n",
    "    #mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "    # From a FT2 file header\n",
    "    # MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "    # MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "    mission_start = 51910.00074287037\n",
    "    return (mission_start + met/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bin_size_name(bins):\n",
    "    \"\"\"Provide a nice name, e.g., 'day' for a time interval\n",
    "    \"\"\"\n",
    "    if np.isscalar(bins) :\n",
    "        binsize = bins\n",
    "    else:\n",
    "        binsize = np.mean(bins)\n",
    "\n",
    "    def check_unit(x):\n",
    "        unit_table = dict(week=1/7, day=1, hour=24, min=24*60, s=24*3600)\n",
    "        for name, unit in unit_table.items():\n",
    "            t = x*unit\n",
    "            r = np.mod(t+1e-9,1)\n",
    "            if r<1e-6 or t>1:\n",
    "                return t, name\n",
    "        return x, 'day'\n",
    "    n, unit =  check_unit(binsize)\n",
    "    nt = f'{n:.0f}' if np.mod(n,1)<1e-2 else f'{n:.0f}'\n",
    "    return f'{nt}-{unit}'# if n>1 else f'{unit}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6-hour', '1-day', '2-day', '1-hour', '2-hour', '2-min', '2-week']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5-day'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print([bin_size_name(x) for x in [0.25, 1, 2, 1/24, 2/24, 2.1/24/60, 14]])\n",
    "# bin_size_name(np.linspace(0,10,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "class PointSource():\n",
    "    \"\"\"Manage the position and name of a point source\n",
    "    \"\"\"\n",
    "    def __init__(self, name, position=None):\n",
    "        \"\"\"position: (l,b) tuple or None. if None, expect to be found by lookup\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        if position is None:\n",
    "            try:\n",
    "                skycoord = SkyCoord.from_name(name)\n",
    "            except Exception as e:\n",
    "                print(f'PointSource: a source \"{name}\" was not recognized by SkyCoord: {e}', file=sys.stderr)\n",
    "                raise\n",
    "            gal = skycoord.galactic\n",
    "            self.l,self.b = (gal.l.value, gal.b.value)\n",
    "        else:\n",
    "            self.l,self.b = position\n",
    "            skycoord = SkyCoord(self.l,self.b, unit='deg', frame='galactic')\n",
    "        self.skycoord = skycoord\n",
    "    def __str__(self):\n",
    "        return f'Source \"{self.name}\" at: (l,b)=({self.l:.3f},{self.b:.3f})'\n",
    "    def __repr__(self): return str(self)\n",
    "\n",
    "    @property\n",
    "    def ra(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.ra.value\n",
    "    @property\n",
    "    def dec(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.dec.value\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        \"\"\"Modified name for file system\"\"\"\n",
    "        return self.name.replace(' ', '_').replace('+','p')\n",
    "\n",
    "    @classmethod\n",
    "    def fk5(cls, name, position):\n",
    "        \"\"\"position: (ra,dec) tuple \"\"\"\n",
    "        ra,dec = position\n",
    "        sk = SkyCoord(ra, dec, unit='deg',  frame='fk5').transform_to('galactic')\n",
    "        return cls(name, (sk.l.value, sk.b.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"PointSource.fk5\" class=\"doc_header\"><code>PointSource.fk5</code><a href=\"__main__.py#L39\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PointSource.fk5</code>(**`name`**, **`position`**)\n",
       "\n",
       "position: (ra,dec) tuple "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PointSource.fk5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, expect in [( PointSource('Geminga'),             'Source \"Geminga\" at: (l,b)=(195.134,4.266)'),\n",
    "                  ( PointSource('gal_source', (0,0)),   'Source \"gal_source\" at: (l,b)=(0.000,0.000)', ),\n",
    "                  ( PointSource.fk5('fk5_source',(0,0)),'Source \"fk5_source\" at: (l,b)=(96.337,-60.189)',)\n",
    "                   ]:    \n",
    "    assert str(s)==expect, f'expected {expect}, got {str(s)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_weights.ipynb.\n",
      "Converted 04_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 99-main.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sat May  8 17:28:34 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
