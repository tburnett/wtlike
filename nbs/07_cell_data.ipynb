{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-going",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to wtlike.cell_data,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export cell_data\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-process",
   "metadata": {},
   "source": [
    "# Manage cell data\n",
    "> Create cells from source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wtlike.config import *\n",
    "from wtlike.source_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class CellData(SourceData):\n",
    "    \"\"\"Manage a set of cells generated from a data set\n",
    "    \n",
    "        Invoke superclass to load photon data and exposure for the source.\n",
    "        Manage a list of cells\n",
    "        \n",
    "        * config Config instance, with file paths appropriate fo SourceData\n",
    "        * source PointSource instance\n",
    "        * exp_min minimum relative exposure -- applied to dataframe output\n",
    "        * bins time bins: use default otherwise\n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self, config, source, exp_min=0.3, bins=None, clear=False):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(config, source, clear )\n",
    "\n",
    "        self.source_name =source.name\n",
    "        self.verbose = config.verbose\n",
    "        self.use_uint8  = config.use_uint8\n",
    "        self.exp_min = exp_min\n",
    "        photon_data = self.p_df\n",
    "        \n",
    "        # exposure binned as well\n",
    "        self.fexposure, bins = self.binned_exposure( time_bins=bins, ) #bins, exposure)\n",
    "\n",
    "        # manage bins \n",
    "        self.N = len(bins)-1 # number of bins\n",
    "        self.bins = bins\n",
    "        self.bin_centers = 0.5*(bins[1:]+bins[:-1])\n",
    "        \n",
    "        # restrict photons to range of bin times\n",
    "        photons = photon_data.query(f'{bins[0]}<time<{bins[-1]}')\n",
    "\n",
    "        # get the photon data with good weights, not NaN\n",
    "        w = photons.weight\n",
    "        good = np.logical_not(np.isnan(w))\n",
    "        self.photons = photons.loc[good]\n",
    "        self.weights = w = self.photons.weight.values\n",
    "        \n",
    "        # estimates for averate signal and background per cell\n",
    "        self.S = np.sum(w)/self.N\n",
    "        self.B = np.sum(1-w)/self.N\n",
    "\n",
    "        # use photon times to get indices of bin edges\n",
    "        self._edges = np.searchsorted(self.photons.time, bins)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'''{self.__class__}:\n",
    "        {len(self.fexposure)} intervals from {self.bins[0]:.1f} to {self.bins[-1]:.1f} for source {self.source_name}\n",
    "        S {self.S:.2f}  B {self.B:.2f} '''\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\" get info for ith time bin and return dict with\n",
    "            t : MJD\n",
    "            tw: bin width,\n",
    "            e: exposure as fraction of total,\n",
    "            n : number of photons in bin\n",
    "            w : list of weights as uint8 integers<=255\n",
    "            S,B:  value\n",
    "        \"\"\"\n",
    "        k   = self._edges\n",
    "        w = self.weights[k[i]:k[i+1]]\n",
    "        wts = np.array(w*256, np.uint8) if self.use_uint8 else w\n",
    "        n = len(wts)\n",
    "        e = self.fexposure[i]\n",
    "        tw  = self.bins[i+1]-self.bins[i]\n",
    "\n",
    "        return dict(\n",
    "                t=self.bin_centers[i], # time\n",
    "                tw = tw,  # bin width\n",
    "                e=e, # moving to this name\n",
    "                n=n, # number of photons in bin\n",
    "                w=wts,\n",
    "                S= e *self.S,\n",
    "                B= e *self.B,\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    @property\n",
    "    def dataframe(self):\n",
    "        \"\"\" combine all cells into a dataframe, applying exposure cut\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'df'): return self.df\n",
    "        emin = self.exp_min\n",
    "        if emin is None: emin=0\n",
    "        self.df = pd.DataFrame([cell for cell in self if cell['e']>emin ])\n",
    "        return self.df\n",
    "    \n",
    "    def concatenate( self ):\n",
    "        \"\"\"\n",
    "        Combine this set of cells to one\n",
    "        Return a dict with summed n, S, B, and concatenated w\n",
    "        \"\"\"\n",
    "        newcell = dict()\n",
    "        cells = self.dataframe\n",
    "        if 't' in cells:\n",
    "            ca, cb =cells.iloc[0], cells.iloc[-1]\n",
    "            newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))\n",
    "\n",
    "        for col in ' n S B'.split():\n",
    "            newcell[col] = cells[col].sum()\n",
    "        newcell['w'] = np.concatenate(list(cells.w.values))\n",
    "        return newcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-specification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CellData\" class=\"doc_header\"><code>class</code> <code>CellData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CellData</code>(**`config`**, **`source`**, **`exp_min`**=*`0.3`*, **`bins`**=*`None`*, **`clear`**=*`False`*) :: [`SourceData`](wtlike/source_data#SourceData)\n",
       "\n",
       "Manage a set of cells generated from a data set\n",
       "\n",
       "Invoke superclass to load photon data and exposure for the source.\n",
       "Manage a list of cells\n",
       "\n",
       "* config Config instance, with file paths appropriate fo SourceData\n",
       "* source PointSource instance\n",
       "* exp_min minimum relative exposure -- applied to dataframe output\n",
       "* bins time bins: use default otherwise"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "show_doc(CellData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photons and exposure for Geminga: Restoring from cache with key \"Geminga_monthly_data\"\n",
      "Time bins: 4624 intervals of 1 days, from MJD 54683.0(2008-08-05) to 59307.0(2021-04-03))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class '__main__.CellData'>:\n",
       "        4624 intervals from 54683.0 to 59307.0 for source Geminga\n",
       "        S 193.50  B 133.74 "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "config = Config(data_folder='/home/burnett/monthly')\n",
    "source = PointSource('Geminga')\n",
    "cd = CellData(config, source)\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def concatenate_cells( cells):\n",
    "    \"\"\"\n",
    "    Combine a group of cells to one\n",
    "    - cells: dataframe with cells containing  n, w, S, B<br>\n",
    "            Optionally, if $t$ is present, generate t and tw\n",
    "    Return a dict with summed n, S, B, and concatenated w\n",
    "    \"\"\"\n",
    "    newcell = dict()\n",
    "    if 't' in cells:\n",
    "        ca, cb =cells.iloc[0], cells.iloc[-1]\n",
    "        newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))\n",
    "\n",
    "    for col in ' n S B'.split():\n",
    "        newcell[col] = cells[col].sum()\n",
    "    newcell['w'] = np.concatenate(list(cells.w.values))\n",
    "    return newcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def partition_cells(config, cells, edges):\n",
    "    \"\"\" Partition a set of cells\n",
    "     - cells -- A DataFrame of cells\n",
    "     - edges  -- a list of edges delimiting boundaries between cells\n",
    "    \"\"\"\n",
    "    # should check limitsk\n",
    "    ii = np.searchsorted(cells.t, edges)\n",
    "    \n",
    "    newcells = []\n",
    "    for k in range(len(ii)-1):\n",
    "        a,b = ii[k:k+2]\n",
    "        subset = cells.iloc[a:b]; \n",
    "\n",
    "        ca, cb = subset.iloc[0], subset.iloc[-1]\n",
    "        newcell = dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2)  )\n",
    "\n",
    "        for col in 'tw e n S B'.split():\n",
    "            newcell[col] = subset[col].sum()\n",
    "        newcell['e'] /= len(subset)\n",
    "        newcell['w'] = np.concatenate(list(subset.w.values)) #np.array(w, np.uint8)\n",
    "        newcells.append(newcell)\n",
    "    return pd.DataFrame(newcells)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"partition_cells\" class=\"doc_header\"><code>partition_cells</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>partition_cells</code>(**`config`**, **`cells`**, **`edges`**)\n",
       "\n",
       "Partition a set of cells\n",
       "- cells -- A DataFrame of cells\n",
       "- edges  -- a list of edges delimiting boundaries between cells"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(partition_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_gti.ipynb.\n",
      "Converted 02_source_data.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_cell_data.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_loglike.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Tue Apr 20 06:03:12 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-nursery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
