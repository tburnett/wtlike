{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to wtlike.bayesian,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n",
      "Sun Apr 25 06:21:48 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export bayesian\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utilities.ipynb_docgen import *\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Blocks\n",
    "\n",
    "> Partition a light curve with the Bayesian Block algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions implemented here are:\n",
    "\n",
    "- `get_bb_partition` to perform a BB partition. It requires a \"fitness\" function to perform an evaluation of the \n",
    "likelihoods for a set of sequential cells. There are two such, using the number of counts, and the Kerr likelihood. See the [Bayesian Block reference](https://arxiv.org/pdf/1207.5578.pdf).\n",
    "\n",
    " - `CountFitness`\n",
    " - `LikelihoodFitness`, the default\n",
    " \n",
    "\n",
    "- `bb_overplot` which overplots fits to the partitioned blocks on the original light curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.stats.bayesian_blocks import FitnessFunc\n",
    "\n",
    "from wtlike.config import *\n",
    "from wtlike.lightcurve import * #get_lightcurve, fit_cells, flux_plot\n",
    "from wtlike.cell_data import * #get_cells, partition_cells\n",
    "from wtlike.loglike import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CountFitness(FitnessFunc):\n",
    "    \"\"\"\n",
    "    Adapted version of a astropy.stats.bayesian_blocks.FitnessFunc\n",
    "    Considerably modified to give the `fitness function` access to the cell data.\n",
    "    \n",
    "    Implements the Event model using exposure instead of time.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lc, p0=0.05,):\n",
    "        \"\"\"\n",
    "        - lc  -- a LightCurve data table, with  exposure (e) and counts (n),\n",
    "            as well as a representation of the likelihood for each cell\n",
    "        - p0 --\n",
    "        \"\"\"\n",
    "        self.p0=p0\n",
    "        self.df= df= lc\n",
    "        N = self.N = len(df)\n",
    "        # Invoke empirical function from Scargle 2012\n",
    "        self.ncp_prior = self.p0_prior(N)\n",
    "\n",
    "        #actual times for bin edges\n",
    "        t = df.t.values\n",
    "        dt = df.tw.values/2\n",
    "        self.mjd = np.concatenate([t-dt, [t[-1]+dt[-1]] ] ) # put one at the end\n",
    "        self.name = self.__class__.__name__\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "\n",
    "        # counts per cell\n",
    "        self.nn = df.n.values\n",
    "        assert min(self.nn)>0, 'Attempt to Include a cell with no contents'\n",
    "\n",
    "        # edges and block_length use exposure as \"time\"\n",
    "        e = df.e.values\n",
    "        self.edges = np.concatenate([[0], np.cumsum(e)])\n",
    "        self.block_length = self.edges[-1] - self.edges\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return f'{self.name}: {self.N} cells, spanning {self.block_length[0]:.1f} days, prior={self.ncp_prior:.1f}'\n",
    "        \n",
    "    def __call__(self, R):\n",
    "        \"\"\" The fitness function needed for BB algorithm\n",
    "        For cells 0..R return array of length R+1 of the maximum log likelihoods for combined cells\n",
    "        0..R, 1..R, ... R\n",
    "        \"\"\"\n",
    "        # exposures and corresponding counts\n",
    "        w_k = self.block_length[:R + 1] - self.block_length[R + 1]\n",
    "        N_k = np.cumsum(self.nn[:R + 1][::-1])[::-1]\n",
    "\n",
    "        # Solving eq. 26 from Scargle 2012 for maximum $\\lambda$ gives\n",
    "        return N_k * (np.log(N_k) - np.log(w_k))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the Bayesian Blocks model given the specified fitness function.\n",
    "        Refactored version using code from bayesian_blocks.FitnesFunc.fit\n",
    "        Returns\n",
    "        -------\n",
    "        edges : ndarray\n",
    "            array containing the (M+1) edges, in MJD units, defining the M optimal bins\n",
    "        \"\"\"\n",
    "        # This is the basic Scargle algoritm, copied almost verbatum\n",
    "        # ---------------------------------------------------------------\n",
    "\n",
    "        # arrays to store the best configuration\n",
    "        N = self.N\n",
    "        best = np.zeros(N, dtype=float)\n",
    "        last = np.zeros(N, dtype=int)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Start with first data cell; add one cell at each iteration\n",
    "        # ----------------------------------------------------------------\n",
    "        for R in range(N):\n",
    "\n",
    "            # evaluate fitness function\n",
    "            fit_vec = self(R)\n",
    "\n",
    "            A_R = fit_vec - self.ncp_prior\n",
    "            A_R[1:] += best[:R]\n",
    "\n",
    "            i_max = np.argmax(A_R)\n",
    "            last[R] = i_max\n",
    "            best[R] = A_R[i_max]\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Now find changepoints by iteratively peeling off the last block\n",
    "        # ----------------------------------------------------------------\n",
    "        change_points = np.zeros(N, dtype=int)\n",
    "        i_cp = N\n",
    "        ind = N\n",
    "        while True:\n",
    "            i_cp -= 1\n",
    "            change_points[i_cp] = ind\n",
    "            if ind == 0:\n",
    "                break\n",
    "            ind = last[ind - 1]\n",
    "        change_points = change_points[i_cp:]\n",
    "\n",
    "        return self.mjd[change_points]\n",
    "\n",
    "#export\n",
    "class LikelihoodFitness(CountFitness):\n",
    "    \"\"\" Fitness function that uses the full likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lc,  p0=0.05, npt=50):\n",
    "        self.npt = npt\n",
    "        super().__init__(lc, p0)\n",
    "        \n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "        N = self.N\n",
    "        \n",
    "        def liketable(prep):\n",
    "            return prep.create_table(self.npt)\n",
    "        \n",
    "        self.tables = df.fit.apply(liketable).values\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}: {self.N} cells,  prior={self.ncp_prior:.1f}'\n",
    "\n",
    "    def __call__(self, R):\n",
    "        \n",
    "        a, y  = self.tables[R]\n",
    "        x = np.linspace(*a)\n",
    "        y = np.zeros(self.npt)\n",
    "        rv = np.empty(R+1)\n",
    "        for i in range(R, -1, -1): \n",
    "            a, yi = self.tables[i]\n",
    "            xi = np.linspace(*a)\n",
    "            y += np.interp(x, xi, yi, left=-np.inf, right=-np.inf)\n",
    "            amax = np.argmax(y)\n",
    "            rv[i] =y[amax]\n",
    "        return rv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Generate data sets for an AGN and a pulsar\n",
       "<details  class=\"nbdoc-description\" >  <summary> printout </summary>  <div style=\"margin-left: 5%\"><pre>photons and exposure for Geminga: Restoring from cache with key \"Geminga_monthly_data\"<br>Time bins: 4624 intervals of 1 days, from MJD 54683.0(2008-08-05) to 59307.0(2021-04-03))<br>Loaded 4424 / 4424 cells with exposure &gt; 0.3 for light curve analysis<br>photons and exposure for 3C 279: Restoring from cache with key \"3C 279_monthly_data\"<br>Time bins: 4624 intervals of 1 days, from MJD 54683.0(2008-08-05) to 59307.0(2021-04-03))<br>Loaded 4422 / 4422 cells with exposure &gt; 0.3 for light curve analysis<br></pre></div> </details>\n",
       "\n",
       "Choose the time interval, 54750&lt;t&lt;54855 (105 days) to bracket a modest flare of the AGN.\n",
       " \n",
       "<table>\n",
       "<tr> <td>Pulsar</td><td>AGN</td></tr>\n",
       "<tr>\n",
       "<td><div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 2\">  <a href=\"images/data_setup_fig_02.png\" title=\"images/data_setup_fig_02.png\">    <img src=\"images/data_setup_fig_02.png\" alt=\"Figure 2 at images/data_setup_fig_02.png\" width=300>   </a> </figure>\n",
       "</div>\n",
       "</td> <td><div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 3\">  <a href=\"images/data_setup_fig_03.png\" title=\"images/data_setup_fig_03.png\">    <img src=\"images/data_setup_fig_03.png\" alt=\"Figure 3 at images/data_setup_fig_03.png\" width=300>   </a> </figure>\n",
       "</div>\n",
       "</td>\n",
       "</tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7faceeb0e7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%nbdev_collapse_input\n",
    "lcs ={} # make small light curves available locally\n",
    "\n",
    "def data_setup(config, lcs=lcs, mjd_query='54750<t<54855', names=['Geminga','3C 279']):\n",
    "    \"\"\"\n",
    "    ### Generate data sets for an AGN and a pulsar\n",
    "    {printout}\n",
    "    \n",
    "    Choose the time interval, {mjd_query} ({days} days) to bracket a modest flare of the AGN.\n",
    "     \n",
    "    <table>\n",
    "    <tr> <td>Pulsar</td><td>AGN</td></tr>\n",
    "    <tr>\n",
    "    <td>{fig1}</td> <td>{fig2}</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    \n",
    "    from wtlike.config import Config,  PointSource\n",
    "    from wtlike.lightcurve import  getLightCurve, flux_plot\n",
    "    figs=[]\n",
    "    plt.rc('font', size=20)\n",
    "    with capture_print('printout') as printout:\n",
    "        for i,name in enumerate(names):\n",
    "            lcfull = getLightCurve(config,  PointSource(name), key=None)\n",
    "            lc = lcs[name] = lcfull.query(mjd_query) if mjd_query else lcfull\n",
    "            fig= flux_plot(config,lc, fignum=i, title=name)\n",
    "            figs.append(figure(fig, width=300))\n",
    "    fig1, fig2 = figs\n",
    "    mjd_query = mjd_query.replace('<', '&lt;')\n",
    "    days = len(lc)\n",
    "    return locals()\n",
    "\n",
    "config = Config(data_folder='/home/burnett/monthly')\n",
    "if config.valid:\n",
    "    nbdoc(data_setup, config, lcs, mjd_query='54750<t<54855', )\n",
    "else:\n",
    "    print('No analysis: config not valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def doc_countfitness( fitness, light_curve_dict, source_name):\n",
    "    \"\"\"\n",
    "    #### {class_name} test with source {source_name}\n",
    "         \n",
    "    Create object: `bbfitter = {class_name}(lc)`\n",
    "    \n",
    "    Object description:   {bbfitter}\n",
    "    \n",
    "    Then `bbfitter({n})` returns the values\n",
    "        {values}\n",
    "   \n",
    "    Finally, the partition algorithm, 'bbfitter.fit()' returns {cffit}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lc = light_curve_dict[source_name]\n",
    "    bbfitter = fitness(lc)\n",
    "    class_name = bbfitter.name\n",
    "    n = 10\n",
    "    values  = np.array(bbfitter(n)).round(1)    \n",
    "    cffit = bbfitter.fit()\n",
    "    \n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### CountFitness test with source Geminga\n",
       "     \n",
       "Create object: `bbfitter = CountFitness(lc)`\n",
       "\n",
       "Object description:   CountFitness: 105 cells, spanning 133.4 days, prior=4.9\n",
       "\n",
       "Then `bbfitter(10)` returns the values\n",
       "    [19135.3 17237.9 15427.8 13421.1 12009.5 10042.1  8595.7  6817.3  5235.3\n",
       "  3546.6  1889.7]\n",
       "\n",
       "Finally, the partition algorithm, 'bbfitter.fit()' returns [54750. 54792. 54855.]\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7facee847350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### CountFitness test with source 3C 279\n",
       "     \n",
       "Create object: `bbfitter = CountFitness(lc)`\n",
       "\n",
       "Object description:   CountFitness: 105 cells, spanning 139.0 days, prior=4.9\n",
       "\n",
       "Then `bbfitter(10)` returns the values\n",
       "    [2572.9 2266.5 2004.3 1767.5 1452.8 1265.2 1018.7  846.1  667.2  466.1\n",
       "  250.3]\n",
       "\n",
       "Finally, the partition algorithm, 'bbfitter.fit()' returns [54750. 54754. 54782. 54790. 54807. 54827. 54855.]\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7facf2a9d310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%nbdev_collapse_input\n",
    "if config.valid:\n",
    "    nbdoc(doc_countfitness, CountFitness, light_curve_dict = lcs, source_name='Geminga')\n",
    "    nbdoc(doc_countfitness, CountFitness, light_curve_dict = lcs, source_name='3C 279')\n",
    "else:\n",
    "     print('No analysis: config not valid')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def get_bb_partition(config, lc, fitness_class=LikelihoodFitness, p0=0.05, key=None, clear=False):    \n",
    "\n",
    "    \"\"\"Perform Bayesian Block partition of the cells found in a light curve\n",
    "    \n",
    "    - lc : input LightCurve object or DataFrame with fit cells\n",
    "    - fitness_class \n",
    "    \n",
    "    return edges for partition\n",
    "    \"\"\"\n",
    "    assert issubclass(fitness_class,CountFitness), 'fitness_class wrong'\n",
    "    if isinstance(lc, LightCurve):\n",
    "        lc = lc.dataframe\n",
    "    assert 'fit' in lc.columns, 'Expect the dataframe ho have the Poisson representation'\n",
    "\n",
    "\n",
    "    def doit():\n",
    "        fitness = fitness_class(lc, p0=p0)\n",
    "        # Now run the astropy Bayesian Blocks code using my version of the 'event' model\n",
    "        return fitness.fit() \n",
    "        \n",
    "    key = f'BB_edges_' if key is '' else key\n",
    "    \n",
    "    edges = config.cache(key, doit,  description=key if config.verbose>0 else '', overwrite=clear)\n",
    "    \n",
    "    if config.verbose>0:\n",
    "        print(f'Partitioned {len(lc)} cells into {len(edges)-1} blocks, using {fitness_class.__name__} ' )\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"get_bb_partition\" class=\"doc_header\"><code>get_bb_partition</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>get_bb_partition</code>(**`config`**, **`lc`**, **`fitness_class`**=*`'LikelihoodFitness'`*, **`p0`**=*`0.05`*, **`key`**=*`None`*, **`clear`**=*`False`*)\n",
       "\n",
       "Perform Bayesian Block partition of the cells found in a light curve\n",
       "\n",
       "- lc : input LightCurve object or DataFrame with fit cells\n",
       "- fitness_class \n",
       "\n",
       "return edges for partition"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_bb_partition, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned 105 cells into 6 blocks, using CountFitness \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### BB partition for 3C 279 using CountFitness\n",
       "\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 1\">  <a href=\"images/count_fig_01.png\" title=\"images/count_fig_01.png\">    <img src=\"images/count_fig_01.png\" alt=\"Figure 1 at images/count_fig_01.png\" width=400>   </a> </figure>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7facf153f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned 105 cells into 6 blocks, using LikelihoodFitness \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### BB partition for 3C 279 using LikelihoodFitness\n",
       "\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 1\">  <a href=\"images/like_fig_01.png\" title=\"images/like_fig_01.png\">    <img src=\"images/like_fig_01.png\" alt=\"Figure 1 at images/like_fig_01.png\" width=400>   </a> </figure>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7facee9217d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%nbdev_collapse_input\n",
    "\n",
    "def test_bb(lcs, name, fitness):\n",
    "    \"\"\"\n",
    "    ### BB partition for {name} using {fitness.__name__}\n",
    "    \n",
    "    {lc_fig}\n",
    "    \"\"\"\n",
    "    lc = lcs[name]\n",
    "    edges = get_bb_partition(config, lc, fitness, key=None) \n",
    "    lc_fig = flux_plot(config, lc, title=f'{name} partition with {fitness.__name__}')\n",
    "    lc_fig.width=400\n",
    "    ax = lc_fig.axes[0]\n",
    "    edges = np.concatenate([edges, [edges[-1]] ])\n",
    "    for  i,t in enumerate(edges[::2]):\n",
    "        if 2*i+1==len(edges): break\n",
    "        t2 = edges[2*i+1]\n",
    "        ax.axvspan(t, t2, color='lightcyan')\n",
    "    for t in edges:\n",
    "        ax.axvline(t, ls=':', color='cyan')\n",
    "    return locals()\n",
    "\n",
    "if config.valid:\n",
    "    nbdoc(test_bb, lcs, '3C 279', CountFitness, name='count')\n",
    "    nbdoc(test_bb, lcs, '3C 279', LikelihoodFitness, name='like')\n",
    "else:\n",
    "    print('No output, config not valid')\n",
    "#     nbdoc(test_bb, lcs, 'Geminga', CountFitness)\n",
    "#     nbdoc(test_bb, lcs, 'Geminga', LikelihoodFitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def bb_overplot(config, lc, bb_fit, ax=None, **kwargs):\n",
    "    \"\"\"Plot light curve: cell fits with BB overplot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    colors = kwargs.pop('colors', ('lightblue', 'wheat', 'blue'))\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,4)) if not ax else (ax.figure, ax)\n",
    "    flux_plot(config, lc, ax=ax, colors=colors,**kwargs)\n",
    "    flux_plot(config, bb_fit, ax=ax, step=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"bb_overplot\" class=\"doc_header\"><code>bb_overplot</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>bb_overplot</code>(**`config`**, **`lc`**, **`bb_fit`**, **`ax`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Plot light curve: cell fits with BB overplot\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bb_overplot,title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class BayesianBlockAnalysis(CellData):\n",
    "    \"\"\"Full analysis of a source, including Bayesian block analysis\n",
    "    Inherits from `CellData`\n",
    "    \n",
    "    - source\n",
    "    - exp_min\n",
    "    - bins\n",
    "    - clear -- if set, clear the cache entry\n",
    "    \"\"\"\n",
    "    def __init__(self, config, source, exp_min=0.3, bins=None,  clear=False):\n",
    "        super().__init__(config, source, exp_min, bins, clear)\n",
    "        # get the cells from superclass\n",
    "        self.cells = self.dataframe\n",
    "        self.lc = LightCurve(config, self.cells, source)\n",
    "        self.lc_df = self.lc.dataframe\n",
    "        \n",
    "    def partition(self,key=None, clear=False):\n",
    "    \n",
    "        key = self.source.data_key.replace('data', 'bb_edges') if key is None else key\n",
    "        self.source.edges_key = key\n",
    "        bb_edges  = get_bb_partition(self.config, self.lc_df,  key=key, clear=clear) \n",
    "\n",
    "        self.bb_cells = partition_cells(self.config, self.cells, bb_edges);\n",
    "        self.bb_fit = fit_cells(self.config, self.bb_cells, )\n",
    "        \n",
    "    def plot(self, ax=None, **kwargs):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = ig, ax = plt.subplots(figsize=(12,3)) if ax is None else (ax.figure, ax)\n",
    "        bb_overplot(self.config, self.lc_df, self.bb_fit, ax=ax, **kwargs)\n",
    "        return fig\n",
    "    \n",
    "    def all_data_likelihood(self, query='' ):\n",
    "        \"\"\"Concatentate all the cells, return a LogLike object\"\"\"\n",
    "        return LogLike(self.concatenate()) \n",
    "    \n",
    "# alias        \n",
    "BBA = BayesianBlockAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"BayesianBlockAnalysis\" class=\"doc_header\"><code>class</code> <code>BayesianBlockAnalysis</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>BayesianBlockAnalysis</code>(**`config`**, **`source`**, **`exp_min`**=*`0.3`*, **`bins`**=*`None`*, **`clear`**=*`False`*) :: [`CellData`](wtlike/cell_data#CellData)\n",
       "\n",
       "Full analysis of a source, including Bayesian block analysis\n",
       "Inherits from [`CellData`](wtlike/cell_data#CellData)\n",
       "\n",
       "- source\n",
       "- exp_min\n",
       "- bins\n",
       "- clear -- if set, clear the cache entry"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BayesianBlockAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit blocks and overplot\n",
    "\n",
    "The following code shows how to refit, and demonstrates the overplot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>tw</th>\n",
       "      <th>n</th>\n",
       "      <th>e</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>54750.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.526[1+0.318-0.375], &lt; 0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>54751.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.496[1+0.311-0.369], &lt; 0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>54752.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.302[1+0.445-0.556], &lt; 0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>54753.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.712[1+0.259-0.296], &lt; 1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>54754.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.428[1+0.347-0.410], &lt; 0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>54850.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.908[1+0.237-0.260], &lt; 1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>54851.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.940[1+0.253-0.290], &lt; 1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>54852.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.955[1+0.238-0.260], &lt; 1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>54853.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.958[1+0.249-0.286], &lt; 1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>54854.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.688[1+0.164-0.178], &lt; 2.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           t   tw   n     e                             fit\n",
       "67   54750.5  1.0  76  1.29    0.526[1+0.318-0.375], < 0.90\n",
       "68   54751.5  1.0  67  1.32    0.496[1+0.311-0.369], < 0.85\n",
       "69   54752.5  1.0  62  1.35    0.302[1+0.445-0.556], < 0.64\n",
       "70   54753.5  1.0  79  1.40    0.712[1+0.259-0.296], < 1.10\n",
       "71   54754.5  1.0  52  1.41    0.428[1+0.347-0.410], < 0.76\n",
       "..       ...  ...  ..   ...                             ...\n",
       "167  54850.5  1.0  50  1.10    0.908[1+0.237-0.260], < 1.33\n",
       "168  54851.5  1.0  48  1.00    0.940[1+0.253-0.290], < 1.45\n",
       "169  54852.5  1.0  55  1.11    0.955[1+0.238-0.260], < 1.40\n",
       "170  54853.5  1.0  54  1.01    0.958[1+0.249-0.286], < 1.47\n",
       "171  54854.5  1.0  70  1.16    1.688[1+0.164-0.178], < 2.22\n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs['3C 279']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_collapse_input\n",
    "lc = lcs['3C 279']\n",
    "# todo -- test with this\n",
    "# if config.valid:\n",
    "#     name = '3C 279'\n",
    "#     config.verbose=1\n",
    "#     source = PointSource(name)\n",
    "#     bba = BBA(config, source)\n",
    "#     bba.partition()\n",
    "#     fig = bba.plot(yscale='log')\n",
    "#     plt.gca().set_title(f'Bayesian-block analysis of {name}')\n",
    "# else:\n",
    "#     print('Not showing BB plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_gti.ipynb.\n",
      "Converted 02_source_data.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_cell_data.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_loglike.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sun Apr 25 06:23:21 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
