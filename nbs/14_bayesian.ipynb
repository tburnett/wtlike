{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bayesian\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev import showdoc \n",
    "from utilities.ipynb_docgen import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Blocks\n",
    "\n",
    "> Partition a light curve with the Bayesian Block algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm depends on a 'fitness' function of the light curve, an evaluation of the \n",
    "likelihoods for a set of sequential cells. There are two such, using the number of counts, and the Kerr likelihood.\n",
    "\n",
    "- `CountFitness`\n",
    "- `LikelihoodFitness`\n",
    "\n",
    "See the [Bayesian Block reference](https://arxiv.org/pdf/1207.5578.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats.bayesian_blocks import FitnessFunc\n",
    "\n",
    "from wtlike.config import *\n",
    "from wtlike.lightcurve import get_lightcurve, fit_cells, flux_plot\n",
    "from wtlike.cells import get_cells, partition_cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Generate data sets for an AGN and a pulsar\n",
       "<details  class=\"nbdoc-description\" >  <summary> printout </summary>  <div style=\"margin-left: 5%\"><pre>Light curve for Geminga: Saving to cache with key \"lightfcurve_Geminga\"<br>Cell data for Geminga: Saving to cache with key \"cells_Geminga\"<br>Photon data: Saving to cache with key \"photons_Geminga\"<br>Processing 11 FITS files with GTI information ...  11 files, 63635 intervals with 3,322 days live time<br>Loading  132 months from Arrow dataset /home/burnett/data/dataset<br>....................................................................................................................................<br>\tSelected 1,313,726 photons within 5 deg of  (195.13,4.27)<br>\tEnergies: 100.0-1000000 MeV<br>\tDates:    2008-08-04 15:46 - 2019-08-03 01:17<br>\tMJD  :    54682.7          - 58698.1         <br>Load weights from file /mnt/d/OneDrive/fermi/weight_files/Geminga_weights.pkl<br>\tFound: PSR J0633+1746 at (195.14, 4.27)<br>\tApplyng weights: 240 / 1313726 photon pixels are outside weight region<br>\t233109 weights set to NaN<br>binned exposure for source Geminga: Saving to cache with key \"binexp_Geminga\"<br>exposure for Geminga: Saving to cache with key \"exposure_Geminga\"<br>Processing 12 S/C history (FT2) files<br>  applying cuts cos(theta) &lt; 0.4,  z &lt; 100<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2008.fits: 362996 entries, 360944 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2009.fits: 874661 entries, 870446 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2010.fits: 889547 entries, 884697 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2011.fits: 882832 entries, 871672 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2012.fits: 881317 entries, 868109 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2013.fits: 885307 entries, 867342 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2014.fits: 894730 entries, 886570 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2015.fits: 890006 entries, 886086 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2016.fits: 890933 entries, 884823 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2017.fits: 888349 entries, 883761 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2018.fits: 842824 entries, 830723 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2019.fits: 737029 entries, 514657 in GTI<br>\tFound 9,609,830 S/C entries:  2,695,715 remain after zenith and theta cuts<br>Calculate exposure using the energy domain 100.0-1000000.0 4 bins/decade<br>2695715 entries, MJD 54683 - 58698<br>Time bins: 4015 intervals of 1 days, in range (54683.0, 58698.0)<br>Loaded 3873 / 4015 cells with exposure &gt; 0.3 for light curve analysis<br>first cell: t                                                    54683.5<br>tw                                                         1<br>e                                                    1.26456<br>n                                                        330<br>w          [0.95343286, 0.83939403, 0.68349504, 0.0219892...<br>S                                                    225.585<br>B                                                    114.707<br>loglike    wtlike.loglike.LogLike:  time 54683.500, 330 w...<br>Name: 0, dtype: object<br>Fitting likelihoods with poisson representation<br>Light curve for 3C 279: Saving to cache with key \"lightfcurve_3C 279\"<br>Cell data for 3C 279: Saving to cache with key \"cells_3C 279\"<br>Photon data: Saving to cache with key \"photons_3C 279\"<br>Loading  132 months from Arrow dataset /home/burnett/data/dataset<br>....................................................................................................................................<br>\tSelected 215,158 photons within 5 deg of  (305.10,57.06)<br>\tEnergies: 100.0-1000000 MeV<br>\tDates:    2008-08-04 15:52 - 2019-08-03 01:50<br>\tMJD  :    54682.7          - 58698.1         <br>Load weights from file /mnt/d/OneDrive/fermi/weight_files/3C_279_weights.pkl<br>\tFound: P88Y3243 at (305.10, 57.07)<br>\tApplyng weights: 2086 / 215158 photon pixels are outside weight region<br>\t67655 weights set to NaN<br>binned exposure for source 3C 279: Saving to cache with key \"binexp_3C 279\"<br>exposure for 3C 279: Saving to cache with key \"exposure_3C 279\"<br>Processing 12 S/C history (FT2) files<br>  applying cuts cos(theta) &lt; 0.4,  z &lt; 100<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2008.fits: 362996 entries, 360944 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2009.fits: 874661 entries, 870446 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2010.fits: 889547 entries, 884697 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2011.fits: 882832 entries, 871672 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2012.fits: 881317 entries, 868109 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2013.fits: 885307 entries, 867342 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2014.fits: 894730 entries, 886570 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2015.fits: 890006 entries, 886086 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2016.fits: 890933 entries, 884823 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2017.fits: 888349 entries, 883761 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2018.fits: 842824 entries, 830723 in GTI<br>\tfile /home/burnett/work/lat-data/ft2/ft2_2019.fits: 737029 entries, 514657 in GTI<br>\tFound 9,609,830 S/C entries:  2,438,906 remain after zenith and theta cuts<br>\tcut from 2,438,906 to 105 - 2438858, or 2,438,753 entries after MJD range selection<br>Calculate exposure using the energy domain 100.0-1000000.0 4 bins/decade<br>2438753 entries, MJD 54683 - 58697<br>Time bins: 4014 intervals of 1 days, in range (54683.0, 58697.0)<br>Loaded 3845 / 4014 cells with exposure &gt; 0.3 for light curve analysis<br>first cell: t                                                    54683.5<br>tw                                                         1<br>e                                                   0.858171<br>n                                                         19<br>w          [0.064962015, 0.8456794, 0.4740412, 0.5252704,...<br>S                                                    14.8428<br>B                                                      16.69<br>loglike    wtlike.loglike.LogLike:  time 54683.500, 19 we...<br>Name: 0, dtype: object<br>Fitting likelihoods with poisson representation<br></pre></div> </details>\n",
       "\n",
       "Choose the time interval, 54750&lt;t&lt;54855 (105 days) to bracket a modest flare of the AGN.\n",
       " \n",
       "<table>\n",
       "<tr> <td>Pulsar</td><td>AGN</td></tr>\n",
       "<tr>\n",
       "<td><div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 2\">  <a href=\"images/data_setup_fig_02.png\" title=\"images/data_setup_fig_02.png\">    <img src=\"images/data_setup_fig_02.png\" alt=\"Figure 2 at images/data_setup_fig_02.png\" width=300>   </a> </figure>\n",
       "</div>\n",
       "</td> <td><div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 3\">  <a href=\"images/data_setup_fig_03.png\" title=\"images/data_setup_fig_03.png\">    <img src=\"images/data_setup_fig_03.png\" alt=\"Figure 3 at images/data_setup_fig_03.png\" width=300>   </a> </figure>\n",
       "</div>\n",
       "</td>\n",
       "</tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb02c045950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse_hide\n",
    "\n",
    "\n",
    "lcs ={}\n",
    "def data_setup(lcs = lcs, mjd_query='54750<t<54855', names=['Geminga','3C 279']):\n",
    "    \"\"\"\n",
    "    ## Generate data sets for an AGN and a pulsar\n",
    "    {printout}\n",
    "    \n",
    "    Choose the time interval, {mjd_query} ({days} days) to bracket a modest flare of the AGN.\n",
    "     \n",
    "    <table>\n",
    "    <tr> <td>Pulsar</td><td>AGN</td></tr>\n",
    "    <tr>\n",
    "    <td>{fig1}</td> <td>{fig2}</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    \n",
    "    from wtlike.config import Config,  PointSource\n",
    "    from wtlike.lightcurve import get_lightcurve, flux_plot\n",
    "    config = Config()\n",
    "    figs=[]\n",
    "    plt.rc('font', size=20)\n",
    "    with capture_print('printout') as printout:\n",
    "        for i,name in enumerate(names):\n",
    "            lcfull = get_lightcurve(config,  PointSource(name))\n",
    "            lc = lcs[name] = lcfull.query(mjd_query) if mjd_query else lcfull\n",
    "            fig= flux_plot(config,lc, fignum=i, title=name)\n",
    "            figs.append(figure(fig, width=300))\n",
    "    fig1, fig2 = figs\n",
    "    mjd_query = mjd_query.replace('<', '&lt;')\n",
    "    days = len(lc)\n",
    "    return locals()\n",
    "\n",
    "if Config().valid:\n",
    "    nbdoc(data_setup, lcs, mjd_query='54750<t<54855', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CountFitness(FitnessFunc):\n",
    "    \"\"\"\n",
    "    Adapted version of a astropy.stats.bayesian_blocks.FitnessFunc\n",
    "    Considerably modified to give the `fitness function` access to the cell data.\n",
    "    \n",
    "    Implements the Event model using exposure instead of time.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lc, p0=0.05,):\n",
    "        \"\"\"\n",
    "        - lc  -- a LightCurve data table, with  exposure (e) and counts (n),\n",
    "            as well as a representation of the likelihood for each cell\n",
    "        - p0 --\n",
    "        \"\"\"\n",
    "        self.p0=p0\n",
    "        self.df= df= lc\n",
    "        N = self.N = len(df)\n",
    "        # Invoke empirical function from Scargle 2012\n",
    "        self.ncp_prior = self.p0_prior(N)\n",
    "\n",
    "        #actual times for bin edges\n",
    "        t = df.t.values\n",
    "        dt = df.tw.values/2\n",
    "        self.mjd = np.concatenate([t-dt, [t[-1]+dt[-1]] ] ) # put one at the end\n",
    "        self.name = self.__class__.__name__\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "\n",
    "        # counts per cell\n",
    "        self.nn = df.n.values\n",
    "        assert min(self.nn)>0, 'Attempt to Include a cell with no contents'\n",
    "\n",
    "        # edges and block_length use exposure as \"time\"\n",
    "        e = df.e.values\n",
    "        self.edges = np.concatenate([[0], np.cumsum(e)])\n",
    "        self.block_length = self.edges[-1] - self.edges\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return f'{self.name}: {self.N} cells, spanning {self.block_length[0]:.1f} days, prior={self.ncp_prior:.1f}'\n",
    "        \n",
    "    def __call__(self, R):\n",
    "        \"\"\" The fitness function needed for BB algorithm\n",
    "        For cells 0..R return array of length R+1 of the maximum log likelihoods for combined cells\n",
    "        0..R, 1..R, ... R\n",
    "        \"\"\"\n",
    "        # exposures and corresponding counts\n",
    "        w_k = self.block_length[:R + 1] - self.block_length[R + 1]\n",
    "        N_k = np.cumsum(self.nn[:R + 1][::-1])[::-1]\n",
    "\n",
    "        # Solving eq. 26 from Scargle 2012 for maximum $\\lambda$ gives\n",
    "        return N_k * (np.log(N_k) - np.log(w_k))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the Bayesian Blocks model given the specified fitness function.\n",
    "        Refactored version using code from bayesian_blocks.FitnesFunc.fit\n",
    "        Returns\n",
    "        -------\n",
    "        edges : ndarray\n",
    "            array containing the (M+1) edges, in MJD units, defining the M optimal bins\n",
    "        \"\"\"\n",
    "        # This is the basic Scargle algoritm, copied almost verbatum\n",
    "        # ---------------------------------------------------------------\n",
    "\n",
    "        # arrays to store the best configuration\n",
    "        N = self.N\n",
    "        best = np.zeros(N, dtype=float)\n",
    "        last = np.zeros(N, dtype=int)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Start with first data cell; add one cell at each iteration\n",
    "        # ----------------------------------------------------------------\n",
    "        for R in range(N):\n",
    "\n",
    "            # evaluate fitness function\n",
    "            fit_vec = self(R)\n",
    "\n",
    "            A_R = fit_vec - self.ncp_prior\n",
    "            A_R[1:] += best[:R]\n",
    "\n",
    "            i_max = np.argmax(A_R)\n",
    "            last[R] = i_max\n",
    "            best[R] = A_R[i_max]\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Now find changepoints by iteratively peeling off the last block\n",
    "        # ----------------------------------------------------------------\n",
    "        change_points = np.zeros(N, dtype=int)\n",
    "        i_cp = N\n",
    "        ind = N\n",
    "        while True:\n",
    "            i_cp -= 1\n",
    "            change_points[i_cp] = ind\n",
    "            if ind == 0:\n",
    "                break\n",
    "            ind = last[ind - 1]\n",
    "        change_points = change_points[i_cp:]\n",
    "\n",
    "        return self.mjd[change_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CountFitness\" class=\"doc_header\"><code>class</code> <code>CountFitness</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CountFitness</code>(**`lc`**, **`p0`**=*`0.05`*) :: `FitnessFunc`\n",
       "\n",
       "Adapted version of a astropy.stats.bayesian_blocks.FitnessFunc\n",
       "Considerably modified to give the `fitness function` access to the cell data.\n",
       "\n",
       "Implements the Event model using exposure instead of time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "showdoc.show_doc(CountFitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse_hide\n",
    "def doc_countfitness( fitness, light_curve_dict, source_name):\n",
    "    \"\"\"\n",
    "    ### {class_name} test with source {source_name}\n",
    "         \n",
    "    Create object: `bbfitter = {class_name}(lc)`\n",
    "    \n",
    "    Object description:   {bbfitter}\n",
    "    \n",
    "    Then `bbfitter({n})` returns the values\n",
    "        {values}\n",
    "   \n",
    "    Finally, the partition algorithm, 'bbfitter.fit()' returns {cffit}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lc = light_curve_dict[source_name]\n",
    "    bbfitter = fitness(lc)\n",
    "    class_name = bbfitter.name\n",
    "    n = 10\n",
    "    values  = np.array(bbfitter(n)).round(1)    \n",
    "    cffit = bbfitter.fit()\n",
    "    \n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### CountFitness test with source Geminga\n",
       "     \n",
       "Create object: `bbfitter = CountFitness(lc)`\n",
       "\n",
       "Object description:   CountFitness: 105 cells, spanning 131.0 days, prior=4.9\n",
       "\n",
       "Then `bbfitter(10)` returns the values\n",
       "    [14517.  13066.1 11631.2 10159.8  9106.2  7633.9  6573.   5173.6  3959.6\n",
       "  2746.6  1451.2]\n",
       "\n",
       "Finally, the partition algorithm, 'bbfitter.fit()' returns [54750. 54788. 54855.]\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb0558da850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### CountFitness test with source 3C 279\n",
       "     \n",
       "Create object: `bbfitter = CountFitness(lc)`\n",
       "\n",
       "Object description:   CountFitness: 105 cells, spanning 138.0 days, prior=4.9\n",
       "\n",
       "Then `bbfitter(10)` returns the values\n",
       "    [1657.1 1431.1 1267.9 1145.3  919.4  811.2  648.   510.2  378.7  266.3\n",
       "  148.2]\n",
       "\n",
       "Finally, the partition algorithm, 'bbfitter.fit()' returns [54750. 54754. 54785. 54790. 54807. 54827. 54855.]\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb05539fb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "if Config().valid:\n",
    "    nbdoc(doc_countfitness, CountFitness, light_curve_dict = lcs, source_name='Geminga')\n",
    "    nbdoc(doc_countfitness, CountFitness, light_curve_dict = lcs, source_name='3C 279')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LikelihoodFitness(CountFitness):\n",
    "    \"\"\" Fitness function that uses the full likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lc,  p0=0.05, npt=50):\n",
    "        self.npt = npt\n",
    "        super().__init__(lc, p0)\n",
    "        \n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "        N = self.N\n",
    "        \n",
    "        def liketable(prep):\n",
    "            return prep.create_table(self.npt)\n",
    "        \n",
    "        self.tables = df.fit.apply(liketable).values\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}: {self.N} cells,  prior={self.ncp_prior:.1f}'\n",
    "\n",
    "    def __call__(self, R):\n",
    "        \n",
    "        a, y  = self.tables[R]\n",
    "        x = np.linspace(*a)\n",
    "        y = np.zeros(self.npt)\n",
    "        rv = np.empty(R+1)\n",
    "        for i in range(R, -1, -1): \n",
    "            a, yi = self.tables[i]\n",
    "            xi = np.linspace(*a)\n",
    "            y += np.interp(x, xi, yi, left=-np.inf, right=-np.inf)\n",
    "            amax = np.argmax(y)\n",
    "            rv[i] =y[amax]\n",
    "        return rv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"LikelihoodFitness\" class=\"doc_header\"><code>class</code> <code>LikelihoodFitness</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>LikelihoodFitness</code>(**`lc`**, **`p0`**=*`0.05`*, **`npt`**=*`50`*) :: [`CountFitness`](/ #wtlike/bayesian.html#CountFitness)\n",
       "\n",
       "Fitness function that uses the full likelihood\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "showdoc.show_doc(LikelihoodFitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### LikelihoodFitness test with source Geminga\n",
       "     \n",
       "Create object: `bbfitter = LikelihoodFitness(lc)`\n",
       "\n",
       "Object description:   LikelihoodFitness: 105 cells,  prior=4.9\n",
       "\n",
       "Then `bbfitter(10)` returns the values\n",
       "    [-4.1 -3.8 -1.5 -1.4 -1.3 -1.3 -0.4 -0.4 -0.3 -0.3 -0. ]\n",
       "\n",
       "Finally, the partition algorithm, 'bbfitter.fit()' returns [54750. 54793. 54855.]\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb024e705d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### LikelihoodFitness test with source 3C 279\n",
       "     \n",
       "Create object: `bbfitter = LikelihoodFitness(lc)`\n",
       "\n",
       "Object description:   LikelihoodFitness: 105 cells,  prior=4.9\n",
       "\n",
       "Then `bbfitter(10)` returns the values\n",
       "    [-8.3 -8.2 -8.1 -7.1 -5.7 -5.7 -4.7 -3.6 -2.9 -2.6 -0. ]\n",
       "\n",
       "Finally, the partition algorithm, 'bbfitter.fit()' returns [54750. 54779. 54785. 54790. 54809. 54827. 54843. 54855.]\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb02c0ccc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config().valid:\n",
    "    nbdoc(doc_countfitness, LikelihoodFitness, light_curve_dict = lcs, source_name='Geminga')\n",
    "    nbdoc(doc_countfitness, LikelihoodFitness, light_curve_dict = lcs, source_name='3C 279')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_bb_partition(config, lc, fitness_class=LikelihoodFitness, p0=0.05, key=None):    \n",
    "\n",
    "    \"\"\"Perform Bayesian Block partition of the cells found in a light curve\n",
    "    \n",
    "    - lc : input light curve\n",
    "    - fitness_class \n",
    "    \n",
    "    return edges for partition\n",
    "    \"\"\"\n",
    "    assert issubclass(fitness_class,CountFitness), 'fitness_class wrong'\n",
    "    assert 'fit' in lc.columns, 'Expect the dataframe ho have the Poisson representation'\n",
    "\n",
    "\n",
    "    def doit():\n",
    "        fitness = fitness_class(lc, p0=p0)\n",
    "        # Now run the astropy Bayesian Blocks code using my version of the 'event' model\n",
    "        return fitness.fit() \n",
    "        \n",
    "    key = f'BB_edges_' if key is '' else key\n",
    "    \n",
    "    edges = config.cache(key, doit,  description='BB edges for...')\n",
    "    \n",
    "    if config.verbose>0:\n",
    "        print(f'Partitioned {len(lc)} cells into {len(edges)-1} blocks, using {fitness_class.__name__} ' )\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"get_bb_partition\" class=\"doc_header\"><code>get_bb_partition</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>get_bb_partition</code>(**`config`**, **`lc`**, **`fitness_class`**=*`LikelihoodFitness`*, **`p0`**=*`0.05`*, **`key`**=*`None`*)\n",
       "\n",
       "Perform Bayesian Block partition of the cells found in a light curve\n",
       "\n",
       "- lc : input light curve\n",
       "- fitness_class \n",
       "\n",
       "return edges for partition"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "showdoc.show_doc(get_bb_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned 105 cells into 6 blocks, using CountFitness \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### BB partition for 3C 279 using CountFitness\n",
       "\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 1\">  <a href=\"images/test_bb_fig_01.png\" title=\"images/test_bb_fig_01.png\">    <img src=\"images/test_bb_fig_01.png\" alt=\"Figure 1 at images/test_bb_fig_01.png\" width=400>   </a> </figure>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb016dd9d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned 105 cells into 7 blocks, using LikelihoodFitness \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### BB partition for 3C 279 using LikelihoodFitness\n",
       "\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 1\">  <a href=\"images/test_bb_fig_01.png\" title=\"images/test_bb_fig_01.png\">    <img src=\"images/test_bb_fig_01.png\" alt=\"Figure 1 at images/test_bb_fig_01.png\" width=400>   </a> </figure>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fb024fec950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse_hide\n",
    "\n",
    "def test_bb(lcs, name, fitness):\n",
    "    \"\"\"\n",
    "    #### BB partition for {name} using {fitness.__name__}\n",
    "    \n",
    "    {lc_fig}\n",
    "    \"\"\"\n",
    "\n",
    "    config = Config()\n",
    "     \n",
    "    lc = lcs[name]\n",
    "    edges = get_bb_partition(config, lc, fitness, key=None) \n",
    "    lc_fig = flux_plot(config, lc, title=f'{name} partition with {fitness.__name__}')\n",
    "    lc_fig.width=400\n",
    "    ax = lc_fig.axes[0]\n",
    "    edges = np.concatenate([edges, [edges[-1]] ])\n",
    "    for  i,t in enumerate(edges[::2]):\n",
    "        if 2*i+1==len(edges): break\n",
    "        t2 = edges[2*i+1]\n",
    "        ax.axvspan(t, t2, color='lightcyan')\n",
    "    for t in edges:\n",
    "        ax.axvline(t, ls=':', color='cyan')\n",
    "    return locals()\n",
    "\n",
    "if Config().valid:\n",
    "    nbdoc(test_bb, lcs, '3C 279', CountFitness)\n",
    "    nbdoc(test_bb, lcs, '3C 279', LikelihoodFitness)\n",
    "#     nbdoc(test_bb, lcs, 'Geminga', CountFitness)\n",
    "#     nbdoc(test_bb, lcs, 'Geminga', LikelihoodFitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fitting the new cells from the partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bb_overplot(config, lc, bb_fit, ax=None, **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(10,4)) if ax is None else (ax.figure, ax)\n",
    "    flux_plot(config, lc,   ax=ax, \n",
    "              colors=(('lightblue', 'sandybrown', 'blue')), **kwargs)\n",
    "    flux_plot(config, bb_fit, ax=ax, step=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_manage_dataset.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_loglike.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Tue Dec 29 06:04:58 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
