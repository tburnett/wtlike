{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  6 10:43:18 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "# default_exp bayesian\n",
    "#%nbdev_default_export bayesian\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utilities.ipynb_docgen import *\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Blocks\n",
    "\n",
    "> Partition a light curve with the Bayesian Block algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions implemented here are:\n",
    "\n",
    "- `get_bb_partition` to perform a BB partition. It requires a \"fitness\" function to perform an evaluation of the \n",
    "likelihoods for a set of sequential cells. There are two such, using the number of counts, and the Kerr likelihood. See the [Bayesian Block reference](https://arxiv.org/pdf/1207.5578.pdf).\n",
    "\n",
    " - `CountFitness`\n",
    " - `LikelihoodFitness`, the default\n",
    " \n",
    "\n",
    "- `bb_overplot` which overplots fits to the partitioned blocks on the original light curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "#%nbdev_export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.stats.bayesian_blocks import FitnessFunc\n",
    "\n",
    "from wtlike.config import *\n",
    "from wtlike.lightcurve import * #get_lightcurve, fit_cells, flux_plot\n",
    "from wtlike.cell_data import * #get_cells, partition_cells\n",
    "from wtlike.loglike import *\n",
    "\n",
    "plt.rc('font', size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CountFitness(FitnessFunc):\n",
    "    \"\"\"\n",
    "    Adapted version of a astropy.stats.bayesian_blocks.FitnessFunc\n",
    "    Considerably modified to give the `fitness function` access to the cell data.\n",
    "    \n",
    "    Implements the Event model using exposure instead of time.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lc, p0=0.05,):\n",
    "        \"\"\"\n",
    "        - lc  -- a LightCurve data table, with  exposure (e) and counts (n),\n",
    "            as well as a representation of the likelihood for each cell\n",
    "        - p0 --\n",
    "        \"\"\"\n",
    "        self.p0=p0\n",
    "        self.df= df= lc\n",
    "        N = self.N = len(df)\n",
    "        # Invoke empirical function from Scargle 2012\n",
    "        self.ncp_prior = self.p0_prior(N)\n",
    "\n",
    "        #actual times for bin edges\n",
    "        t = df.t.values\n",
    "        dt = df.tw.values/2\n",
    "        self.mjd = np.concatenate([t-dt, [t[-1]+dt[-1]] ] ) # put one at the end\n",
    "        self.name = self.__class__.__name__\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "\n",
    "        # counts per cell\n",
    "        self.nn = df.n.values\n",
    "        assert min(self.nn)>0, 'Attempt to Include a cell with no contents'\n",
    "\n",
    "        # edges and block_length use exposure as \"time\"\n",
    "        e = df.e.values\n",
    "        self.edges = np.concatenate([[0], np.cumsum(e)])\n",
    "        self.block_length = self.edges[-1] - self.edges\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return f'{self.name}: {self.N} cells, spanning {self.block_length[0]:.1f} days, prior={self.ncp_prior:.1f}'\n",
    "        \n",
    "    def __call__(self, R):\n",
    "        \"\"\" The fitness function needed for BB algorithm\n",
    "        For cells 0..R return array of length R+1 of the maximum log likelihoods for combined cells\n",
    "        0..R, 1..R, ... R\n",
    "        \"\"\"\n",
    "        # exposures and corresponding counts\n",
    "        w_k = self.block_length[:R + 1] - self.block_length[R + 1]\n",
    "        N_k = np.cumsum(self.nn[:R + 1][::-1])[::-1]\n",
    "\n",
    "        # Solving eq. 26 from Scargle 2012 for maximum $\\lambda$ gives\n",
    "        return N_k * (np.log(N_k) - np.log(w_k))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the Bayesian Blocks model given the specified fitness function.\n",
    "        Refactored version using code from bayesian_blocks.FitnesFunc.fit\n",
    "        Returns\n",
    "        -------\n",
    "        edges : ndarray\n",
    "            array containing the (M+1) edges, in MJD units, defining the M optimal bins\n",
    "        \"\"\"\n",
    "        # This is the basic Scargle algoritm, copied almost verbatum\n",
    "        # ---------------------------------------------------------------\n",
    "\n",
    "        # arrays to store the best configuration\n",
    "        N = self.N\n",
    "        best = np.zeros(N, dtype=float)\n",
    "        last = np.zeros(N, dtype=int)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Start with first data cell; add one cell at each iteration\n",
    "        # ----------------------------------------------------------------\n",
    "        for R in range(N):\n",
    "\n",
    "            # evaluate fitness function\n",
    "            fit_vec = self(R)\n",
    "\n",
    "            A_R = fit_vec - self.ncp_prior\n",
    "            A_R[1:] += best[:R]\n",
    "\n",
    "            i_max = np.argmax(A_R)\n",
    "            last[R] = i_max\n",
    "            best[R] = A_R[i_max]\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Now find changepoints by iteratively peeling off the last block\n",
    "        # ----------------------------------------------------------------\n",
    "        change_points = np.zeros(N, dtype=int)\n",
    "        i_cp = N\n",
    "        ind = N\n",
    "        while True:\n",
    "            i_cp -= 1\n",
    "            change_points[i_cp] = ind\n",
    "            if ind == 0:\n",
    "                break\n",
    "            ind = last[ind - 1]\n",
    "        change_points = change_points[i_cp:]\n",
    "\n",
    "        return self.mjd[change_points]\n",
    "\n",
    "class LikelihoodFitness(CountFitness):\n",
    "    \"\"\" Fitness function that uses the full likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lc,  p0=0.05, npt=50):\n",
    "        self.npt = npt\n",
    "        super().__init__(lc, p0)\n",
    "        \n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "        N = self.N\n",
    "        \n",
    "        def liketable(prep):\n",
    "            return prep.create_table(self.npt)\n",
    "        \n",
    "        self.tables = df.fit.apply(liketable).values\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}: {self.N} cells,  prior={self.ncp_prior:.1f}'\n",
    "\n",
    "    def __call__(self, R):\n",
    "        \n",
    "        a, y  = self.tables[R]\n",
    "        x = np.linspace(*a)\n",
    "        y = np.zeros(self.npt)\n",
    "        rv = np.empty(R+1)\n",
    "        for i in range(R, -1, -1): \n",
    "            a, yi = self.tables[i]\n",
    "            xi = np.linspace(*a)\n",
    "            y += np.interp(x, xi, yi, left=-np.inf, right=-np.inf)\n",
    "            amax = np.argmax(y)\n",
    "            rv[i] =y[amax]\n",
    "        return rv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def doc_countfitness( fitness, light_curve_dict, source_name):\n",
    "    \"\"\"\n",
    "    #### {class_name} test with source {source_name}\n",
    "         \n",
    "    Create object: `bbfitter = {class_name}(lc)`\n",
    "    \n",
    "    Object description:   {bbfitter}\n",
    "    \n",
    "    Then `bbfitter({n})` returns the values\n",
    "        {values}\n",
    "   \n",
    "    Finally, the partition algorithm, 'bbfitter.fit()' returns {cffit}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lc = light_curve_dict[source_name]\n",
    "    bbfitter = fitness(lc)\n",
    "    class_name = bbfitter.name\n",
    "    n = 10\n",
    "    values  = np.array(bbfitter(n)).round(1)    \n",
    "    cffit = bbfitter.fit()\n",
    "    \n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_bb_partition(config, lc, fitness_class=LikelihoodFitness, p0=0.05, key=None, clear=False):    \n",
    "\n",
    "    \"\"\"Perform Bayesian Block partition of the cells found in a light curve\n",
    "    \n",
    "    - lc : input LightCurve object or DataFrame with fit cells\n",
    "    - fitness_class \n",
    "    \n",
    "    return edges for partition\n",
    "    \"\"\"\n",
    "    assert issubclass(fitness_class,CountFitness), 'fitness_class wrong'\n",
    "    if not isinstance(lc, pd.DataFrame):\n",
    "        lc = lc.dataframe\n",
    "    assert 'fit' in lc.columns, 'Expect the dataframe to have the Poisson fit object'\n",
    "\n",
    "\n",
    "    def doit():\n",
    "        fitness = fitness_class(lc, p0=p0)\n",
    "        # Now run the astropy Bayesian Blocks code using my version of the 'event' model\n",
    "        return fitness.fit() \n",
    "        \n",
    "    key = f'BB_edges_' if key is '' else key\n",
    "    \n",
    "    edges = config.cache(key, doit,  description=key if config.verbose>0 else '', overwrite=clear)\n",
    "    \n",
    "    if config.verbose>0:\n",
    "        print(f'Partitioned {len(lc)} cells into {len(edges)-1} blocks, using {fitness_class.__name__} ' )\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"get_bb_partition\" class=\"doc_header\"><code>get_bb_partition</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>get_bb_partition</code>(**`config`**, **`lc`**, **`fitness_class`**=*`LikelihoodFitness`*, **`p0`**=*`0.05`*, **`key`**=*`None`*, **`clear`**=*`False`*)\n",
       "\n",
       "Perform Bayesian Block partition of the cells found in a light curve\n",
       "\n",
       "- lc : input LightCurve object or DataFrame with fit cells\n",
       "- fitness_class \n",
       "\n",
       "return edges for partition"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_bb_partition, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def bb_overplot(config, lc, bb_fit, ax=None, source_name=None, step_name=None, **kwargs):\n",
    "    \"\"\"Plot light curve: cell fits with BB overplot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    colors = kwargs.pop('colors', ('lightblue', 'wheat', 'blue'))\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,4)) if not ax else (ax.figure, ax)\n",
    "    flux_plot(config, lc, ax=ax, colors=colors, source_name=source_name, \n",
    "              label=step_name+' bins', **kwargs)\n",
    "    flux_plot(config, bb_fit, ax=ax, step=True, \n",
    "              label='BB overlay', zorder=10,**kwargs)\n",
    "    fig.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"bb_overplot\" class=\"doc_header\"><code>bb_overplot</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>bb_overplot</code>(**`config`**, **`lc`**, **`bb_fit`**, **`ax`**=*`None`*, **`source_name`**=*`None`*, **`step_name`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Plot light curve: cell fits with BB overplot\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bb_overplot,title_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit blocks and overplot\n",
    "\n",
    "The following code shows how to refit, and demonstrates the overplot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BBanalysis(LightCurve):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def applyBB(self, key=None, clear=False):\n",
    "        \"\"\" Apply the Bayesian Blocks algorithm to partition the current set of cells into blocks,\n",
    "        then create a new set of cells and fit them\n",
    "        \n",
    "        - key : cache key. None, defaul to not use the cache\n",
    "        - clear : if True, clear the cache for this key\n",
    "        \"\"\"\n",
    "\n",
    "        self.bb_edges  = get_bb_partition(self.config, self.lc_df,  key=key, clear=clear) \n",
    "        \n",
    "        self.bb_cells = partition_cells(self.config, self.cells, self.bb_edges)\n",
    "        self.bb_fit = fit_cells(self.config, self.bb_cells, )\n",
    "        \n",
    "    def plot_BB(self, ax=None, **kwargs):\n",
    "        \"\"\"Plot the light curve with BB overplot\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        if not hasattr(self, 'bb_cells'):\n",
    "            self.applyBB()\n",
    "        figsize = kwargs.pop('figsize', (12,4))\n",
    "        fignum = kwargs.pop('fignum', 1)\n",
    "        ts_min = kwargs.pop('ts_min',-1)\n",
    "        source_name =kwargs.pop('source_name', self.source_name)\n",
    "        fig, ax = ig, ax = plt.subplots(figsize=figsize, num=fignum) if ax is None else (ax.figure, ax)\n",
    "        \n",
    "#         bb_overplot(self.config, self.lc_df, self.bb_fit, ax=ax, ts_min=ts_min,\n",
    "#                     source_name=source_name, step_name=self.step_name, **kwargs)\n",
    "        colors = kwargs.pop('colors', ('lightblue', 'wheat', 'blue') )\n",
    "        #fig, ax = plt.subplots(1,1, figsize=(12,4)) if not ax else (ax.figure, ax)\n",
    "        flux_plot(self.config, self.lc_df, ax=ax, colors=colors, source_name=source_name, \n",
    "                  label=self.step_name+' bins', **kwargs)\n",
    "        flux_plot(self.config, self.bb_fit, ax=ax, step=True, \n",
    "                  label='BB overlay', zorder=10,**kwargs)\n",
    "        \n",
    "        fig.set_facecolor('white')\n",
    "        return fig\n",
    "    \n",
    "    def bb_table(self, **kwargs):\n",
    "        \"\"\" Return a table of fluxes for the BB analysis\"\"\"\n",
    "        return self.flux_table(self.bb_fit, **kwargs)\n",
    "        \n",
    "BBA = BBanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"BBanalysis\" class=\"doc_header\"><code>class</code> <code>BBanalysis</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>BBanalysis</code>(**\\*`pars`**, **\\*\\*`kwargs`**) :: [`LightCurve`](/wtlikelightcurve.html#LightCurve)\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(BBanalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Demonstration with 3C 279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function demo failed: data_folder /home/burnett/wtlike_data not a directory\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "data_folder /home/burnett/wtlike_data not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-efb02766f1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mnbdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/wtlike/utilities/ipynb_docgen.py\u001b[0m in \u001b[0;36mnbdoc\u001b[0;34m(fun, name, *pars, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;31m# run it and collect its local symbol table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0muser_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Function {fun.__name__} failed: {e}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-efb02766f1d3>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcapture_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Create full weekly light curve'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBBA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3C 279'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     fig1 = figure(\n",
      "\u001b[0;32m~/work/wtlike/wtlike/lightcurve.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *pars, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \"\"\"\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/wtlike/wtlike/cell_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *pars, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bins'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_bins'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#  load phots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/wtlike/wtlike/config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, verbose, files, wtlike_data, cachepath, radius, cos_theta_max, z_max, week_range, time_bins, use_uint8, nside, nest, bins_per_decade, base_spectrum, energy_range, likelihood_rep)\u001b[0m\n",
      "\u001b[0;32m~/work/wtlike/wtlike/config.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwtlike_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwtlike_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwtlike_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data_folder {df} not a directory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0msubs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'aeff_files weight_files data_files'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: data_folder /home/burnett/wtlike_data not a directory"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "#%nbdev_collapse_input\n",
    "full=None\n",
    "\n",
    "def demo():\n",
    "    \"\"\"\n",
    "    ### 3C 279 Demonstration\n",
    "    {out1}    {fig1}\n",
    "    \n",
    "    Expand to see position of a flare:\n",
    "    {fig2}\n",
    "    {out3}    {fig3}\n",
    "    {out4}    {fig4}\n",
    "    \n",
    "    The bb fits\n",
    "    {bb_table}\n",
    "    \n",
    "    Figure 4 From [Kerr paper](https://arxiv.org/pdf/1910.00140.pdf)\n",
    "    {kerr_fig4}\n",
    "    \"\"\"\n",
    "    global full\n",
    "    \n",
    "    with capture_print('Create full weekly light curve') as out1:\n",
    "        full = BBA('3C 279')\n",
    "    \n",
    "    fig1 = figure(\n",
    "        full.plot(yscale='log', ylim=(0.2,20), ts_min=4, figsize=(15,5), xlabel='MJD', fignum=1),\n",
    "        width=600)  \n",
    "    \n",
    "    fig2 = figure(\n",
    "        full.plot(  figsize=(15,5), xlabel='MJD', fmt='o', fignum=2,  xlim=(57100, 57300),),\n",
    "        width=600)  \n",
    "    \n",
    "    with capture_print('Define orbit-based subset around large flare at MJD 57189') as out3:\n",
    "        orbit = full.view((57186, 57191, 0))\n",
    "    fig3 = figure(\n",
    "        orbit.plot(fmt='o', tzero=57186,  ts_min=4,   fignum=3 ),\n",
    "            width=600)\n",
    "    \n",
    "    with capture_print('Apply BB to subset and replot') as out4:\n",
    "        orbit.applyBB()\n",
    "    fig4 = figure(\n",
    "        orbit.plot_BB(fmt='o', tzero=57186,  ts_min=4,   fignum=4),\n",
    "                width=600)\n",
    "    \n",
    "    bb_table = orbit.bb_table()\n",
    "    \n",
    "    kerr_fig4 = image('kerr_fig4.png', width=200, caption=None)\n",
    "    return locals()\n",
    "\n",
    "nbdoc(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(BBanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
