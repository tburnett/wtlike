{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to wtlike.data_man,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export data_man\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data management\n",
    "> Create, from FT1 and FT2, a compact data set with photon and livetime info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Fermi-LAT data files are extracted from the FTP server \n",
    "`https://heasarc.gsfc.nasa.gov/FTP/fermi/data/lat/weekly`, with subfolders for the photon data, `photon` and spacecraft data, `spacecraft`.\n",
    "\n",
    "The class `WeeklyData` downloads these to temporary files and constructs a dict for each week with\n",
    "contents\n",
    "\n",
    "* tstart: reference time\n",
    "* photons: a table, entry per selected photon with columns \n",
    "  * time since tstart\n",
    "  * energy and event type\n",
    "  * position as HEALPix index\n",
    "* sc_data: a table, an entry per 30-s interval, with columns\n",
    "  * start/stop time\n",
    "  * S/C direction\n",
    "* gti_times: an array of interleaved start/stop intervals\n",
    "\n",
    "These dict objects, one per week, are saved in a folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "from astropy.io import fits\n",
    "import wget\n",
    "import healpy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision', 2)\n",
    "import pickle\n",
    "from wtlike.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def get_ft1_data( config, ft1_file):\n",
    "\n",
    "        \"\"\"\n",
    "        Read in a photon data (FT1) file, bin in energy and position to convert to a compact DataFrame\n",
    "        \n",
    "        - `ft1_file` -- A monthly file generated by J. Ballet, or a weekly file from GSFC\n",
    "        \n",
    "        Depends on config items\n",
    "        - `theta_cut, z_cut` -- selection criteria\n",
    "        - `ebins, etypes` -- define band index\n",
    "        - `nside, nest` -- define HEALPix binning\n",
    "         \n",
    "        Returns a tuple with \n",
    "\n",
    "        - `tstart`, the start MET time\n",
    "\n",
    "        - DataFrame  with columns\n",
    "           - `band` (uint8):    energy band index*2 + 0,1 for Front/Back \n",
    "           - `nest_index`  if nest else `ring_index` (uint32): HEALPIx index for the nside \n",
    "           - `time` (float32):    the elapsed time in s from header value TSTART in the FT1 file\n",
    "           \n",
    "        - gti times as an interleaved start, stop array.  \n",
    "        \n",
    "        For the selected events above 100 MeV, this represents 9 bytes per photon, vs. 27.\n",
    "        \"\"\"\n",
    "      \n",
    "        ebins = config.energy_edges\n",
    "        etypes = config.etypes\n",
    "        nside = config.nside\n",
    "        nest = config.nest\n",
    "        z_cut =config.z_max\n",
    "        theta_cut = np.degrees(np.arccos(config.cos_theta_max))\n",
    "        verbose = config.verbose\n",
    "        \n",
    "        with  fits.open(ft1_file) as ft1:\n",
    "            tstart = ft1[1].header['TSTART'] \n",
    "\n",
    "            ## GTI - setup raveled array function to make cut\n",
    "            gti_data= ft1['GTI'].data\n",
    "            # extract arrays for values of interest\n",
    "            data =ft1['EVENTS'].data\n",
    "\n",
    "        a,b = sorted(gti_data.START), sorted(gti_data.STOP)\n",
    "        \n",
    "        gti_times = np.ravel(np.column_stack((a,b)))\n",
    "        if np.any(np.diff(gti_times)<0):\n",
    "            raise Exception(f'Non-monatonic GTI found')\n",
    "            \n",
    "        def apply_gti(time):\n",
    "            x = np.digitize(time, gti_times)\n",
    "            return np.bitwise_and(x,1).astype(bool)\n",
    "        if verbose>1:\n",
    "            total = sum(b)-sum(a)\n",
    "            fraction = total/(b[-1]-a[0])\n",
    "            print(f'GTI times: {a[0]:.0f} - {b[-1]:.0f}'\\\n",
    "                  f' Total: {total:.0f}s, fraction {100*fraction:.1f}%'\n",
    "                 )\n",
    "\n",
    "        glon, glat, energy, et, z, theta, time, ec =\\\n",
    "             [data[x] for x in 'L B ENERGY EVENT_TYPE ZENITH_ANGLE THETA TIME EVENT_CLASS'.split()]\n",
    "        \n",
    "        # generate event_type masks\n",
    "        et_mask={}\n",
    "        for ie in etypes:\n",
    "            et_mask[ie]= et[:,-1-ie]\n",
    "            \n",
    "\n",
    "            \n",
    "        data_cut = np.logical_and(theta<theta_cut, z<z_cut)\n",
    "        e_cut = energy>ebins[0]\n",
    "        gti_cut = apply_gti(time)\n",
    "        \n",
    "        if verbose>1:\n",
    "            print(  f'Photon (FT1) file {ft1_file}: {len(data):,} photons, {sum(e_cut):,} with E>{ebins[0]:.0f} MeV.'\\\n",
    "                    f'\\n\\ttheta<{theta_cut:.1f} and z<{z_cut} selections remove:'\\\n",
    "                    f' {100.- 100*sum(data_cut)/float(len(data)):.2f} %'\\\n",
    "                    f'\\n\\tGTI cut removes {sum(~gti_cut)}'\n",
    "                 )\n",
    "        # apply selection\n",
    "        sel = e_cut & data_cut & gti_cut\n",
    "        glon_sel = glon[sel]\n",
    "        glat_sel = glat[sel]\n",
    "        \n",
    "        # event class -- temporary\n",
    "        def to_hex(x):\n",
    "            from functools import reduce\n",
    "            r= reduce(lambda byte, bit: byte*2 + bit, x, 0)\n",
    "            return f'{r:08x}'\n",
    "        echex = [to_hex(row) for row in ec[sel]]\n",
    "        \n",
    "        # pixelate direction\n",
    "        hpindex = healpy.ang2pix(nside, glon_sel, glat_sel, nest=nest, lonlat=True).astype(np.int32)\n",
    "        hpname = 'nest_index' if nest else 'ring_index'\n",
    "        \n",
    "        # digitize energy and create band index incluing (front/back)\n",
    "        ee = energy[sel]\n",
    "        band_index = (2*(np.digitize(ee, ebins, )-1) + et_mask[1][sel]).astype(np.uint8)\n",
    "\n",
    "        # combine into a recarray to feed to pandas\n",
    "        recarray = np.rec.fromarrays(\n",
    "                    [ band_index,  \n",
    "                     hpindex,  \n",
    "                     (time-tstart)[sel].astype(np.float32),\n",
    "                    echex, ### temp\n",
    "                    ], \n",
    "                    names=['band', hpname, 'time',\n",
    "                           'ec', #### temp\n",
    "                          ])\n",
    "        if verbose>1:\n",
    "            print(f'\\tReturning tstart={tstart:.0f}, {len(recarray):,} photons.')\n",
    "            \n",
    "        return  tstart, pd.DataFrame.from_records(recarray), gti_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"get_ft1_data\" class=\"doc_header\"><code>get_ft1_data</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>get_ft1_data</code>(**`config`**, **`ft1_file`**)\n",
       "\n",
       "Read in a photon data (FT1) file, bin in energy and position to convert to a compact DataFrame\n",
       "\n",
       "- `ft1_file` -- A monthly file generated by J. Ballet, or a weekly file from GSFC\n",
       "\n",
       "Depends on config items\n",
       "- `theta_cut, z_cut` -- selection criteria\n",
       "- `ebins, etypes` -- define band index\n",
       "- `nside, nest` -- define HEALPix binning\n",
       " \n",
       "Returns a tuple with \n",
       "\n",
       "- `tstart`, the start MET time,  and\n",
       "\n",
       "- DataFrame  with columns\n",
       "   - `band` (uint8):    energy band index*2 + 0,1 for Front/Back \n",
       "   - `nest_index`  if nest else `ring_index` (uint32): HEALPIx index for the nside \n",
       "   - `time` (float32):    the elapsed time in s from header value TSTART in the FT1 file\n",
       "   \n",
       "- gti times as an interleaved start, stop array.  \n",
       "\n",
       "For the selected events above 100 MeV, this represents 9 bytes per photon, vs. 27."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_ft1_data, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def get_ft2_info(config, filename, gti=None):\n",
    "    \"\"\"Process a FT2 file, with S/C history data, and return a summary DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        - config -- verbose, cos_theta_max, z_max        \n",
    "        - filename -- spacecraft (FT2) files       \n",
    "        - gti -- GTI object with allowed intervals or None\n",
    "\n",
    "     Returns:\n",
    "        A DataFrame with fields \n",
    "            - start, stop -- interval in MJD units\n",
    "            - livetime -- sec\n",
    "            - ra_scz, dec_scz --spaceraft direction\n",
    "            - ra_zenith, dec_zenith -- local zenith\n",
    "     \"\"\"\n",
    "    # combine the files into a DataFrame with following fields besides START and STOP (lower case for column)\n",
    "    fields    = ['LIVETIME','RA_SCZ','DEC_SCZ', 'RA_ZENITH','DEC_ZENITH']\n",
    "    if config.verbose>1:\n",
    "        print(f'S/C history (FT2) file {filename}', end='')# {\"not\" if gti is None else \"\"} applying GTI')\n",
    "\n",
    "    with fits.open(filename) as hdu:\n",
    "        scdata = hdu['SC_DATA'].data\n",
    "        \n",
    "    # get times to check against MJD limits and GTI\n",
    "    start, stop = [MJD(np.array(scdata.START, float)),\n",
    "                   MJD(np.array(scdata.STOP, float))]\n",
    "    \n",
    "    # apply GTI to bin center (avoid edge effects?)\n",
    "    in_gti = gti(0.5*(start+stop)) if gti else np.ones(len(start), bool)\n",
    "    if config.verbose>1:\n",
    "        gti_check = f', {sum(in_gti)} in GTI' if gti  else ''\n",
    "        print(f' {len(start)} entries {gti_check}')\n",
    "    \n",
    "    t = [('start', start[in_gti]), ('stop',stop[in_gti])]+\\\n",
    "        [(field.lower(), np.array(scdata[field][in_gti],np.float32)) for field in fields ]\n",
    "\n",
    "    sc_data = pd.DataFrame(dict(t) ) \n",
    "            \n",
    "    return sc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"get_ft2_info\" class=\"doc_header\"><code>get_ft2_info</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>get_ft2_info</code>(**`config`**, **`filename`**, **`gti`**=*`None`*)\n",
       "\n",
       "Process a FT2 file, with S/C history data, and return a summary DataFrame\n",
       "\n",
       "Parameters:\n",
       "\n",
       "    - config -- verbose, cos_theta_max, z_max        \n",
       "    - filename -- spacecraft (FT2) files       \n",
       "    - gti -- GTI object with allowed intervals or None\n",
       "\n",
       " Returns:\n",
       "    A DataFrame with fields \n",
       "        - start, stop -- interval in MJD units\n",
       "        - livetime -- sec\n",
       "        - ra_scz, dec_scz --spaceraft direction\n",
       "        - ra_zenith, dec_zenith -- local zenith\n",
       " "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_ft2_info, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S/C history (FT2) file /tmp/from_gsfc/week668_ft2.fits 17021 entries \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>livetime</th>\n",
       "      <th>ra_scz</th>\n",
       "      <th>dec_scz</th>\n",
       "      <th>ra_zenith</th>\n",
       "      <th>dec_zenith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59291.04</td>\n",
       "      <td>59291.04</td>\n",
       "      <td>27.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>51.60</td>\n",
       "      <td>37.46</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59291.04</td>\n",
       "      <td>59291.04</td>\n",
       "      <td>27.64</td>\n",
       "      <td>1.67</td>\n",
       "      <td>52.26</td>\n",
       "      <td>39.16</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59291.04</td>\n",
       "      <td>59291.04</td>\n",
       "      <td>27.66</td>\n",
       "      <td>2.76</td>\n",
       "      <td>52.93</td>\n",
       "      <td>40.87</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59291.04</td>\n",
       "      <td>59291.04</td>\n",
       "      <td>27.69</td>\n",
       "      <td>3.86</td>\n",
       "      <td>53.61</td>\n",
       "      <td>42.58</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59291.04</td>\n",
       "      <td>59291.05</td>\n",
       "      <td>27.65</td>\n",
       "      <td>4.96</td>\n",
       "      <td>54.30</td>\n",
       "      <td>44.29</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start      stop  livetime  ra_scz  dec_scz  ra_zenith  dec_zenith\n",
       "0  59291.04  59291.04     27.59    0.58    51.60      37.46        0.22\n",
       "1  59291.04  59291.04     27.64    1.67    52.26      39.16        1.04\n",
       "2  59291.04  59291.04     27.66    2.76    52.93      40.87        1.86\n",
       "3  59291.04  59291.04     27.69    3.86    53.61      42.58        2.68\n",
       "4  59291.04  59291.05     27.65    4.96    54.30      44.29        3.49"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "filename = '/tmp/from_gsfc/week668_ft2.fits'\n",
    "config = Config()\n",
    "config.verbose=3\n",
    "t = get_ft2_info(config, filename); t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class WeeklyData(object):\n",
    "    \"\"\"Download and process weekly Fermi-LAT files from GSFC \n",
    "    \"\"\"\n",
    "    \n",
    "    ftp = 'https://heasarc.gsfc.nasa.gov/FTP/fermi/data/lat/weekly'\n",
    "    tmp = Path('/tmp/from_gsfc')\n",
    "    \n",
    "    def __init__(self, config, week, saveto):\n",
    "        \"\"\"\n",
    "        * week: a mission week number\n",
    "        * saveto: path to save the fiels\n",
    "        \n",
    "        \"\"\"\n",
    "        self.config= config\n",
    "        self.saveto=Path(saveto)\n",
    "        os.makedirs(self.saveto, exist_ok=True)\n",
    "        assert week>8\n",
    "        self.wk = week\n",
    "  \n",
    "        self.fits_files = [self.tmp/f'week{week:03d}_{x}.fits' for x in 'ft1 ft2'.split()]\n",
    "        os.makedirs(self.tmp, exist_ok=True)\n",
    "        \n",
    "        urls = []\n",
    "        for ftype in  ['photon', 'spacecraft']:\n",
    "             urls.append(f'{self.ftp}/{ftype}/lat_{ftype}_weekly_w{week:03d}_p{\"305\" if ftype==\"photon\" else \"202\" }_v001.fits')\n",
    "        \n",
    "        for url, fname in zip(urls, self.fits_files):\n",
    "            if not fname.exists():\n",
    "                if config.verbose>1:\n",
    "                    print(f'{url.split(\"/\")[-1]} -> {fname}')\n",
    "                wget.download(str(url), str(fname))\n",
    "            else: \n",
    "                if config.verbose>1: print(f'{fname} exists')\n",
    "\n",
    "    def process_ft1(self):\n",
    "        self.tstart, self.photon_data, self.gti_times = get_ft1_data(self.config, self.fits_files[0])\n",
    "    \n",
    "    def process_ft2(self):\n",
    "        \n",
    "        def apply_gti(time): # note MJD\n",
    "            x = np.digitize(time, MJD(self.gti_times))\n",
    "            return np.bitwise_and(x,1).astype(bool)\n",
    "        \n",
    "        self.sc_data = get_ft2_info(self.config, str(self.fits_files[1]), apply_gti)\n",
    "        \n",
    "    def save(self):\n",
    "        \"\"\"process, then save aa dict\"\"\"\n",
    "        \n",
    "        self.process_ft1()\n",
    "        self.process_ft2()\n",
    "        \n",
    "        d = dict(tstart = self.tstart,\n",
    "                photons = self.photon_data,\n",
    "                sc_data = self.sc_data,\n",
    "                gti_times = self.gti_times)\n",
    "        filename = self.saveto/f'week_{self.wk:03d}.pkl'\n",
    "        pickle.dump(d, open(filename, 'wb'))\n",
    "        if self.config.verbose>0:\n",
    "            print(f'Saved to {filename}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "config = Config(verbose=2)\n",
    "wkfolder = '/home/burnett/weekly'\n",
    "\n",
    "for wk in []: #range(532, 668): #59,100):\n",
    "    wd = WeeklyData(config, wk, wkfolder)\n",
    "    wd.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the weekly files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly folder \"/home/burnett/weekly\" contains 659 weeks, from 9 to 668\n",
      "Most recent data to UTC 2021-03-25 01:02\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "weekly_folder = Path(wkfolder)\n",
    "ff = sorted(list(weekly_folder.glob('*.pkl')))\n",
    "wk = list(map(lambda f: int(os.path.splitext(f)[0][-3:]), ff))\n",
    "lastweek = pickle.load(open(ff[-1],'rb'))\n",
    "\n",
    "print(f'Weekly folder \"{weekly_folder}\" contains {len(wk)} weeks, from {wk[0]} to {wk[-1]}')\n",
    "print(f'Most recent data to UTC {UTC(MJD(lastweek[\"tstart\"])+7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02-source_data.ipynb.\n",
      "Converted 02_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_loglike.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Mon Mar 29 16:09:20 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
