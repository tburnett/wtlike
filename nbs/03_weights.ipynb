{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to wtlike.weights,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export weights\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utilities.ipynb_docgen import *\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "> Load weighted data, combine with photon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import os, sys,  pickle, healpy\n",
    "import numpy as np\n",
    "from wtlike.config import *\n",
    "#from wtlike.photon_data import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def check_weights(config, source):\n",
    "    \"\"\"\n",
    "    Check that weights for the source are available: if so, return the weight file name\n",
    "    \n",
    "    - source -- A PointSource object with information on source location\n",
    "    \n",
    "    Returns the filepath to the file if successful, otherwise, print a message abount available files\n",
    "    \"\"\"\n",
    "    weight_files = config.wtlike_data/'weight_files' \n",
    "    assert weight_files.is_dir(), f'Expect {weight_files} to be a directory'\n",
    "    weight_file = weight_files/ (source.filename+'_weights.pkl')\n",
    "    if not weight_file.exists():\n",
    "        available = np.array(list(map(lambda p: p.name[:p.name.find('_weights')], \n",
    "                          weight_files.glob('*_weights.pkl'))))\n",
    "        print(f'{source} not found in list of weight files at\\n\\t {weight_files}.\\n Available:\\n{available}',\n",
    "             file = sys.stderr)\n",
    "        return None\n",
    "    return weight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"check_weights\" class=\"doc_header\"><code>check_weights</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>check_weights</code>(**`config`**, **`source`**)\n",
       "\n",
       "Check that weights for the source are available: if so, return the weight file name\n",
       "\n",
       "- source -- A PointSource object with information on source location\n",
       "\n",
       "Returns the filepath to the file if successful, otherwise, print a message abount available files"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source \"test\" at: (l,b)=(0.000,0.000) not found in list of weight files at\n",
      "\t /home/burnett/wtlike_data/weight_files.\n",
      " Available:\n",
      "['011F-0138' '011F-0217' '011F-0263' '011H-0114' '011H-0116' '011S-0100'\n",
      " '03bN-0330' '03bS-0110' '04aF-0026' '04aS-0035' '204F-0050' '3C454.3'\n",
      " '3C_279' '504F-0472' '504F-0615' '504F-0753' '504F-0933' '504F-0961'\n",
      " '504F-1164' '504F-1322' '504F-1916' '504H-0058' '504H-0261' '504H-0309'\n",
      " '504H-0316' '504H-0369' '504H-0399' '504H-0499' '504N-0010' '504N-0717'\n",
      " '504N-0748' '504N-1076' '504N-1324' '504N-1409' '504N-1637' '504N-1663'\n",
      " '504N-1714' '504P-0428' '504P-0573' '504P-0614' '504P-0675' '504P-0777'\n",
      " '504P-0910' '504P-1095' '504P-1407' '504S-0546' '504S-0683' '504S-1612'\n",
      " '605F-0304' '605F-0537' '605F-0645' '605F-0679' '605F-0762' '605F-1060'\n",
      " '605F-1081' '605H-0133' '605H-0160' '605N-0485' '605N-0940' '605P-0285'\n",
      " '605P-0459' '605S-0359' '605S-0378' '605S-0391' '605S-0513' '998F-0474'\n",
      " '998N-0408' '998N-0517' 'B2_1520p31' 'BL_Lac' 'Geminga' 'P8010-0510'\n",
      " 'P88Y0036' 'P88Y0074' 'P88Y0257' 'P88Y0390' 'P88Y0789' 'P88Y0922'\n",
      " 'P88Y0940' 'P88Y1000' 'P88Y1021' 'P88Y1027' 'P88Y1094' 'P88Y1357'\n",
      " 'P88Y1371' 'P88Y1638' 'P88Y1713' 'P88Y1791' 'P88Y2730' 'P88Y3159'\n",
      " 'P88Y3250' 'P88Y3585' 'P88Y3851' 'P88Y3928' 'P88Y3971' 'P88Y4014'\n",
      " 'P88Y4135' 'P88Y4178' 'P88Y4214' 'P88Y4270' 'P88Y4326' 'P88Y4327'\n",
      " 'P88Y4606' 'P88Y4613' 'P88Y4655' 'P88Y4661' 'P88Y4744' 'P88Y4865'\n",
      " 'P88Y4954' 'P88Y4958' 'P88Y5030' 'P88Y5309' 'P88Y5379' 'P88Y5385'\n",
      " 'P88Y5469' 'P88Y5732' 'P88Y5839' 'P88Y6008' 'P88Y6061' 'P88Y6341'\n",
      " 'P88Y6354' 'PSR_B1259-63' 'PSR_J0633p1746' 'PSR_J0835-4510'\n",
      " 'PSR_J1302-6350' 'PSR_J1836p5925' 'PSR_J1909-3744' 'PSR_J1913p1011'\n",
      " 'PSR_J2022p3842' 'PSR_J2032p4127' 'S8008-1189' 'S8008-1939' 'S8008-2111'\n",
      " 'S8008-2205' 'S8008-2759' 'S8008-2782' 'S8008-2883' 'S8008-3408'\n",
      " 'S8009-1017' 'S8010-0885' 'X_Cyg_x-3']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source \"Geminga\" at: (l,b)=(195.134,4.266) Should be found: file at /home/burnett/wtlike_data/weight_files/Geminga_weights.pkl \n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_doc(check_weights)\n",
    "config = Config(wtlike_data='~/wtlike_data')\n",
    "if config.valid:\n",
    "    print('Check not found')\n",
    "    test_source = PointSource('test', (0,0))\n",
    "    check_weights(config, test_source)\n",
    "    good_source = PointSource('Geminga')\n",
    "    print(f'{good_source} Should be found: file at {check_weights(config, good_source)} ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def _load_weights(config, filename, ):\n",
    "    \"\"\"Load the weight informaton\n",
    "\n",
    "    filename: pickled dict with map info\n",
    "\n",
    "    \"\"\"\n",
    "    # load a pickle containing weights, generated by pointlike\n",
    "    assert os.path.exists(filename),f'File {filename} not found.'\n",
    "    with open(filename, 'rb') as file:\n",
    "        wtd = pickle.load(file, encoding='latin1')\n",
    "    assert type(wtd)==dict, 'Expect a dictionary'\n",
    "    test_elements = 'energy_bins pixels weights nside model_name radius order roi_name'.split()\n",
    "    assert np.all([x in wtd.keys() for x in test_elements]),f'Dict missing one of the keys {test_elements}'\n",
    "    if config.verbose>0:\n",
    "        print(f'Load weights from file {os.path.realpath(filename)}')\n",
    "        pos = wtd['source_lb']\n",
    "        print(f'\\tFound: {wtd[\"source_name\"]} at ({pos[0]:.2f}, {pos[1]:.2f})')\n",
    "    # extract pixel ids and nside used\n",
    "    wt_pix   = wtd['pixels']\n",
    "    nside_wt = wtd['nside']\n",
    "\n",
    "    # merge the weights into a table, with default nans\n",
    "    # indexing is band id rows by weight pixel columns\n",
    "    # append one empty column for photons not in a weight pixel\n",
    "    # calculated weights are in a dict with band id keys\n",
    "    wts = np.full((32, len(wt_pix)+1), np.nan, dtype=np.float32)\n",
    "    weight_dict = wtd['weights']\n",
    "    for k in weight_dict.keys():\n",
    "        t = weight_dict[k]\n",
    "        if len(t.shape)==2:\n",
    "            t = t.T[0] #???\n",
    "        wts[k,:-1] = t\n",
    "    return wts , wt_pix , nside_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def _add_weights(config, wts, wt_pix, nside_wt, photon_data):\n",
    "    # get the photon pixel ids, convert to NEST (if not already) and right shift them\n",
    "\n",
    "    if not config.nest:\n",
    "        # data are RING\n",
    "        photon_pix = healpy.ring2nest(config.nside, photon_data.pixel.values)\n",
    "    else:\n",
    "        photon_pix = photon_data.pixel.values\n",
    "    to_shift = 2*int(np.log2(config.nside/nside_wt));\n",
    "    shifted_pix =   np.right_shift(photon_pix, to_shift)\n",
    "    bad = np.logical_not(np.isin(shifted_pix, wt_pix))\n",
    "    if config.verbose>0:\n",
    "        print(f'\\tApplyng weights: {sum(bad)} / {len(bad)} photon pixels are outside weight region')\n",
    "    if sum(bad)==len(bad):\n",
    "        a = np.array(healpy.pix2ang(nside_wt, wt_pix, nest=True, lonlat=True)).mean(axis=1).round(1)\n",
    "        b = np.array(healpy.pix2ang(nside_wt, shifted_pix, nest=True, lonlat=True)).mean(axis=1).round(1)\n",
    "\n",
    "        raise Exception(f'There was no overlap of the photon data at {b} and the weights at {a}')\n",
    "    shifted_pix[bad] = 12*nside_wt**2 # set index to be beyond pixel indices\n",
    "\n",
    "    # find indices with search and add a \"weights\" column\n",
    "    # (expect that wt_pix are NEST ordering and sorted)\n",
    "    weight_index = np.searchsorted(wt_pix,shifted_pix)\n",
    "    band_index = np.fmin(31, photon_data.band.values) #all above 1 TeV into last bin\n",
    "\n",
    "    # final grand lookup -- isn't numpy wonderful!\n",
    "    photon_data.loc[:,'weight'] = wts[tuple([band_index, weight_index])]\n",
    "    if config.verbose>0:\n",
    "        print(f'\\t{sum(np.isnan(photon_data.weight.values))} weights set to NaN')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def add_weights(config,  photon_data, source, nbins=50):\n",
    "    \"\"\" add weights for the source to the photon data\n",
    "    \n",
    "    - photon_data -- DataFrame with photon data\n",
    "    \n",
    "    - source -- `PointSource` object\n",
    "    \n",
    "    Return the weight value histogram\n",
    "    \"\"\"\n",
    "    files = config.files\n",
    "\n",
    "    weight_file =  check_weights(config,  source)\n",
    "    if weight_file is None:\n",
    "        raise Exception(f'Weight file not found for {source}')\n",
    " \n",
    "    wts, wt_pix, nside_wt = _load_weights(config, weight_file)\n",
    "    _add_weights(config, wts, wt_pix, nside_wt, photon_data)\n",
    "\n",
    "    return np.histogram(photon_data.weight.values, np.linspace(0,1,nbins+1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def get_weight_hist(config,  source, nbins=50, key=''):\n",
    "    \"\"\" return a weight distribution\n",
    "        \n",
    "    - photon_data -- DataFrame with photon data    \n",
    "    - source -- `PointSource` object\n",
    "    \n",
    "    Uses `add_weights`.\n",
    "    \"\"\"\n",
    "    def doit(nbins):\n",
    "        weight_file =  check_weights(config,  source)\n",
    "        if weight_file is None:\n",
    "            raise Exception(f'Weight file not found for {source}')\n",
    "        photon_data = get_photon_data(config,  source )\n",
    "        return add_weights(config, photon_data, source, nbins=nbins)\n",
    "    \n",
    "    key = f'weight_hist_{source.name}' if key=='' else key\n",
    "    description = f'Weight histogram for {source.name}' if config.verbose>1 else ''\n",
    "    return config.cache(key, doit, nbins, description=description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = Config(wtlike_data='~/wtlike_data')\n",
    "# if config.valid:\n",
    "#     source = PointSource('Geminga')\n",
    "#     h = get_weight_hist(config, source, key='')\n",
    "#     print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %nbdev_collapse_input\n",
    "# config = Config() \n",
    "\n",
    "# if config.valid:\n",
    "#     source = PointSource('Geminga')\n",
    "#     print(f'Loading photon data for source {source.name} to test adding weights')\n",
    "#     photon_data = get_photon_data(config,  source )\n",
    "#     h = add_weights(config, photon_data, source)\n",
    "#     print(f'Head of modified photon_data\\n {photon_data.head()}')\n",
    "#     plt.rc('font',size=14)\n",
    "#     fig, ax =plt.subplots(figsize=(4,3))\n",
    "#     n = len(h)\n",
    "#     ax.step( np.linspace(0,1, n+1) , np.concatenate([[h[0]], h])); \n",
    "#     ax.grid();\n",
    "#     ax.set(xlabel='weight', xlim=(0,1), ylim=(0,None))\n",
    "#     #plt.hist(photon_data.weight.values, np.linspace(0,1,51), histtype='stepfilled', lw=2)\n",
    "#     plt.title(f'Weights for source {source.name}')\n",
    "# else:\n",
    "#     print('Not testing since no files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_data_man.ipynb.\n",
      "Converted 03_source_data.ipynb.\n",
      "Converted 03_weights.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_cell_data.ipynb.\n",
      "Converted 08_loglike.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Mon May  3 13:42:40 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
