{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Evaluate the Kerr likelihood, fits using poisson, gaussian\n",
    "output-file: loglike.html\n",
    "title: Log Likelihood tools\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loglike\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Kerr likelihood formula  \n",
    "\n",
    "For each cell with a set of photons with weights $w$, the log likelihood as a function of $\\alpha$  and $\\beta$ is\n",
    "\n",
    "$$ \\displaystyle\\log\\mathcal{L}(\\alpha,\\beta\\ |\\ w)\\ = \\sum_{w}  \\log \\big( 1 + \\alpha\\ w + \\beta\\ (1-w) \\big) - (\\alpha\\ S + \\beta\\ B) $$\n",
    "\n",
    "where  $\\alpha$ and $\\beta$ are the excess signal and background fractions and $S$ and $B$ are\n",
    "the expected numbers of signal and background counts for the cell, determined from the full data set and relative exposure for the cell.\n",
    "\n",
    "Usually, we assume $\\beta=0$, that the background is not varying, and look for signal variation.\n",
    "\n",
    "\n",
    "In the special case where all $w$ values are 1, this reduces to Poisson likelihood, with solution $\\alpha = (1-n/S)$,\n",
    "where $n$ is the number of photons.\n",
    "\n",
    "This module uses this functional evaluation of the likelihood for a cell to define the poisson-like\n",
    "3-parameter function to approximate this likelihood.\n",
    " \n",
    "The case of a known variable background is not equivalent to allowing $\\beta$ to vary, although detecting that would be a reason to be concerned.\n",
    "That is because the rest of the background would not be varying. This case could be dealt with by allowing for two sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special case: expand the log\n",
    "\n",
    "The case where the variation of the signal is small, and background dominated, deserves attention. Suppose $\\max(|\\alpha w|) <<1$ and $\\beta$ is also small.\n",
    "\n",
    "Then we only need the sums $\\sum w$ and $\\sum w^2$. Denoting them as $W$ and $U$, \n",
    "the solution is \n",
    "\n",
    "$$ \\alpha = (W-S)\\ /U\\  \\pm 1/ \\sqrt U $$\n",
    "\n",
    "However, for a source that is mostly quiescent, with brief flares, we have $\\alpha=-1+\\epsilon$, with $0 < \\epsilon$ <<1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import os, sys, pickle\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from scipy import (optimize, linalg)\n",
    "from scipy.linalg import (LinAlgError, LinAlgWarning)\n",
    "from wtlike.poisson import *\n",
    "poisson_tolerance = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class LogLike(object):\n",
    "    \"\"\" implement Kerr Eqn 2 for a single interval, or cell\n",
    "\n",
    "     - cell -- a dict with  w, n, S, B <br>\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if isinstance(cell, pd.Series):\n",
    "            # a row  from the cells dataframe\n",
    "            cell_dict = cell.to_dict()\n",
    "            extract = lambda x: cell_dict[x]\n",
    "            cell = dict(w = extract('w'), S = extract('S'),  B = extract('B'),  n = extract('n'),    )\n",
    "\n",
    "        self.__dict__.update(cell)\n",
    "        self.w = np.atleast_1d(self.w)\n",
    "        self.verbose=0\n",
    "\n",
    "\n",
    "    def fit_info(self, fix_beta=True):\n",
    "        \"\"\"Perform fits, return a dict with cell info\n",
    "        \"\"\"\n",
    "        pars = self.solve(fix_beta)\n",
    "        if pars is None:\n",
    "            if self.verbose>0:\n",
    "                print(f'Fail fit for {self}')\n",
    "            #return None\n",
    "            raise RuntimeError(f'Fit failure: {self}')\n",
    "        hess = self.hessian(pars)\n",
    "        outdict = dict( counts=len(self.w),\n",
    "                       flux=np.float32(round(pars[0],4)) )\n",
    "        if len(pars)==1:\n",
    "            outdict.update( sig_flux=np.float32(round(np.sqrt(1/hess[0]),4)),\n",
    "                      )\n",
    "        else:\n",
    "            beta = pars[1]\n",
    "            try:\n",
    "                var  = np.linalg.inv(hess)\n",
    "                err  = np.sqrt(var.diagonal())\n",
    "                sig_flux=err[0]\n",
    "                sig_beta=err[1]\n",
    "                corr = var[0,1]/(err[0]*err[1])\n",
    "                outdict.update(flux=pars[0], beta=beta,\n",
    "                            sig_flux=sig_flux, sig_beta=sig_beta,corr=corr)\n",
    "            except LinAlgError as e:\n",
    "                # flag as nan\n",
    "                if self.verbose>0:\n",
    "                    print(f'Failed 2-d fit, Hessian= {hess}: {e}')\n",
    "                outdict.update(\n",
    "                    beta=0, sig_beta=np.nan, corr=np.nan)\n",
    "\n",
    "\n",
    "\n",
    "        return outdict\n",
    "\n",
    "    def __call__(self, pars ):\n",
    "        \"\"\" evaluate the log likelihood\n",
    "            pars: array or float\n",
    "                if array with len>1, expect (relative rate, beta)\n",
    "        \"\"\"\n",
    "        pars = np.atleast_1d(pars)\n",
    "        if len(pars)>1:      alpha, beta = pars - np.array([1,0])\n",
    "        else:                alpha, beta = max(-1, pars[0]-1), 0\n",
    "\n",
    "        tmp =  1 + alpha*self.w + beta*(1-self.w)\n",
    "        # limit alpha\n",
    "        tmp[tmp<=1e-6]=1e-6\n",
    "\n",
    "        return np.sum( np.log(tmp)) - alpha*self.S - beta*self.B\n",
    "\n",
    "    def __repr__(self):\n",
    "        time = f' time {self.t:.3f},' if hasattr(self, 't') else ''\n",
    "        return f'{self.__class__.__module__}.{self.__class__.__name__}:'\\\n",
    "        f' {time} {self.n} weights, S {self.S:.1f}, B {self.B:.1f}'\n",
    "\n",
    "    def gradient(self, pars ):\n",
    "        \"\"\"gradient of the log likelihood with respect to alpha=flux-1 and beta, or just alpha\n",
    "        \"\"\"\n",
    "        w,S = self.w, self.S\n",
    "        pars = np.atleast_1d(pars)\n",
    "\n",
    "        alpha =  max(-0.999,pars[0] -1)\n",
    "        if len(pars)==1:\n",
    "            D = 1 + alpha*w\n",
    "            return np.sum(w/D) - S\n",
    "        else:\n",
    "            beta = pars[1]\n",
    "            D =  1 + alpha*w + beta*(1-w)\n",
    "            da = np.sum(w/D) - S\n",
    "            db = np.sum((1-w)/D) - self.B\n",
    "            return [da,db]\n",
    "\n",
    "    def hessian(self, pars):\n",
    "        \"\"\"return Hessian matrix (1 or 2 D according to pars) from explicit second derivatives\n",
    "        Note this is also the Jacobian of the gradient.\n",
    "        \"\"\"\n",
    "        w = self.w\n",
    "        pars = np.atleast_1d(pars)\n",
    "        alpha = max(-0.999, pars[0]-1)\n",
    "        if  len(pars)==1:\n",
    "            D = 1 + alpha*w\n",
    "            return [np.sum((w/D)**2)]\n",
    "        else:\n",
    "            beta= pars[1]\n",
    "            Dsq = (1 + alpha*w + beta*(1-w))**2\n",
    "            a, b, c = np.sum(w**2/Dsq), np.sum(w*(1-w)/Dsq), np.sum((1-w)**2/Dsq)\n",
    "            return np.array([[a,b], [b,c]])\n",
    "\n",
    "    def rate(self, fix_beta=True, debug=False, no_ts=False):\n",
    "        \"\"\"Return signal rate and its error\"\"\"\n",
    "        try:\n",
    "            s = self.solve(fix_beta )\n",
    "            if s is None:\n",
    "                return None\n",
    "            h = self.hessian(s)\n",
    "\n",
    "            v = 1./h[0] if fix_beta else linalg.inv(h)[0,0]\n",
    "            ts = None if no_ts else (0 if s[0]<=-1 else\n",
    "                 2*(self(s)-self( -1 if fix_beta else [-1,s[1]] )))\n",
    "            return (s[0]), np.sqrt(v), ts\n",
    "\n",
    "        except (LinAlgError, LinAlgWarning, RuntimeWarning) as msg:\n",
    "            if debug or self.verbose>2:\n",
    "                print(f'Fit error, cell {self},\\n\\t{msg}')\n",
    "        except Exception as msg:\n",
    "            print(f'exception: s, h: {s},{h}-- {msg}', file=sys.stderr)\n",
    "            raise\n",
    "        print( '***********Failed?', file=sys.stderr)\n",
    "\n",
    "    def minimize(self,   fix_beta=True,estimate=[0.,0], **fmin_kw):\n",
    "        \"\"\"Minimize the -Log likelihood \"\"\"\n",
    "        kw = dict(disp=False)\n",
    "        kw.update(**fmin_kw)\n",
    "        f = lambda pars: -self(pars)\n",
    "        return optimize.fmin_cg(f, estimate[0.:1.] if fix_beta else estimate, **kw)\n",
    "\n",
    "    def solve(self, fix_beta=True, debug=True, estimate=[1.,0],**fit_kw):\n",
    "        \"\"\"Solve non-linear equation(s) from setting gradient to zero\n",
    "        note that the hessian is a jacobian\n",
    "        \"\"\"\n",
    "\n",
    "        if fix_beta:\n",
    "            #\n",
    "            g0= self.gradient([0])\n",
    "            # solution is at zero flux\n",
    "            if g0<=0:\n",
    "                return [0]\n",
    "            # check that solution close to zero, difficult for fsolve.\n",
    "            # if < 0.5 sigma away, just give linear solution\n",
    "            h0=self.hessian(0)[0]\n",
    "            if g0/h0 < 0.5*np.sqrt(1/h0):\n",
    "                return [g0/h0]\n",
    "\n",
    "        kw = dict(factor=2, xtol=1e-3, fprime=self.hessian)\n",
    "        kw.update(**fit_kw)\n",
    "        f = self.gradient\n",
    "        try:\n",
    "            if fix_beta:\n",
    "                # this may fix an issue with known positive root\n",
    "                est = estimate[0]\n",
    "                ret = [1]\n",
    "\n",
    "                while True:\n",
    "                    #print(f'***** est, ret: {est}, {ret}')\n",
    "                    ret = optimize.fsolve(f, est, **kw)\n",
    "                    est /=2\n",
    "                    if ret[0]>0 or est<0.1: break\n",
    "\n",
    "            else:\n",
    "                ret = optimize.fsolve(f, estimate , **kw)\n",
    "\n",
    "            #ret = optimize.fsolve(f, estimate[0] if fix_beta else estimate , **kw)\n",
    "        except RuntimeWarning as msg:\n",
    "            #print(f'RuntimeWarning: {msg}', file=sys.stderr)\n",
    "            # fall back\n",
    "            if fix_beta:\n",
    "                ret = optimize.root_scalar(f, x0=0.5, bracket=[0,2],  method='brentq', xtol=1e-3)\n",
    "#                 print(f'*** fall back {ret}')\n",
    "                if ret.converged:\n",
    "                     return np.array([ret.root])\n",
    "\n",
    "            if debug or self.verbose>2:\n",
    "                print(f'Runtime fsolve warning for cell {self}, \\n\\t {msg}', file=sys.stderr)\n",
    "            raise Exception()\n",
    "        except Exception as msg:\n",
    "            raise Exception(msg)\n",
    "        return np.array(ret)\n",
    "\n",
    "    def plot(self, fix_beta=True, ax=None, **kwargs):\n",
    "        \"\"\" Make a plot of the likelihood, with fit\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(4,2)) if ax is None else (ax.figure, ax)\n",
    "        kw = dict( ylim=(-2,0.2), ylabel='log likelihood', xlabel='relative flux')\n",
    "        kw.update(**kwargs)\n",
    "        ax.set(**kw)\n",
    "\n",
    "        try:\n",
    "            a, s, ts = self.rate(fix_beta=fix_beta, debug=True)\n",
    "            fit = self.fit_info()\n",
    "            ts = PoissonRep(self).ts\n",
    "\n",
    "        except Exception as msg :\n",
    "            print(f'Failed fit: {msg}', file=sys.stderr)\n",
    "            ax.set(title=' **failed fit**')\n",
    "            return\n",
    "\n",
    "        xlim = kw.get('xlim', (a-4*s, a+4*s) )\n",
    "        dom = np.linspace(*xlim)\n",
    "        if fix_beta:\n",
    "            f = lambda x: self([x])-self(a)\n",
    "            beta=0\n",
    "        else:\n",
    "            a, beta = self.solve(fix_beta, debug=True)\n",
    "            f = lambda x: self([x, beta])\n",
    "        ax.plot(dom, list(map(f,dom)) )\n",
    "\n",
    "\n",
    "        ax.plot(a, f(a), 'or')\n",
    "        ax.plot([a-s, a+s], [f(a-s), f(a+s)], '-k',lw=2)\n",
    "        for x in (a-s,a+s):\n",
    "            ax.plot([x,x], [f(x)-0.1, f(x)+0.1], '-k',lw=2)\n",
    "        ax.plot(a, f(a)-0.5, '-ok', ms=10,\n",
    "                label=rf\"{fit['flux']:.3f} $\\pm$ {fit['sig_flux']:.3f}\"\n",
    "                    +f\"\\n TS = {ts:.0f}\")\n",
    "\n",
    "        ax.legend(loc='lower center', fontsize=12)\n",
    "        ax.grid(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"LogLike\" class=\"doc_header\"><code>class</code> <code>LogLike</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>LogLike</code>(**`cell`**)\n",
       "\n",
       "implement Kerr Eqn 2 for a single interval, or cell\n",
       "\n",
       "- cell -- a dict with  w, n, S, B <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "show_doc(LogLike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Create a cell for further tests. Plot the likelihood for a cell with 100 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import optimize\n",
    "\n",
    "# def fitit(loglike, pars):\n",
    "#     pars=np.atleast_1d(pars)\n",
    "#     fun = lambda p:  -loglike(p)\n",
    "#     grad = lambda p: np.atleast_1d(loglike.gradient(p))\n",
    "#     print(f'Estimate: {pars.round(4)},  function: {fun(pars):.3f}, gradient: {(np.array(grad(pars))).round(4)}')\n",
    "#     fi = optimize.fmin_l_bfgs_b(fun, pars, fprime=grad)\n",
    "#     fit_pars = np.array(fi[0])\n",
    "#     print(f'Fit:      {fit_pars.round(4)}, function {fi[1]:.3f}, gradient: {(fi[2][\"grad\"].round(4))}' )\n",
    "#     return fi[2]\n",
    "\n",
    "# loglike = ll\n",
    "# fun = lambda p:  -loglike(p)\n",
    "# grad = lambda p: -np.atleast_1d(loglike.gradient(p))\n",
    "# def check(pars):\n",
    "#     pars = np.atleast_1d(pars)\n",
    "#     print(f'pars: {pars.round(4)},  function: {fun(pars):.3f}, gradient: {(np.array(grad(pars))).round(4)}')\n",
    "    \n",
    "# check([1,0]), check([1.01,0]), check([0.99,0]);\n",
    "\n",
    "# fitit(ll, [1.,0])\n",
    "\n",
    "# fitit(ll, [0.99, 0])\n",
    "\n",
    "# pars=[1,0.1]\n",
    "# ll.gradient(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GaussianRep(object):\n",
    "    \"\"\" Manage fits to the loglike object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loglike, fix_beta=True):\n",
    "        \"\"\"1- or 2-D fits to LogLike\"\"\"\n",
    "        self.fix_beta = fix_beta\n",
    "        self.fit = loglike.fit_info(fix_beta)\n",
    "\n",
    "    def __call__(self, pars):\n",
    "        return None # TODO if needed\n",
    "\n",
    "    def __repr__(self):\n",
    "        fit = self.fit\n",
    "        beta_fit = f\"\\n\\tbeta: {fit['beta']:.3f} +/- {fit['sig_beta']:.3f}\" if not self.fix_beta else ''\n",
    "        r = f\"{self.__class__.__name__}: {fit['counts']:,} counts\"\\\n",
    "            f\"\\n\\tflux: {fit['flux']:.3f} +/- {fit['sig_flux']:.3f} {beta_fit}\"\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 1-D gaussian fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# gr = GaussianRep(ll); print(gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the rate is significant, more than 5 $\\sigma$, the resulting poisson-like parameters are\n",
    "straight-forward to fit.  \n",
    "\n",
    "If $s$ and $v$ are the signal rate and its  variance, determined by the 1-d Gaussian fit for $n$ measurements,\n",
    "so $s > 5\\sqrt{v} $, then we determine the poisson-like parameters as follows.\n",
    "\n",
    "We use the properties of the Poisson distribution \n",
    "$f(n;\\lambda) = \\exp(n \\log\\lambda - \\lambda + \\mathrm{const})$, \n",
    "where the parameter $\\lambda$ is equal to the expected value of number of occurrences $n$ and \n",
    "to its variance, and that the function we want is shifted by the background $b$ and scaled by a factor\n",
    "$k$ so we use $f(k(s-b); \\lambda)$ This implies that for the expected value of $s$, $\\lambda = n$,\n",
    "and $ k(s-b)= k^2 v = n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from which we obtain $k=\\sqrt{n}/v$ and $b=s-k/n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D Gaussian fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Gaussian2dRep(GaussianRep):\n",
    "    def __init__(self, ll):\n",
    "        super().__init__( ll, fix_beta=False)\n",
    "        ll.solve(fix_beta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian2dRep: 1,100 counts\n",
      "\tflux: 1.000 +/- 0.038 \n",
      "\tbeta: 0.000 +/- 0.050\n"
     ]
    }
   ],
   "source": [
    "# create a cell with 100 weights equal to 0.8\n",
    "n = 1000\n",
    "s = 0.7\n",
    "b = 0.4\n",
    "w = np.hstack( [np.full(int(n*s), 1, np.float32), np.full(int(n*b), 0, np.float32)])\n",
    "cell = dict( n=n, w=w, S=n*s, B=n*b)\n",
    "\n",
    "ll2 = LogLike(cell)\n",
    "print( Gaussian2dRep(ll2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PoissonRep(object):\n",
    "    r\"\"\"Manage the representation of the log likelihood of a cell by a `Poisson`.\n",
    "\n",
    "    - loglike: a LogLike object\n",
    "    - ts_min : tolerance for if use fitter\n",
    "    - thresh: sigma threshold to assume no Bayesian restriction\n",
    "\n",
    "    Constructor takes a `LogLike` object, fits it to the poisson-like function (see `Poisson`), and\n",
    "    defines a function to evaluate that.\n",
    "\n",
    "    Note that beta is set to zero.\n",
    "\n",
    "    If the rate is significant, more than 5 $\\sigma$, so that the likelihood is not truncated by the\n",
    "    Bayesian requirement, the resulting poisson-like parameters are   straightforward to determine.\n",
    "\n",
    "    If $s$ and $v$ are the signal rate and its  variance, determined by the 1-d Gaussian fit for $n$ measurements,\n",
    "    so $s > 5\\sqrt{v} $, then we determine the poisson-like parameters as follows.\n",
    "\n",
    "    We use the properties of the Poisson distribution\n",
    "    $f(n;\\lambda) = \\exp(n \\log\\lambda - \\lambda + \\mathrm{const})$,\n",
    "    where the parameter $\\lambda$ is equal to the expected value of number of occurrences $n$ and\n",
    "    to its variance, and that the function we want is shifted by the background $b$ and scaled by a factor\n",
    "    $k$ so we use $f(k(s-b); \\lambda)$ This implies that for the expected value of $s$, $\\lambda = n$,\n",
    "    and $ k(s-b)= k^2 v = n$.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loglike, tol=poisson_tolerance,  # note global\n",
    "                 ts_min=25,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.loglike = loglike # do I need this? lots of memory for the array of weights\n",
    "        rate, sig, self.ts= loglike.rate()\n",
    "\n",
    "        def use_fitter( ):\n",
    "            fmax=max(0, rate)\n",
    "            ## NB: the dd=-10 is a kluge for very small limits, set for loglike stuff with different scales.\n",
    "            # this seems to work, but must be looked at more carefully\n",
    "            try:\n",
    "                self.pf = PoissonFitter(loglike, fmax=fmax, scale=sig if rate>0 else 1,  dd=-10., tol=tol)\n",
    "            except Exception as msg:\n",
    "                print(f'PoissonRep: Fail poisson fit for {loglike}: {msg}'\n",
    "                      f'\\n\\tfmax={fmax}, scale={sig if rate>0 else 1,}'\n",
    "                      , file=sys.stderr)\n",
    "                with open('failed_loglike.pkl', 'wb') as file:\n",
    "                    pickle.dump(loglike, file)\n",
    "                print('Saved LogLike file for study')\n",
    "                raise Exception(msg) #assert False, 'breakpoint'\n",
    "            self.poiss =  self.pf.poiss\n",
    "\n",
    "        if self.ts>ts_min: # can use the simple non-truncated scaled Poisson distribution.\n",
    "            try:\n",
    "                self.poiss = Poisson.from_fit(loglike.n, rate,sig)\n",
    "                self.pf = None\n",
    "            except Exception as e:\n",
    "                use_fitter()\n",
    "        else:\n",
    "            use_fitter()\n",
    "\n",
    "        p = self\n",
    "        # pass on t, tw, e if there else enter 0,1,1\n",
    "        self.fit= dict(t= loglike.t if hasattr(loglike, 't') else 0,\n",
    "                       tw=loglike.tw if hasattr(loglike, 'tw') else 1,\n",
    "                       counts=len(loglike.w),\n",
    "                       e=loglike.e if hasattr(loglike, 'e') else 1,\n",
    "                       flux=np.round(p.flux,4),\n",
    "                       errors=np.abs(np.array(p.errors)-p.flux).round(3),\n",
    "                       limit=np.round(p.limit, 3),\n",
    "                       ts=np.round(p.ts,3),\n",
    "                       poiss_pars=list(np.float32(self.poiss.p)),\n",
    "                      )\n",
    "\n",
    "    def __call__(self, flux):\n",
    "        return self.poiss(flux)\n",
    "\n",
    "    def __repr__(self):\n",
    "        relerr = np.abs(np.array(self.errors)/self.flux-1) if self.flux>0 else [0,0]\n",
    "        return  f'  {self.flux:.3f}[1+{relerr[0]:.3f}-{relerr[1]:.3f}], '\\\n",
    "                f'< {self.limit:.2f}'\n",
    "    @property\n",
    "    def flux(self):\n",
    "        return self.poiss.flux\n",
    "    @property\n",
    "    def errors(self):\n",
    "        return self.poiss.errors\n",
    "    @property\n",
    "    def limit(self):\n",
    "        \"\"\" 95% confidence interval\"\"\"\n",
    "        return self.poiss.cdfcinv(0.05)\n",
    "\n",
    "    def cl(self, x):\n",
    "        \"\"\"Confidence level\"\"\"\n",
    "        return self.poiss.cdfc(x)\n",
    "\n",
    "    def info(self):\n",
    "        \"\"\" Return a dict with useful info\"\"\"\n",
    "        flux = self.flux\n",
    "        return dict(flux=round(flux, 4),\n",
    "                    ts=round(self.ts,1),\n",
    "                    errors=tuple(np.array(self.errors-flux)[::-1].round(4)),\n",
    "                    limit=round(self.limit,4))\n",
    "\n",
    "    def create_table(self, npts=100, support=1e-6):\n",
    "        # make a table of evently-spaced points between limits\n",
    "        #\n",
    "        pars = self.fit['poiss_pars']\n",
    "        p = Poisson(pars)\n",
    "        a,b = p.cdfinv(support), p.cdfcinv(support)\n",
    "        dom=(0 if np.isinf(a) else a, b, npts) # cdfinv can return inf\n",
    "        cod = np.array(list(map(p, np.linspace(*dom)))) .astype(np.float32)\n",
    "        return dom, cod\n",
    "\n",
    "    def comparison_plots(self, xlim=None, ax=None, nbins=21, **kwargs):\n",
    "        \"\"\"Plots comparing this approximation to the actual likelihhod\n",
    "        \"\"\"\n",
    "        f_like = lambda x: self(x)\n",
    "        #pr = light_curve.PoissonRep(self);\n",
    "        fp = lambda x: self(x)\n",
    "        f_like = lambda x: self.loglike([x])\n",
    "        fi = self.loglike.fit_info()\n",
    "        xp = fi['flux']\n",
    "        sigp = fi['sig_flux']\n",
    "        peak = f_like(xp)\n",
    "        if xlim is None:\n",
    "            xlim=(xp-4*sigp, xp+5*sigp)\n",
    "        dom = np.linspace(*xlim,num=nbins)\n",
    "        f_gauss = lambda x: -((x-xp)/sigp)**2/2\n",
    "        fig, ax = plt.subplots(figsize=(6,4)) if not ax else (ax.figure, ax)\n",
    "        ax.plot(dom, [f_like(x)-peak for x in dom], '-b', label='LogLike');\n",
    "        ax.plot(dom, fp(dom), ':+', lw=1, color='green', ms=15, label='PoissonRep');\n",
    "        ax.plot(dom, [f_gauss(x) for x in dom], '--r', label='GaussianRep');\n",
    "        ax.grid(alpha=0.5);\n",
    "        ax.set(ylim=(-9,0.5), **kwargs);\n",
    "        ax.axhline(0, color='grey', ls='--')\n",
    "        ax.legend(prop=dict(size=12))#, family='monospace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(0, 1, 11); y = [fail(t) for t in x]\n",
    "# plt.plot(x,y);\n",
    "\n",
    "# pr = PoissonRep(fail, tol=0.4);\n",
    "# plt.plot(x, [pr(t) for t in x]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# from utilities.ipynb_docgen import *\n",
    "# like = None\n",
    "# @ipynb_doc\n",
    "# def like_demo(n=1000, s=0.7 ):\n",
    "#     \"\"\"## Likelihood demonstration\n",
    "    \n",
    "#     Create a cell, `cell` with {n} weights, {s} of them  set to 1\n",
    "#     and the rest  0: \n",
    "#     <br>\n",
    "#     The LogLike object: `like = LogLike(cell)` is {like_local}\n",
    "    \n",
    "#     1d fit: {fit1d}\n",
    "#     2d fit: {fit2d}\n",
    "#     {fig}\n",
    "#     \"\"\"\n",
    "#     global like\n",
    "#     S = n*s\n",
    "#     B = n-S\n",
    "#     w = np.hstack( [np.full(int(S), 1), \n",
    "#                     np.full(int(n*(1-s)), 0)])\n",
    "#     cell = dict( n=n, w=w, S=S, B=B)\n",
    "\n",
    "#     like = like_local = LogLike(cell)\n",
    "#     fit1d = like.fit_info()\n",
    "#     fit2d = like.fit_info(False)\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(3,1.5))\n",
    "#     like.plot(ax=ax)\n",
    "#     return locals()\n",
    "# like_demo()\n",
    "\n",
    "# self = like\n",
    "# s = self.solve(False); s\n",
    "# h = self.hessian(s); h\n",
    "# v = linalg.inv(h)\n",
    "# s,h, v, len(self.w)\n",
    "\n",
    "# like.rate(False, debug=True)\n",
    "\n",
    "# print(f'1D:\\n{pd.Series(like.fit_info()):}\\n2D:\\n{pd.Series(like.fit_info(False)):}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# def check(ll, pars, xtol=1e-3):\n",
    "#     pars = np.atleast_1d(pars)\n",
    "#     print(f'pars: {pars.round(4)},  function: {fun(pars):.3f}, gradient: {(np.array(grad(pars))).round(4)}')\n",
    "#     pars = ll.solve(fix_beta=False, estimate=pars, xtol=xtol)\n",
    "#     print(f'pars: {pars.round(4)},  function: {fun(pars):.3f}, gradient: {(np.array(grad(pars))).round(4)}')\n",
    "    \n",
    "# check(like, [1.,0.])\n",
    "\n",
    "# check(like, [1.5,0.1], xtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(self, pars):\n",
    "#     pars = np.atleast_1d(pars)\n",
    "#     if len(pars)>1:      alpha, beta = pars - np.array([1,0])\n",
    "#     else:                alpha, beta = max(-1, pars[0]-1), 0\n",
    "#     tmp =  1 + alpha*self.w + beta*(1-self.w)\n",
    "#     # limit alpha\n",
    "#     tmp[tmp<=1e-6]=1e-6\n",
    "\n",
    "#     return np.sum( np.log(tmp)) - alpha*self.S - beta*self.B\n",
    "# test(ll, 1), test(ll, [1,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisson representation development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# info = ll.fit_info()\n",
    "# print(f'LogLike fit info:{info}')\n",
    "# pr = PoissonRep(ll, ts_min=15)\n",
    "# print(f'PoissonRep: {pr}, poiss: {pr.poiss}')\n",
    "# pars = np.array(pr.poiss.p).round(3)\n",
    "# print(f'poisson pars: {pars}')\n",
    "# print(f'poisson info:\\n{pr.info()} ')\n",
    "\n",
    "# n, m, sig = np.array(list(info.values())).round(3)\n",
    "# print(f'Get poisson parmeters from n={int(n)}, m={m}, sig={sig}')\n",
    "# mu, beta = n, n-np.sqrt(n)/sig\n",
    "# e = m*(mu-beta)\n",
    "# b = beta/e\n",
    "# pois = Poisson([m, e , b])\n",
    "# print(pois, pois.p)\n",
    "# pr.comparison_plots(xlim=(0.4, 1.6), ylabel='log likelihood' ,\n",
    "#                     title='Likelihood Functional representations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PoissonRepTable(PoissonRep):\n",
    "    \"\"\"\n",
    "    Create a table, then interpolate it\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loglike):\n",
    "        # PoissonRep fits to Poisson\n",
    "        super().__init__(loglike, )\n",
    "        # now make a table and add to dict\n",
    "        self.dom,self.cod = self.create_table()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return np.interp(x, np.linspace(*self.dom), self.cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 03_sources.ipynb.\n",
      "Converted 04_load_data.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 04_skymaps.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10-time_series.ipynb.\n",
      "Converted 11_energyflux.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_main.ipynb.\n",
      "Converted 99_presentation.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Tue Oct 18 17:58:44 PDT 2022\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bddd76f89f9c9183a8b2a90b7165361291df625cebea30cc3c5961f83ec3bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
