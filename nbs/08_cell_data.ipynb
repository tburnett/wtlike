{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cell_data\n",
    "from nbdev import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-judgment",
   "metadata": {},
   "source": [
    "# Manage cell data\n",
    "> Create cells from source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wtlike.config import *\n",
    "from wtlike.source_data import *\n",
    "from wtlike.loglike import LogLike, PoissonRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class CellData(SourceData):\n",
    "    \"\"\"Manage a set of cells generated from a data set\n",
    "    \n",
    "        Invoke superclass to load photon data and exposure for the source.\n",
    " \n",
    "        * time_bins, default config.time_bins\n",
    "        \n",
    "        \n",
    "        Note that the `e`  cell entry is the actual exposure for the cell in units $cm^2\\ s$, times $10^{-6}$.\n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self, *pars, **kwargs): \n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        bins = kwargs.pop('bins', kwargs.pop('time_bins', Config().time_bins))\n",
    "        #  load source data\n",
    "        super().__init__(*pars, **kwargs )\n",
    "\n",
    "\n",
    "        self.rebin(bins)\n",
    "        self.parent = None\n",
    "\n",
    "    def rebin(self, newbins):\n",
    "        \"\"\"bin, or rebin \n",
    "        \"\"\"\n",
    "        photon_data = self.photons\n",
    "        self.cell_edges = edges = time_bin_edges(self.config, self.exposure, newbins)\n",
    "        if self.config.verbose>0:\n",
    "            step = newbins[2]\n",
    "            self.step_name = 'orbit-based' if step<=0 else bin_size_name(step)\n",
    "            print(f'CellData: Bin photon data into {int(len(edges)/2)} {self.step_name}'\\\n",
    "                  f' bins from {edges[0]:.1f} to {edges[-1]:.1f}')\n",
    "        \n",
    "        # note need to take care of interleave\n",
    "        self.binexp = self.binned_exposure( edges ) [0::2] \n",
    "\n",
    "        \n",
    "#         #self.fexposure=(expose/self.exptot).astype(np.float32)\n",
    "#         self.fexposure = expose \n",
    "        \n",
    "        self.get_cells()\n",
    "        \n",
    "    def get_cells(self, exposure_factor=1e-6):\n",
    "        \"\"\"\n",
    "        Generate the cell DataFrame\n",
    "        \n",
    "        - exposure_factor --  recast exposure as cm^2 * Ms if $10^{-6}$ \n",
    "        \n",
    "        Thus the `e`  cell entry is the actual exposure for the cell in units $cm^2\\ Ms$.\n",
    "        \"\"\"\n",
    "        # restrict photons to range of bin times\n",
    "        photons = self.photons.query(f'{self.cell_edges[0]}<time<{self.cell_edges[-1]}')\n",
    "        \n",
    "        # use photon times to get indices into photon list\n",
    "        edges = np.searchsorted(photons.time, self.cell_edges)\n",
    "        \n",
    "        wts = photons.weight.values\n",
    "        start,stop = self.cell_edges[0::2], self.cell_edges[1::2]\n",
    "        center = (start+stop)/2\n",
    "        width = (stop-start)\n",
    "        cells = []\n",
    "        ek = np.append(edges[0::2], edges[-1])\n",
    "        etot = self.exptot*exposure_factor\n",
    "\n",
    "        Sk, Bk = self.S/etot, self.B/etot\n",
    "\n",
    "        for k, (t, tw, e) in enumerate( zip(\n",
    "                    center, width, self.binexp*exposure_factor) ):\n",
    "            w = wts[ek[k]:ek[k+1]] \n",
    "            n = len(w)\n",
    "            cells.append(dict(t=t, tw=tw, \n",
    "                              e=e,\n",
    "                              n=n,\n",
    "                              w=w,\n",
    "                              S=e*Sk,\n",
    "                              B=e*Bk,\n",
    "                             )\n",
    "                        )\n",
    "        self.cells =  pd.DataFrame(cells)\n",
    "        return self.cells\n",
    "\n",
    "    def update(self): pass # virtual\n",
    "    \n",
    "    def view(self, newbins=None):\n",
    "        \"\"\"Return a \"view\": a new instance of this class with a perhaps a different set of cells\n",
    "        \n",
    "        - newbins -- a tuple (start, stop, step) to define new binning.\n",
    "          - start and stop are either MJD values, or offsets from the start or stop.\n",
    "          - step -- the cell size in days, or if zero, orbit-based binning\n",
    "        \"\"\"\n",
    "        import copy\n",
    "        if self.config.verbose>1:\n",
    "            print(f'Making a view of the class {self.__class__}')\n",
    "        r = copy.copy(self)\n",
    "\n",
    "        if newbins is not None:\n",
    "            r.rebin(newbins)\n",
    "        r.parent = self\n",
    "        r.update()\n",
    "        return r\n",
    "        \n",
    "#### needs fixxing    \n",
    "#     def __repr__(self):\n",
    "#         return f'''{self.__class__}:\n",
    "#         {len(self.fexposure)} intervals from {self.cell_edges[0]:.1f} to {self.cell_edges[-1]:.1f} for source {self.source_name}\n",
    "#         S {self.S:.2f}  B {self.B:.2f} '''\n",
    "\n",
    "    \n",
    "    def concatenate( self ):\n",
    "        \"\"\"\n",
    "        Combine this set of cells to one\n",
    "        Return a dict with summed n, S, B, and concatenated w\n",
    "        \"\"\"\n",
    "\n",
    "        cells = self.cells\n",
    "        \n",
    "        newcell = dict()\n",
    "\n",
    "        if 't' in cells:\n",
    "            ca, cb =cells.iloc[0], cells.iloc[-1]\n",
    "            newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))\n",
    "\n",
    "        for col in ' n S B'.split():\n",
    "            newcell[col] = cells[col].sum()\n",
    "        newcell['w'] = np.concatenate(list(cells.w.values))\n",
    "        return newcell\n",
    "    \n",
    "        \n",
    "    def full_likelihood(self ):\n",
    "        \"\"\"Concatentate all the cells, return a LogLike object\n",
    "        \"\"\"\n",
    "        return LogLike(self.concatenate()) \n",
    "    \n",
    "    def plot_concatenated(self, fignum=1, **kwargs):\n",
    "        \"\"\"Likelihood function, with fit for concatenated data\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        lka = self.full_likelihood()\n",
    "        fig,ax = plt.subplots(figsize=(4,2), num=fignum)\n",
    "        lka.plot(ax=ax, **kwargs) \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "# cd = CellData('Geminga')\n",
    "\n",
    "# cd.plot_concatenated(xlim=(0.99, 1.01), title=f'{cd.source.name}');\n",
    "# print('Parmeters from Poisson fit')\n",
    "# L = cd.full_likelihood()\n",
    "# pr = PoissonRep(L)\n",
    "# print(pd.Series(pr.info()))\n",
    "\n",
    "# (cd.cells.n/cd.cells.e).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CellData\" class=\"doc_header\"><code>class</code> <code>CellData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CellData</code>(**\\*`pars`**, **\\*\\*`kwargs`**) :: [`SourceData`](/wtlikesource_data#SourceData)\n",
       "\n",
       "Manage a set of cells generated from a data set\n",
       "\n",
       "Invoke superclass to load photon data and exposure for the source.\n",
       "\n",
       "* time_bins, default config.time_bins\n",
       "\n",
       "\n",
       "Note that the `e`  cell entry is the actual exposure for the cell in units $cm^2\\ s$, times $10^{-6}$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CellData.view\" class=\"doc_header\"><code>CellData.view</code><a href=\"__main__.py#L88\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CellData.view</code>(**`newbins`**=*`None`*)\n",
       "\n",
       "Return a \"view\": a new instance of this class with a perhaps a different set of cells\n",
       "\n",
       "- newbins -- a tuple (start, stop, step) to define new binning.\n",
       "  - start and stop are either MJD values, or offsets from the start or stop.\n",
       "  - step -- the cell size in days, or if zero, orbit-based binning"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CellData)\n",
    "show_doc(CellData.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def concatenate_cells( cells):\n",
    "    \"\"\"\n",
    "    Combine a group of cells to one\n",
    "    - cells: dataframe with cells containing  n, w, S, B<br>\n",
    "            Optionally, if $t$ is present, generate t and tw\n",
    "    Return a dict with summed n, S, B, and concatenated w\n",
    "    \"\"\"\n",
    "    newcell = dict()\n",
    "    if 't' in cells:\n",
    "        ca, cb =cells.iloc[0], cells.iloc[-1]\n",
    "        newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))\n",
    "\n",
    "    for col in ' n S B'.split():\n",
    "        newcell[col] = cells[col].sum()\n",
    "    newcell['w'] = np.concatenate(list(cells.w.values))\n",
    "    return newcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def partition_cells(config, cells, edges):\n",
    "    \"\"\" Partition a set of cells\n",
    "     - cells -- A DataFrame of cells\n",
    "     - edges  -- a list of edge times delimiting boundaries between cells\n",
    "     \n",
    "    Returns a DataFrame of combined cells, with times and widths adjusted to account for missing cells\n",
    "    \n",
    "    \"\"\"\n",
    "    # get indices of  cell idexes just beyond each edge time\n",
    "    ii = np.searchsorted(cells.t, edges)\n",
    "    \n",
    "    # Get the appropriate boundary times to apply to combined cells\n",
    "    # this is complicated by missing cells, need to put boundary in gaps if ncessary\n",
    "    ileft = ii[:-1]\n",
    "    cleft = cells.iloc[ileft ]\n",
    "    tleft =  (cleft.t - cleft.tw/2).values\n",
    "    iright = ii[1:]-1\n",
    "    cright = cells.iloc[iright ]  \n",
    "    tright = (cright.t+cright.tw/2).values\n",
    "    betweens = 0.5*(tleft[1:] + tright[:-1])\n",
    "    tboundary = np.append(np.insert(betweens, 0, tleft[0]), tright[-1])\n",
    "    \n",
    "    # now combine the cells, \n",
    "    newcells = []\n",
    "    for k in range(len(ii)-1):\n",
    "        a,b = ii[k:k+2]\n",
    "        subset = cells.iloc[a:b]; \n",
    "\n",
    "#         ca, cb = subset.iloc[0], subset.iloc[-1]\n",
    "#         newcell = dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2)  )\n",
    "        tl, tr = tboundary[k:k+2]\n",
    "        newcell = dict(t=0.5*(tl+tr), tw=tr-tl)\n",
    "        \n",
    "        for col in 'e n S B'.split():\n",
    "            newcell[col] = subset[col].sum()\n",
    "        newcell['e'] /= len(subset)\n",
    "        newcell['w'] = np.concatenate(list(subset.w.values)) #np.array(w, np.uint8)\n",
    "        newcells.append(newcell)\n",
    "    return pd.DataFrame(newcells)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-short",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"partition_cells\" class=\"doc_header\"><code>partition_cells</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>partition_cells</code>(**`config`**, **`cells`**, **`edges`**)\n",
       "\n",
       "Partition a set of cells\n",
       " - cells -- A DataFrame of cells\n",
       " - edges  -- a list of edge times delimiting boundaries between cells\n",
       " \n",
       "Returns a DataFrame of combined cells, with times and widths adjusted to account for missing cells"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(partition_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-modern",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_weights.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90-main.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Mon May 10 17:22:19 PDT 2021\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-crest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
