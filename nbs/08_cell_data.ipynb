{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  8 00:41:16 PDT 2022\n"
     ]
    }
   ],
   "source": [
    "# default_exp cell_data\n",
    "from nbdev.showdoc import show_doc\n",
    "from utilities.ipynb_docgen import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-assault",
   "metadata": {},
   "source": [
    "# Manage cell data\n",
    "> Create cells from source data and define the likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da4e22-01ab-4585-9523-3b151d5025bd",
   "metadata": {},
   "source": [
    "## Creating and fitting cells\n",
    "\n",
    "As set out in Kerr, we create \"cells\" by binning in time to form light curves. For each cell, we determine its likelihood function, which is then optimized to estimate the relative signal rate for that duration. \n",
    "\n",
    "Eqn. 2 of Kerr presents the log likelihood as a function of the incremental relative flux $\\alpha$ (with $\\beta=0$). The log likelihood for a cell,\n",
    "\n",
    "$$ \\displaystyle\\log\\mathcal{L}(\\alpha)\\ = \\sum_w  \\log \\big( 1 + \\alpha\\ w \\big) - \\alpha\\ S \\tag{1}  $$\n",
    "\n",
    "The sum is over the photon weights $w$ for that cell, and $S$ is the expected value for sum of weights, determined from the total sum and the fraction of the energy-weighted exposure for the cell:\n",
    "\n",
    "$$ S =  \\frac{f_{cell}}{ f_{total}}\\ \\sum{w},  $$\n",
    "where $f$ represents the energy-weighted exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d681e5-a3fb-44fb-9442-13f09d1c75e3",
   "metadata": {},
   "source": [
    "*Fermi* data is broken into distinct _runs_, corresponding at most to a single orbit. The effective area, or $\\frac{df}{dt}$, which varies by a factor of 2 or 3 for each 90-min orbit, is typically  $ 3 000\\ \\mathrm{cm}^2$, or $0.3\\ \\mathrm{m^2}$. This is measured in 30-s intervals. Exposure is the sum, for each interval in contained in the cell, of the effective area times livetime in the direcion of the source. Since it depends on energy, the Kerr strategy is to perform a weighted average with a spectrum. This can be improved on, see below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbebe18-0be1-486a-8a9f-50c71af2572c",
   "metadata": {},
   "source": [
    "The value of $\\alpha$,  $\\hat{\\alpha}$, which maximizes the likelihood for the cell is the solution to \n",
    "\n",
    "$$ \\sum_{w} \\frac{w}{1+\\hat{\\alpha}\\ w} = S $$\n",
    "\n",
    "So that $\\hat{\\alpha}=0$ corresponds to $\\sum w=  S$, as expected if the cell's flux is the same as the average. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514903b-4e0f-48cd-baa2-6094b1ea2ad9",
   "metadata": {},
   "source": [
    "The Hessian, or inverse variance, is  \n",
    "$$ -\\frac{d^2\\ \\log(\\mathcal{L})}{d\\ \\alpha^2} = \\sum_{w} \\frac{w^2}{(1+\\hat{\\alpha}\\ w)^2}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881db731-5c23-4973-b3d7-eb5ba62adb03",
   "metadata": {},
   "source": [
    "### Approximate the log if $\\alpha \\times \\omega$ is small\n",
    "\n",
    "Kerr uses this to for the frequency derivation. Let $W_=\\sum w$ and $U=\\sum w^2$. Then the  cell's likelihood is\n",
    "\n",
    "$$ \\displaystyle\\log\\mathcal{L}(\\alpha)\\ \\approx   \\alpha\\ \\ (W-S) - \\tfrac{1}{2} \\alpha^2\\ U ,  \\tag{2}$$\n",
    "\n",
    "\n",
    "and the maximum likelihood solution is analytic: $\\hat{\\alpha} =  (W-S)/U$\n",
    "and the inverse variance simply $U$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cad7ce-9376-46c6-8bf1-628d25bfde7e",
   "metadata": {},
   "source": [
    "### Accounting for spectral dependence\n",
    "\n",
    "The development above does not consider energy. The sum over weights includes all photons of all energies, and the coresponding exposure uses a weighted average of the energy-dependent effective area. The Kerr \n",
    "application uses a power-law spectral shape for this--since we have the actual spectrum available, we can use it instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad6162-3727-4692-adef-de7976d5d3e4",
   "metadata": {},
   "source": [
    "We bin energy into four bands per decade. This modification breaks up a call into eight sub-cells with the\n",
    "same $\\alpha$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892e546-d17a-4fd7-a22a-f6970e675ecc",
   "metadata": {},
   "source": [
    "Also, the development above determines the _count_ flux per cell, that is, simply counting photons.  An improvement wmeasures the energy flux as well, or perhaps a spectral index factor as a factor for the assumed spectrum. \n",
    "\n",
    "Each photon has a _band_ index, indicating its type as Front or Back, and its energy band, one of 16 from 100 MeV to 1 TeV. (Although we only use 8 bands, up to 10 GeV). To use this information, we need the corresponding exposure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676bdf0-df2d-4740-bd3e-ca405f18227b",
   "metadata": {},
   "source": [
    "Currently the `exposure` DataFrame has, for each 30-s time interval, the exposure as calculated for the assumed spectrum. This is extended to provide the exposure per energy band.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b697b5b-8f3d-49a8-8164-a87439342861",
   "metadata": {},
   "source": [
    "Let $l$ be the energy index. It represents a logarithmic derivative of the energy. Replace $\\alpha$ with $\\alpha+\\zeta l$ in Equ. (2): Then the solution for $\\zeta$ is\n",
    "\n",
    "$$\\zeta = \\frac{\\sum_l(W_l-S_l-\\alpha U_l)}{\\sum_l l U_l} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794fc3f-455b-4965-8cd0-d22c7fec82f4",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The class `CellData` is created with the list of photons and exposure history for the source. It is created with \n",
    "a `time_bins` argument to describe the binning, generating a list, accessible via the property `cells` with the cell information needed to calculate the likelihood function.\n",
    "\n",
    "Its `view` member function is used to create a new binning, by making a copy of the `CellData` object with the new binning. \n",
    "\n",
    "The default binning is sequential, with start, stop, and step values. Units for start and stop are MJD, so step is in days. The conventions for interpeting the three numbers (0,0,7), the default, is all weeks from the start of data taking. This is implemented by the function `time_bin_edges`.\n",
    "\n",
    "The function `partition_cells` is used to create a set of unequal-sized cells from a BB partition.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a002ec3-970e-4732-8430-957bef9f7ffd",
   "metadata": {},
   "source": [
    "#### Special phased bins\n",
    "\n",
    "To study long-term, many days, variations in the flux, perhaps due to systematics in the exposure, we implement a folded binning version, specified by start, period, and number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('figure', facecolor='white')\n",
    "from wtlike.config import *\n",
    "from wtlike.sources import *\n",
    "from wtlike.source_data import *\n",
    "from wtlike.loglike import LogLike, PoissonRep, poisson_tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc70f17-4dd9-4804-ad8d-04a7b2ced136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export  \n",
    "def time_bin_edges(config, exposure, tbin=None):\n",
    "    \"\"\"Return an interleaved array of time bin, or cell start/stop values\n",
    "\n",
    "    - exposure -- the weighted exposure table derived from the spacecraft info and the source. Used only \n",
    "        to establish nominal start/stop\n",
    "    - tbin: an array (a,b,d), default config.time_bins to specify binning\n",
    "\n",
    "        interpretation of a, b, d:\n",
    "\n",
    "        a:  if > 50000, interpret as MJD for start\n",
    "            if < 0, back from stop\n",
    "            otherwise, offset from exposure start\n",
    "\n",
    "        b:  if > 50000, interpret MJD value for stop    \n",
    "            if > 0, increment from start\n",
    "            otherwise, offset from exposure stop\n",
    "\n",
    "        d : if positive, the day bin size\n",
    "            if 0; return contiguous bins\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # nominal total range, MJD edges\n",
    "    start = np.round(exposure.start.values[0])\n",
    "    stop =  np.round(exposure.stop.values[-1])\n",
    "\n",
    "    a, b, step = tbin if tbin is not None else config.time_bins\n",
    "\n",
    "    if a>50000: start=a\n",
    "    elif a<0: start = stop+a\n",
    "    else : start += a\n",
    "\n",
    "    if b>50000: stop=b\n",
    "    elif b>0: stop = start+b\n",
    "    else: stop += b\n",
    "\n",
    "    if step<=0:\n",
    "        return contiguous_bins(exposure.query(f'{start}<start<{stop}'),)\n",
    "\n",
    "    # adjust stop\n",
    "    nbins = int((stop-start)/step)\n",
    "    assert nbins>0, 'Bad binning: no bins'\n",
    "    stop = start+(nbins)*step\n",
    "    u =  np.linspace(start,stop, nbins+1 )\n",
    "\n",
    "    # make an interleaved start/stop array\n",
    "    v = np.empty(2*nbins, float)\n",
    "    v[0::2] = u[:-1]\n",
    "    v[1::2] = u[1:]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72d807-3d80-418c-adb2-a6263413efb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"time_bin_edges\" class=\"doc_header\"><code>time_bin_edges</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>time_bin_edges</code>(**`config`**, **`exposure`**, **`tbin`**=*`None`*)\n",
       "\n",
       "Return an interleaved array of time bin, or cell start/stop values\n",
       "\n",
       "- exposure -- the weighted exposure table derived from the spacecraft info and the source. Used only \n",
       "    to establish nominal start/stop\n",
       "- tbin: an array (a,b,d), default config.time_bins to specify binning\n",
       "\n",
       "    interpretation of a, b, d:\n",
       "\n",
       "    a:  if > 50000, interpret as MJD for start\n",
       "        if < 0, back from stop\n",
       "        otherwise, offset from exposure start\n",
       "\n",
       "    b:  if > 50000, interpret MJD value for stop    \n",
       "        if > 0, increment from start\n",
       "        otherwise, offset from exposure stop\n",
       "\n",
       "    d : if positive, the day bin size\n",
       "        if 0; return contiguous bins"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(time_bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975a4b6-50a7-4ee7-b207-4afd14cadd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def contiguous_bins(exposure, min_gap=20, min_duration=600):\n",
    "\n",
    "    \"\"\" return a start/stop interleaved array for contiguous intervals\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    stop = exposure.stop.values\n",
    "    start = exposure.start.values\n",
    "\n",
    "    # interleave  the starts and stops\n",
    "    ssint = np.empty(2*len(start))\n",
    "    ssint[0::2] = start\n",
    "    ssint[1::2] = stop\n",
    "\n",
    "    # Tag the (stpp,start) pairs < 10 sec as  not adjacent\n",
    "    not_adjacent = np.diff(ssint)[1::2] > min_gap/(24*3600) ;\n",
    "    #print(f'{sum(not_adjacent)} (start,stop) pairs are not closer than {min_gap} s')\n",
    "\n",
    "    # make a mask, keep ends\n",
    "    mask = np.empty(2*len(start), bool)\n",
    "    mask[0] = mask[-1] = True\n",
    "    #\n",
    "\n",
    "    # insert into mask -- keep only the (stop,start) pairs  which are not adjacent\n",
    "    mask[1:-2:2] = not_adjacent\n",
    "    mask[2:-1:2] = not_adjacent\n",
    "\n",
    "    # apply mask, split into start and stop\n",
    "    keep = ssint[mask]\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b8329-2d83-40af-978d-d1671758a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CellData(SourceData):\n",
    "    \"\"\"Manage a set of cells generated from a data set\n",
    "\n",
    "        Invoke superclass to load photon data and exposure for the source.\n",
    "\n",
    "        * time_bins, default config.time_bins. If specified, set week_range and bypass cache.\n",
    "\n",
    "        The `e` cell entry is the weighted exposure for the cell in units $cm^2\\ Ms$.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, *pars, **kwargs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        bins = kwargs.pop('time_bins', None)\n",
    "        if bins is not None:\n",
    "            if bins[0]>50000 and bins[1]>50000:\n",
    "                # kluge to at least accept (0,0) in constructor\n",
    "                week_range = (mission_week(bins[0]), mission_week(bins[1]))\n",
    "                kwargs.update(week_range=week_range)\n",
    "                setweeks=True\n",
    "        else:\n",
    "            bins = Config().time_bins\n",
    "            setweeks=False\n",
    " \n",
    "        #  load source data\n",
    "  \n",
    "        super().__init__(*pars, **kwargs )\n",
    "        if self.config.verbose>1 and setweeks: \n",
    "            print(f'CellData: set week range to {week_range}')\n",
    "\n",
    "        self.rebin(bins)\n",
    "        self.parent = None\n",
    "\n",
    "    def rebin(self, newbins):\n",
    "        \"\"\"bin, or rebin\n",
    "        \"\"\"\n",
    "        photon_data = self.photons\n",
    "        self.time_bins = newbins\n",
    "        self.cell_edges = edges = time_bin_edges(self.config, self.exposure, newbins)\n",
    "        if self.config.verbose>0:\n",
    "            step = newbins[2]\n",
    "            self.step_name = 'orbit-based' if step<=0 else bin_size_name(step)\n",
    "            print(f'CellData.rebin: Bin photon data into {int(len(edges)/2)} {self.step_name}'\\\n",
    "                  f' bins from {edges[0]:.1f} to {edges[-1]:.1f}')\n",
    "        # note need to take care of interleave\n",
    "        #self.binexp = self.binned_exposure( edges ) [0::2]\n",
    "\n",
    "        self.make_cells()\n",
    "\n",
    "    def get_exposure_per_cell(self, exposure_factor=1e-6):\n",
    "        \"\"\"\n",
    "        Return a dict of arrays per cell:\n",
    "        - exp -- exposure, in cm^2 Ms units, if exposure_factor==1e-6\n",
    "        - costh -- mean cos theta per cell\n",
    "        - exp_energy if exp_fract in the exposure DF, set exposure energy\n",
    "        \n",
    "        Note: total exposure vs. energy is:\n",
    "            t =df.apply(lambda r: np.array(r.exp * np.array(r.exp_fract), float), axis=1).values\n",
    "            u = np.vstack(t)\n",
    "        \"\"\"\n",
    "        exp = self.exposure.exp.values\n",
    "        costh = self.exposure.cos_theta.values\n",
    "        # the cell index list  \n",
    "        eci = np.searchsorted(self.exposure.stop, self.cell_edges).reshape(len(self.cell_edges)//2,2)\n",
    "        cell_exp = np.array([exp[slice(*ecx)].sum()*exposure_factor for ecx in eci], np.float32) #np.float32)\n",
    "        cell_costh =np.array([costh[slice(*ecx)].mean() for ecx in eci], np.float32) #np.float32)\n",
    "        \n",
    "        ef = self.exposure.get('exp_fract', None)\n",
    "        if ef is not None:\n",
    "            efa = np.array([np.array(x,float) for x in ef])\n",
    "            efe = efa.T * exp\n",
    "            cee = np.array([efe.T[slice(*ecx)].sum(axis=0)*exposure_factor for ecx in eci], np.float32)\n",
    "        else:\n",
    "            cee = None\n",
    "        return dict(exp=cell_exp, costh=cell_costh, exp_energy= cee)\n",
    "   \n",
    "    def get_weights_per_cell(self):\n",
    "        \"\"\"\n",
    "        Return a list of arrays of the weights per cell\n",
    "        \"\"\"\n",
    "        wts = self.photons.weight.values.astype(np.float32)\n",
    "        # use photon times to get cell index range into photon list\n",
    "        photon_cell = np.searchsorted(self.photons.time, self.cell_edges).reshape(len(self.cell_edges)//2,2)\n",
    "        return  [wts[slice(*cell)] for cell in photon_cell]\n",
    "        \n",
    "    def make_cells(self, exposure_factor=1e-6):\n",
    "        \"\"\"\n",
    "        Generate a \"cells\" DataFrame, binning according to self.cell_edges\n",
    "\n",
    "        - exposure_factor --  recast exposure as cm^2 * Ms if `exposure_factor`==1e-6`\n",
    "\n",
    "        Thus the `e` cell entry is the weighted exposure for the cell in units $\\mathrm{cm^2 Ms}$.\n",
    "        \"\"\"\n",
    "        # ncells = len(self.cell_edges)//2\n",
    "        start,stop = self.cell_edges[0::2], self.cell_edges[1::2]\n",
    "        center = (start+stop)/2\n",
    "        width = (stop-start)\n",
    "        etot = self.exptot*exposure_factor\n",
    "        Sk, Bk = self.S/etot, self.B/etot\n",
    "\n",
    "        # invoke the helper functions to make lists to incorporate\n",
    "        weights = self.get_weights_per_cell()\n",
    "        ec = self.get_exposure_per_cell(exposure_factor)\n",
    "        cell_exp, cell_costh = ec['exp'], ec['costh']\n",
    "\n",
    "        self.cells = pd.DataFrame.from_dict(dict(\n",
    "            t=center, \n",
    "            tw=width,\n",
    "            e = cell_exp,\n",
    "            ctm = cell_costh,\n",
    "            n = [len(w) for w in weights],\n",
    "            w = weights,\n",
    "            S = cell_exp*Sk,\n",
    "            B = cell_exp*Bk,\n",
    "        ))\n",
    "\n",
    "    def update(self): pass # virtual\n",
    "\n",
    "    def view(self, *pars, exp_min=None, no_update=False):\n",
    "        \"\"\"\n",
    "        Return a \"view\", a copy of this instance with a perhaps a different set of cells\n",
    "\n",
    "        - pars -- start, stop, step  to define new binning. Or start, step, or just step\n",
    "           start and stop are either MJD values, or offsets from the start or stop.\n",
    "           step -- the cell size in days, or if zero, orbit-based binning\n",
    "\n",
    "        - exp_min [None] -- If specified, a different minimum exposure, in cm^2 Ms units to use for fitting\n",
    "            from.\n",
    "            \n",
    "        - no_update -- avoid fitting the cells if invoked by LightCurve or WtLike\n",
    "        \"\"\"\n",
    "        import copy\n",
    "        if self.config.verbose>1:\n",
    "            print(f'Making a view of the class {self.__class__}')\n",
    "        r = copy.copy(self)\n",
    "        if exp_min is not None: r.exp_min=exp_min\n",
    "\n",
    "        if len(pars)==3:\n",
    "            newbins = pars\n",
    "        elif len(pars)==2: # new limits, same interval\n",
    "            newbins = (pars[0], pars[1], self.time_bins[0])\n",
    "        elif len(pars)==1:\n",
    "            if type(pars[0])==tuple:\n",
    "                newbins = pars[0]\n",
    "            else:\n",
    "                newbins = (self.time_bins[0], self.time_bins[1], pars[0])\n",
    "        else:\n",
    "            newbins=None\n",
    "\n",
    "        if newbins is not None:\n",
    "            r.rebin(newbins)\n",
    "            if not no_update:\n",
    "                r.update()\n",
    " \n",
    "        r.parent = self\n",
    "        return r\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'''{self.__class__}:\n",
    "        {len(self.exposure):,} intervals from {self.cell_edges[0]:.1f} to {self.cell_edges[-1]:.1f} for source {self.source_name}\n",
    "        S {self.S:.2f}  B {self.B:.2f} '''\n",
    "\n",
    "\n",
    "    def concatenate( self ):\n",
    "        \"\"\"\n",
    "        Combine this set of cells to one\n",
    "        Return a dict with summed n, S, B, and concatenated w\n",
    "        \"\"\"\n",
    "\n",
    "        cells = self.cells\n",
    "\n",
    "        newcell = dict()\n",
    "\n",
    "        if 't' in cells:\n",
    "            ca, cb =cells.iloc[0], cells.iloc[-1]\n",
    "            newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))\n",
    "\n",
    "        for col in ' n e S B'.split():\n",
    "            newcell[col] = cells[col].sum()\n",
    "        newcell['w'] = np.concatenate(list(cells.w.values))\n",
    "        return newcell\n",
    "\n",
    "\n",
    "    def full_likelihood(self ):\n",
    "        \"\"\"Concatentate all the cells, return a LogLike object\n",
    "        \"\"\"\n",
    "        return LogLike(self.concatenate())\n",
    "\n",
    "    def plot_concatenated(self, fignum=1, ax=None, **kwargs):\n",
    "        \"\"\"Likelihood function, with fit for concatenated data\n",
    "        \"\"\"\n",
    "        lka = self.full_likelihood()\n",
    "        fig,ax = plt.subplots(figsize=(4,2), num=fignum) if ax is None else (ax.figure, ax)\n",
    "        lka.plot(ax=ax, **kwargs)\n",
    "        return fig\n",
    "    \n",
    "    def x_view(self, corr_func):\n",
    "        \"\"\" Return a new view with a modified exposure and same binning\n",
    "        - corr_func -- exposure correction factor function of (MJD) time\n",
    "        \"\"\"\n",
    "        import copy\n",
    "        if self.config.verbose>0:\n",
    "            print(f'CellData.x_view: Making a view of the class {self.__class__.__name__} with adjusted exposure')\n",
    "        r = copy.copy(self)\n",
    "        # need a copy of this object to change the exp field?\n",
    "        r.exposure = copy.copy(self.exposure)\n",
    "        t = r.exposure.stop\n",
    "        mod_exp = r.exposure.exp * corr_func(t) \n",
    "        r.exposure.drop('exp', axis=1)\n",
    "        r.exposure.loc[:,'exp'] = mod_exp\n",
    "\n",
    "        r.rebin(self.time_bins)\n",
    "        r.update()\n",
    "        r.parent = self\n",
    "\n",
    "        return r\n",
    "    \n",
    "    def phase_view(self, period, nbins=25, reference='2008'):\n",
    "        \"\"\" Return a \"phase\" view, in which the cell time binning is according to phase.\n",
    "        \n",
    "        * period -- 'year' | 'precession' | float\n",
    "        * reference -- a UTC date for aligning the bins.\n",
    "        \"\"\"\n",
    "        ref = 0 if not reference else MJD(reference)\n",
    "        \n",
    "        period = dict(precession=53.05, year=365.25).get(period, period)\n",
    "        assert np.isreal(period), f'The specified period, \"{name}\", is not a real number'\n",
    "        \n",
    "        if self.config.verbose>0:\n",
    "            print(f'CellData.phase_view: Create phase view, {nbins} bins with period {period} days.')\n",
    "\n",
    "        # helper function that returns the bin number as a float in [0,period)\n",
    "        binner = lambda t: np.mod(t-ref,period)/period * nbins\n",
    "\n",
    "        # adjust start to correspond to edge of bin\n",
    "\n",
    "        # create a view with nbins per period and get the cells\n",
    "        st = self.start # the start of data taking\n",
    "        self.reference_bin =strefbin = binner(st)\n",
    "        stnew = st +np.mod(-strefbin,1)*period/nbins\n",
    "        view = self.view(stnew, 0, period/nbins, no_update=True)\n",
    "        cells = view.cells\n",
    "        bw = 1/nbins\n",
    "\n",
    "        def concat(pcells, t):\n",
    "            newcell = dict(t=t, tw=bw)\n",
    "            for col in 'n e S B'.split():\n",
    "                newcell[col] = pcells[col].sum()\n",
    "            newcell['w'] = np.concatenate(list(pcells.w.values))\n",
    "            return newcell\n",
    "\n",
    "        # concatenate all in the same phase bin--note cyclic rotation\n",
    "        k = int(strefbin)\n",
    "        fcells = [concat(cells.iloc[((ibin-k)%nbins):-1:nbins], (ibin+0.5)*bw)  for ibin in range(nbins) ]\n",
    "        \n",
    "        view.cells = pd.DataFrame(fcells) \n",
    "        view.update() # does fit\n",
    "        view.is_phase = True # tag to choose proper plot\n",
    "        view.period = period\n",
    "        return  view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CellData\" class=\"doc_header\"><code>class</code> <code>CellData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CellData</code>(**\\*`pars`**, **\\*\\*`kwargs`**) :: [`SourceData`](/wtlikesource_data.html#SourceData)\n",
       "\n",
       "Manage a set of cells generated from a data set\n",
       "\n",
       "Invoke superclass to load photon data and exposure for the source.\n",
       "\n",
       "* time_bins, default config.time_bins. If specified, set week_range and bypass cache.\n",
       "\n",
       "The `e` cell entry is the weighted exposure for the cell in units $cm^2\\ Ms$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CellData.view\" class=\"doc_header\"><code>CellData.view</code><a href=\"__main__.py#L121\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CellData.view</code>(**\\*`pars`**, **`exp_min`**=*`None`*, **`no_update`**=*`False`*)\n",
       "\n",
       "Return a \"view\", a copy of this instance with a perhaps a different set of cells\n",
       "\n",
       "- pars -- start, stop, step  to define new binning. Or start, step, or just step\n",
       "   start and stop are either MJD values, or offsets from the start or stop.\n",
       "   step -- the cell size in days, or if zero, orbit-based binning\n",
       "\n",
       "- exp_min [None] -- If specified, a different minimum exposure, in cm^2 Ms units to use for fitting\n",
       "    from.\n",
       "    \n",
       "- no_update -- avoid fitting the cells if invoked by LightCurve or WtLike"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CellData)\n",
    "show_doc(CellData.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def concatenate_cells( cells):\n",
    "    \"\"\"\n",
    "    Combine a group of cells to one\n",
    "    - cells: dataframe with cells containing  n, w, S, B<br>\n",
    "            Optionally, if $t$ is present, generate t and tw\n",
    "    Return a dict with summed n, S, B, and concatenated w\n",
    "    \"\"\"\n",
    "    newcell = dict()\n",
    "    if 't' in cells:\n",
    "        ca, cb =cells.iloc[0], cells.iloc[-1]\n",
    "        newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))\n",
    "\n",
    "    for col in ' n S B'.split():\n",
    "        newcell[col] = cells[col].sum()\n",
    "    newcell['w'] = np.concatenate(list(cells.w.values))\n",
    "    return newcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def partition_cells(config, cells, edges):\n",
    "    \"\"\" Partition a set of cells\n",
    "     - cells -- A DataFrame of cells\n",
    "     - edges  -- a list of edge times delimiting boundaries between cells\n",
    "\n",
    "    Returns a DataFrame of combined cells, with times and widths adjusted to account for missing cells\n",
    "\n",
    "    \"\"\"\n",
    "    # get indices of  cell indexes just beyond each edge time\n",
    "    ii = np.searchsorted(cells.t, edges)\n",
    "\n",
    "    # Get the appropriate boundary times to apply to combined cells\n",
    "    # this is complicated by missing cells, need to put boundary in gaps if ncessary\n",
    "    ileft = ii[:-1]\n",
    "    cleft = cells.iloc[ileft ]\n",
    "    tleft =  (cleft.t - cleft.tw/2).values\n",
    "    iright = ii[1:]-1\n",
    "    cright = cells.iloc[iright ]\n",
    "    tright = (cright.t+cright.tw/2).values\n",
    "    betweens = 0.5*(tleft[1:] + tright[:-1])\n",
    "    tboundary = np.append(np.insert(betweens, 0, tleft[0]), tright[-1])\n",
    "\n",
    "    # now combine the cells,\n",
    "    newcells = []\n",
    "    for k in range(len(ii)-1):\n",
    "        a,b = ii[k:k+2]\n",
    "        check = cells.iloc[a:b]\n",
    "        subset = check[~pd.isna(check.n)]\n",
    "\n",
    "        tl, tr = tboundary[k:k+2]\n",
    "        newcell = dict(t=0.5*(tl+tr), tw=tr-tl)\n",
    "\n",
    "        for col in 'e n S B'.split():\n",
    "            newcell[col] = subset[col].sum()\n",
    "        newcell['e'] /= len(subset)\n",
    "        newcell['w'] = np.concatenate(list(subset.w.values)) #np.array(w, np.uint8)\n",
    "        newcells.append(newcell)\n",
    "    return pd.DataFrame(newcells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f11c7-0aea-46c8-98d4-67b8cef88b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Study cell formation\n",
       "\n",
       "Set `config.full_exp=True` to get the energy-dependent exposure. Code that does is in `exposure.sc_data_selection`\n",
       "\n",
       "Load first 4 weeks.\n",
       "\n",
       "### Load data\n",
       "<details  class=\"nbdoc-description\" >  <summary> setup: load 4 weeks of data for source \"Geminga\" </summary>  <div style=\"margin-left: 5%;\"><pre>SourceData:  PSR J0633+1746<br>LoadData: Loading weeks[9:12:]<br>\tProcessing 4 week files week_009.pkl - week_012.pkl , using 4 processes <br><br>SourceData: Source PSR J0633+1746 with:<br>\t data:         6,148 photons from 2008-08-04 to 2008-08-27<br>\t exposure:    14,835 intervals,  average effective area 3174 cm^2 for 0.4 Ms<br>\t rates:  source 3.29e-06/s, background 1.07e-06/s, TS 2276709.9<br>CellData.rebin: Bin photon data into 3 1-week bins from 54683.0 to 54704.0<br></pre></div> </details>\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 1\">  <a href=\"images/load_cell_data_fig_01.png\" title=\"images/load_cell_data_fig_01.png\">    <img src=\"images/load_cell_data_fig_01.png\" alt=\"Figure 1 at images/load_cell_data_fig_01.png\" >   </a> </figure>\n",
       "<details open class=\"nbdoc-description\" >  <summary> Parmeters from Poisson fit to full data set </summary>  <div style=\"margin-left: 5%;\"><pre>flux                   1.0<br>ts                 13309.2<br>errors    (0.017, -0.0168)<br>limit               1.0281<br>dtype: object<br></pre></div> </details>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fd8ed2217f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collapse-hide\n",
    "cells = None # global CellData object used below\n",
    "\n",
    "@ipynb_doc\n",
    "def load_cell_data(source_name='Geminga', weeks=(9,12), **kwargs) :\n",
    "    \"\"\"\n",
    "    ## Study cell formation\n",
    "\n",
    "    Set `config.full_exp=True` to get the energy-dependent exposure. Code that does is in `exposure.sc_data_selection`\n",
    "\n",
    "    Load first 4 weeks.\n",
    "\n",
    "    ### Load data\n",
    "    {out1}\n",
    "    {fig}\n",
    "    {out2}\n",
    "    \"\"\"\n",
    "    global cells\n",
    "    \n",
    "    with capture_hide(f'setup: load {weeks[1]-weeks[0]+1} weeks of data for source \"{source_name}\"') as out1:\n",
    "        source = PointSource(source_name) #'Geminga')\n",
    "        cells = CellData(source, config=Config(**kwargs), week_range=weeks,key=None)\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    cells.plot_concatenated(ax=ax, title=source_name);\n",
    "    with capture_show('Parmeters from Poisson fit to full data set') as out2:\n",
    "        L = cells.full_likelihood()\n",
    "        pr = PoissonRep(L)\n",
    "        print(pd.Series(pr.info()))\n",
    "    return locals()\n",
    "load_cell_data(use_kerr=False, full_exp=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24a307-7d5b-42e2-80d5-050c997d63bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Exposure vs. energy\n",
       "\n",
       "With the PSR J0633+1746 data, \n",
       "<details open class=\"nbdoc-description\" >  <summary> Exposure Dataframe from \"df.iloc[0]\" </summary>  <div style=\"margin-left: 5%;\"><pre>start                                             54682.656038<br>stop                                              54682.656375<br>livetime                                             25.041281<br>cos_theta                                             0.818062<br>exp                                              108401.359375<br>exp_fract    [0.10925, 0.135, 0.2428, 0.2141, 0.1604, 0.091...<br>Name: 0, dtype: object<br></pre></div> </details>\n",
       "<details  class=\"nbdoc-description\" >  <summary> Exposure dataframe info </summary>  <div style=\"margin-left: 5%;\"><pre>&lt;class 'pandas.core.frame.DataFrame'&gt;<br>RangeIndex: 14835 entries, 0 to 14834<br>Data columns (total 6 columns):<br> #   Column     Non-Null Count  Dtype  <br>---  ------     --------------  -----  <br> 0   start      14835 non-null  float64<br> 1   stop       14835 non-null  float64<br> 2   livetime   14835 non-null  float32<br> 3   cos_theta  14835 non-null  float32<br> 4   exp        14835 non-null  float32<br> 5   exp_fract  14835 non-null  object <br>dtypes: float32(3), float64(2), object(1)<br>memory usage: 521.7+ KB<br>None<br></pre></div> </details>\n",
       "Note the `exp_fract` values, which are the fraction of the total (`exp`) in each band.\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 2\">  <a href=\"images/check_energy_exposure_fig_02.png\" title=\"images/check_energy_exposure_fig_02.png\">    <img src=\"images/check_energy_exposure_fig_02.png\" alt=\"Figure 2 at images/check_energy_exposure_fig_02.png\" >   </a> </figure>\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fd8ed18b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collapse-hide\n",
    "@ipynb_doc\n",
    "def check_energy_exposure():\n",
    "    \"\"\" ### Exposure vs. energy\n",
    "    \n",
    "    With the {name} data, \n",
    "    {out1}\n",
    "    {out2}\n",
    "    Note the `exp_fract` values, which are the fraction of the total (`exp`) in each band.\n",
    "    {fig}\n",
    "    \"\"\"\n",
    "    df = cells.exposure\n",
    "    name =cells.source.name\n",
    "    with capture_show('Exposure Dataframe from \"df.iloc[0]\"') as out1:\n",
    "        print(df.iloc[0])\n",
    "    with capture_hide('Exposure dataframe info') as out2:\n",
    "        print(df.info())\n",
    "    \n",
    "    # generate array of the 8 \n",
    "    t =df.apply(lambda r: np.array(r.exp * np.array(r.exp_fract), float), axis=1).values\n",
    "    u = np.vstack(t)\n",
    "\n",
    "    fig, (ax, ax2,) =plt.subplots(1,2, figsize=(10,4), sharex=True)\n",
    "    plt.subplots_adjust(top=0.9, wspace=0.3)\n",
    "    fig.suptitle('Exposure vs. Energy')\n",
    "    ax.plot(u.sum(axis=0), 'o')\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.set(xlabel='Energy band', ylabel='Total Exposure')\n",
    "    ax2.violinplot(u, np.arange(8), showmeans=True);\n",
    "    ax2.grid(alpha=0.5)\n",
    "    ax2.set(ylabel='Exposure per interval', xlabel='Energy band index')\n",
    "\n",
    "\n",
    "    return locals()\n",
    "check_energy_exposure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e9ec3-21e6-4e14-a7c6-bb037d4b7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# df = cells.photons.copy()\n",
    "# df.loc[:,'eindex'] = (df.band.values//2).astype(int)\n",
    "\n",
    "\n",
    "# t = df.groupby('eindex').agg(\n",
    "#     wcount = ('weight', len),\n",
    "#     wsum = ('weight', np.sum), #column=\"B\", aggfunc=\"min\"\n",
    "#     wsumsq =('weight', lambda x: np.sum(x**2))\n",
    "# )\n",
    "\n",
    "# t.loc[:,'unc'] = t.apply(lambda r: np.sqrt(r.wsumsq)/r.wsum, axis=1)\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51752a1b-abe1-4d11-94ff-3f67134be96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Weight sum vs. energy\n",
       "The sum of weights is proportional to the flux.\n",
       "Exmamine the photon energy dependence for PSR J0633+1746.\n",
       "\n",
       "<details  class=\"nbdoc-description\" >  <summary> Photon dataframe info </summary>  <div style=\"margin-left: 5%;\"><pre>&lt;class 'pandas.core.frame.DataFrame'&gt;<br>RangeIndex: 6148 entries, 0 to 6147<br>Data columns (total 4 columns):<br> #   Column   Non-Null Count  Dtype  <br>---  ------   --------------  -----  <br> 0   band     6148 non-null   uint8  <br> 1   run_ref  6148 non-null   uint8  <br> 2   weight   6148 non-null   float64<br> 3   time     6148 non-null   float64<br>dtypes: float64(2), uint8(2)<br>memory usage: 108.2 KB<br>None<br></pre></div> </details>\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 3\">  <a href=\"images/flux_energy_fig_03.png\" title=\"images/flux_energy_fig_03.png\">    <img src=\"images/flux_energy_fig_03.png\" alt=\"Figure 3 at images/flux_energy_fig_03.png\" >   </a> </figure>\n",
       "\n",
       "### Check flux per energy band\n",
       "Make the ratio of the sum of weights to exposure, a measure of the flux relative to the spectrum.\n",
       "<details  class=\"nbdoc-description\" >  <summary> Table of weights and Total exposure per band </summary>  <div style=\"margin-left: 5%;\"><pre>         wtsum    exp  ratio<br>eindex                      <br>0        457.6  143.8   3.18<br>1        579.4  181.5   3.19<br>2       1119.4  344.2   3.25<br>3        979.5  307.8   3.18<br>4        809.6  231.4   3.50<br>5        448.5  131.9   3.40<br>6        182.4   53.0   3.44<br>7         60.8   14.1   4.32<br></pre></div> </details>\n",
       "\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 4\">  <a href=\"images/flux_energy_fig_04.png\" title=\"images/flux_energy_fig_04.png\">    <img src=\"images/flux_energy_fig_04.png\" alt=\"Figure 4 at images/flux_energy_fig_04.png\" >   </a> </figure>\n",
       "Loods pretty good.\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7fd8ecb31280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collapse-hide\n",
    "@ipynb_doc\n",
    "def flux_energy():\n",
    "    \"\"\"\n",
    "    ### Weight sum vs. energy\n",
    "    The sum of weights is proportional to the flux.\n",
    "    Exmamine the photon energy dependence for {nickname}.\n",
    "    \n",
    "    {out1}\n",
    "    {fig1}\n",
    "    \n",
    "    ### Check flux per energy band\n",
    "    Make the ratio of the sum of weights to exposure, a measure of the flux relative to the spectrum.\n",
    "    {out2}\n",
    "    \n",
    "    {fig2}\n",
    "    Loods pretty good.\n",
    "    \"\"\"\n",
    "    df = cells.photons.copy()\n",
    "    name, nickname = cells.source.name, cells.source.nickname\n",
    "    with capture_hide('Photon dataframe info') as out1:\n",
    "        print(df.info())\n",
    "    df.loc[:,'eindex'] = (df.band.values//2).astype(int)\n",
    "    # plt.subplots_adjust(wspace=0.3)\n",
    "    # ax.hist(df.eindex, np.linspace(-0.5,7.5,9), log=False, histtype='step', lw=2);\n",
    "    # ax.set(xlabel='Energy index', ylim=(2,None));\n",
    "    \n",
    "    # get the moments of the weight per energy\n",
    "    gb = df.groupby('eindex').agg(\n",
    "            wcount = ('weight', len),\n",
    "            wsum = ('weight', np.sum), #column=\"B\", aggfunc=\"min\"\n",
    "            wsumsq =('weight', lambda x: np.sum(x**2))\n",
    "        )\n",
    "\n",
    "    gb.loc[:,'unc'] = gb.apply(lambda r: np.sqrt(r.wsumsq)/r.wsum, axis=1)\n",
    "    # wtsums = gb.sum().weight.values\n",
    "\n",
    "    fig1, ax1 = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "    ax1.plot(gb.wsum.values, 'o', label='weight sum');\n",
    "    ax1.plot(gb.wcount, 'D', label='counts');\n",
    "    ax1.set(xlabel='Energy band index', yscale='log');\n",
    "    ax1.legend(); ax1.grid(alpha=0.5)\n",
    "    \n",
    "    # get exposure vs enegy\n",
    "    t =cells.exposure.apply(lambda r: np.array(r.exp * np.array(r.exp_fract), float), axis=1).values\n",
    "    ee = np.vstack(t).sum(axis=0)*1e-6\n",
    "    with capture_hide('Table of weights and Total exposure per band') as out2:\n",
    "        dfx = pd.DataFrame(dict(wtsum=gb.wsum.round(1), exp=ee.round(1), ratio=(gb.wsum/ee).round(2)))\n",
    "        print(dfx)\n",
    "   \n",
    "        \n",
    "    fig2, ax2 = plt.subplots(1,1)\n",
    "    ax2.set(ylim=(0,5), xlabel='Energy band index', ylabel='flux/exposure')\n",
    "    ax2.grid(alpha=0.5)\n",
    "    ratio = gb.wsum/ee\n",
    "    ax2.errorbar(x=range(len(ratio)), y=ratio, yerr=ratio*gb.unc, fmt='o', ms=10)\n",
    "    # ax2.plot(gb.wsum/ee, 'o');\n",
    "    \n",
    "    return locals()\n",
    "flux_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72495d96-f8cb-4826-b962-de4168cb8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# df = cells.photons.copy()\n",
    "# name, nickname = cells.source.name, cells.source.nickname\n",
    "# df.loc[:,'eindex'] = (df.band.values//2).astype(int)\n",
    "# # get the moments of the weight per energy\n",
    "# gb = df.groupby('eindex').agg(\n",
    "#         wcount = ('weight', len),\n",
    "#         wsum = ('weight', np.sum), #column=\"B\", aggfunc=\"min\"\n",
    "#         wsumsq =('weight', lambda x: np.sum(x**2))\n",
    "#     )\n",
    "\n",
    "# gb.loc[:,'unc'] = gb.apply(lambda r: np.sqrt(r.wsumsq)/r.wsum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa1240-a8d3-46cb-804c-b48c1d3bcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# #export\n",
    "# def phase_cells(self, period, nbins):\n",
    "#     \"\"\"    \n",
    "#     \"\"\"\n",
    "#     view = self.view(0,0, period/nbins)\n",
    "#     cells = view.cells\n",
    "#     bw = 1/nbins\n",
    "    \n",
    "#     def concat(pcells, t):\n",
    "#         newcell = dict(t=t, tw=bw)\n",
    "\n",
    "#         for col in 'n e S B'.split():\n",
    "#             newcell[col] = pcells[col].sum()\n",
    "#         newcell['w'] = np.concatenate(list(pcells.w.values))\n",
    "#         return newcell\n",
    "    \n",
    "#     fcells = [concat(cells.iloc[ibin:-1:nbins], (ibin+0.5)*bw) for ibin in range(nbins) ]\n",
    "         \n",
    "#     return  pd.DataFrame(fcells)\n",
    "\n",
    "# # hide\n",
    "# ################################\n",
    "# #  Develop folded cells\n",
    "# ###############################\n",
    "# source = PointSource('Vela pulsar')\n",
    "\n",
    "# # photons, exposure = cd.photons.copy(), cd.exposure.copy()\n",
    "# period, nbins = 53.05, 25\n",
    "\n",
    "\n",
    "\n",
    "# z = phase_cells(CellData(source), period,nbins)\n",
    "# z.head()\n",
    "\n",
    "# # hide\n",
    "# config=Config(use_kerr=True); config.verbose=2\n",
    "# if config.valid:\n",
    "#     source = PointSource('Geminga')\n",
    "\n",
    "#     cd = CellData(source, config=config, week_range=(9,11),key=None)\n",
    "\n",
    "#     cd.plot_concatenated( title=f'{cd.source.name}');\n",
    "#     print('Parmeters from Poisson fit to full data set')\n",
    "#     L = cd.full_likelihood()\n",
    "#     pr = PoissonRep(L)\n",
    "#     print(pd.Series(pr.info()))\n",
    "\n",
    "# #(cd.cells.n/cd.cells.e).describe()\n",
    "\n",
    "# # from wtlike.exposure import weighted_aeff\n",
    "# sc_df = cells.exposure\n",
    "\n",
    "# cos_theta = sc_df.cos_theta.values\n",
    "# livetime = sc_df.livetime.values\n",
    "\n",
    "# # func = weighted_aeff(config, source) \n",
    "# # sc_df.loc[:,'exp'] =\n",
    "# exp = sc_df.exp.values #(func(cos_theta) * livetime).astype(np.float32)\n",
    "\n",
    "# ef = sc_df.exp_fract\n",
    "# efa = np.array([np.array(x,float) for x in ef])\n",
    "# efe = efa.T * exp\n",
    "# efe.sum(axis=0)\n",
    "\n",
    "#     def get_exposure_per_cell(self, exposure_factor=1e-6):\n",
    "#         \"\"\"\n",
    "#         Return a dict of arrays per cell:\n",
    "#         - exp -- exposure, in cm^2 Ms units, if exposure_factor==1e-6\n",
    "#         - costh -- mean cos theta per cell\n",
    "#         - exp_energy if exp_fract in the exposure DF, set exposure energy\n",
    "        \n",
    "#         \"\"\"\n",
    "#         exp = self.exposure.exp.values\n",
    "#         costh = self.exposure.cos_theta.values\n",
    "#         # the cell index list  \n",
    "#         eci = np.searchsorted(self.exposure.stop, self.cell_edges).reshape(len(self.cell_edges)//2,2)\n",
    "#         cell_exp = np.array([exp[slice(*ecx)].sum()*exposure_factor for ecx in eci], np.float32) #np.float32)\n",
    "#         cell_costh =np.array([costh[slice(*ecx)].mean() for ecx in eci], np.float32) #np.float32)\n",
    "        \n",
    "#         ef = self.exposure.get('exp_fract', False)\n",
    "#         if ef is not None:\n",
    "#             efa = np.array([np.array(x,float) for x in ef])\n",
    "#             efe = efa.T * exp\n",
    "#             cee = np.array([efe.T[slice(*ecx)].sum(axis=0)*exposure_factor for ecx in eci], np.float32)\n",
    "#         else:\n",
    "#             cee = None\n",
    "#         return dict(exp=cell_exp, costh= cell_costh, exp_energy= cee)\n",
    "\n",
    "# get_exposure_per_cell(cells)\n",
    "\n",
    "# self = cd; exposure_factor=1e-6\n",
    "# exp = self.exposure.exp.values\n",
    "\n",
    "# eci = np.searchsorted(self.exposure.stop, self.cell_edges).reshape(len(self.cell_edges)//2,2)\n",
    "# cell_exp = np.array([exp[slice(*ecx)].sum()*exposure_factor for ecx in eci], np.float32) #np.float32)\n",
    "\n",
    "# cell_energy_exp = t = np.array([efe.T[slice(*ecx)].sum(axis=0)*exposure_factor for ecx in eci])\n",
    "# t, t.sum(axis=1)-\n",
    "\n",
    "## Temporary - check phased cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_data_man.ipynb.\n",
      "Converted 02_effective_area.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 03_sources.ipynb.\n",
      "Converted 04_load_data.ipynb.\n",
      "Converted 04_simulation.ipynb.\n",
      "Converted 05_source_data.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_loglike.ipynb.\n",
      "Converted 08_cell_data.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10-time_series.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_main.ipynb.\n",
      "Converted 99_presentation.ipynb.\n",
      "Converted 99_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sun May  8 00:41:27 PDT 2022\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426879bf-6e6c-4b4e-a868-61b8df311cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
