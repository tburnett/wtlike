# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/07_cells.ipynb (unless otherwise specified).

__all__ = ['get_cells', 'concatenate_cells', 'partition_cells']

# Cell
import os
import numpy as np
import pandas as pd
from .config import Config,  PointSource, Cache
from .photon_data import get_photon_data
from .weights import add_weights, check_weights
from .exposure import get_exposure, get_binned_exposure, get_default_bins

# Cell
class _WeightedCells(object):
    """ Generate a list of cells, with access to cell data
        weights
    """

    def __init__(self, config, source,
                 photon_data:'DataFrame with photon data',
                 bins: 'time bins default if None'=None,
                ):
        """
        Use time binning photon_data to generate list of cells
        """
        self.source_name =source.name
        self.verbose = config.verbose
        self.use_uint8  = config.use_uint8

        # exposure binned as well
        self.fexposure, bins = get_binned_exposure(config, source=source, time_bins=bins, ) #bins, exposure)

        # manage bins
        self.N = len(bins)-1 # number of bins
        self.bins = bins
        self.bin_centers = 0.5*(bins[1:]+bins[:-1])

        # restrict photons to range of bin times
        photons = photon_data.query(f'{bins[0]}<time<{bins[-1]}')

        # get the photon data with good weights, not NaN
        w = photons.weight
        good = np.logical_not(np.isnan(w))
        self.photons = photons.loc[good]
        self.weights = w = self.photons.weight.values

        # estimates for averate signal and background per cell
        self.S = np.sum(w)/self.N
        self.B = np.sum(1-w)/self.N

        # use photon times to get indices of bin edges
        self._edges = np.searchsorted(self.photons.time, bins)


    def __repr__(self):
        return f'''{self.__class__}:
        {len(self.fexposure)} intervals from {self.bins[0]:.1f} to {self.bins[-1]:.1f} for source {self.source_name}
        S {self.S:.2f}  B {self.B:.2f} '''

    def __getitem__(self, i):
        """ get info for ith time bin and return dict with
            t : MJD
            tw: bin width,
            e: exposure as fraction of total,
            n : number of photons in bin
            w : list of weights as uint8 integers<=255
            S,B:  value
        """
        k   = self._edges
        w = self.weights[k[i]:k[i+1]]
        wts = np.array(w*256, np.uint8) if self.use_uint8 else w
        n = len(wts)
        e = self.fexposure[i]
        tw  = self.bins[i+1]-self.bins[i]

        return dict(
                t=self.bin_centers[i], # time
                tw = tw,  # bin width
                e=e, # moving to this name
                n=n, # number of photons in bin
                w=wts,
                S= e *self.S,
                B= e *self.B,
                )

    def __len__(self):
        return self.N

    @property
    def dataframe(self):
        """ combine all cells into a dataframe
        """
        df = pd.DataFrame([cell for cell in self])
        return df


# Cell
def get_cells(config,  source, bins=None, key=''):
    """Return a cells DataFrame for the source

    - source -- `PointSource` object
    - bins -- None, or an array of bin edges to define cells. If None use the default defined in config


    """
    def doit(config, source, bins):
        photon_data = get_photon_data(config,   source )
        add_weights(config,  photon_data, source)

        return _WeightedCells(config, source,photon_data, bins).dataframe

    key = f'cells_{source.name}' if key=='' else  key
    description = f'Cell data for {source.name}' if config.verbose>0 and key is not None else ''

    return config.cache(key, doit, config, source, bins, description=description)

# Cell
def concatenate_cells( cells):
    """
    Combine a group of cells to one
    - cells: dataframe with cells containing  n, w, S, B<br>
            Optionally, if $t$ is present, generate t and tw
    Return a dict with summed n, S, B, and concatenated w
    """
    newcell = dict()
    if 't' in cells:
        ca, cb =cells.iloc[0], cells.iloc[-1]
        newcell.update(dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2), tw=cb.t-ca.t ))

    for col in ' n S B'.split():
        newcell[col] = cells[col].sum()
    newcell['w'] = np.concatenate(list(cells.w.values))
    return newcell

# Cell
def partition_cells(config, cells, edges):
    """ Partition a set of cells
     - cells -- A DataFrame of cells
     - edges  -- a list of edges delimiting boundaries between cells
    """
    # should check limitsk
    ii = np.searchsorted(cells.t, edges)

    newcells = []
    for k in range(len(ii)-1):
        a,b = ii[k:k+2]
        subset = cells.iloc[a:b];

        ca, cb = subset.iloc[0], subset.iloc[-1]
        newcell = dict(t= 0.5*(ca.t-ca.tw/2 + cb.t+cb.tw/2)  )

        for col in 'tw e n S B'.split():
            newcell[col] = subset[col].sum()
        newcell['e'] /= len(subset)
        newcell['w'] = np.concatenate(list(subset.w.values)) #np.array(w, np.uint8)
        newcells.append(newcell)
    return pd.DataFrame(newcells)
